{
  "repository": {
    "summary": "Repository: cyclotruc/gitingest\nFiles analyzed: 65\n\nEstimated tokens: 56.5k",
    "tree": "Directory structure:\n└── cyclotruc-gitingest/\n    ├── README.md\n    ├── CODE_OF_CONDUCT.md\n    ├── CONTRIBUTING.md\n    ├── Dockerfile\n    ├── LICENSE\n    ├── SECURITY.md\n    ├── pyproject.toml\n    ├── requirements-dev.txt\n    ├── requirements.txt\n    ├── .dockerignore\n    ├── .pre-commit-config.yaml\n    ├── docs/\n    ├── src/\n    │   ├── gitingest/\n    │   │   ├── __init__.py\n    │   │   ├── cli.py\n    │   │   ├── cloning.py\n    │   │   ├── config.py\n    │   │   ├── entrypoint.py\n    │   │   ├── ingestion.py\n    │   │   ├── output_formatters.py\n    │   │   ├── query_parsing.py\n    │   │   ├── schemas/\n    │   │   │   ├── __init__.py\n    │   │   │   ├── filesystem_schema.py\n    │   │   │   └── ingestion_schema.py\n    │   │   └── utils/\n    │   │       ├── __init__.py\n    │   │       ├── exceptions.py\n    │   │       ├── file_utils.py\n    │   │       ├── git_utils.py\n    │   │       ├── ignore_patterns.py\n    │   │       ├── ingestion_utils.py\n    │   │       ├── notebook_utils.py\n    │   │       ├── path_utils.py\n    │   │       ├── query_parser_utils.py\n    │   │       └── timeout_wrapper.py\n    │   ├── server/\n    │   │   ├── __init__.py\n    │   │   ├── main.py\n    │   │   ├── query_processor.py\n    │   │   ├── server_config.py\n    │   │   ├── server_utils.py\n    │   │   ├── routers/\n    │   │   │   ├── __init__.py\n    │   │   │   ├── download.py\n    │   │   │   ├── dynamic.py\n    │   │   │   └── index.py\n    │   │   └── templates/\n    │   │       ├── api.jinja\n    │   │       ├── base.jinja\n    │   │       ├── git.jinja\n    │   │       ├── index.jinja\n    │   │       └── components/\n    │   │           ├── footer.jinja\n    │   │           ├── git_form.jinja\n    │   │           ├── navbar.jinja\n    │   │           └── result.jinja\n    │   └── static/\n    │       ├── robots.txt\n    │       └── js/\n    │           └── utils.js\n    ├── tests/\n    │   ├── __init__.py\n    │   ├── conftest.py\n    │   ├── test_cli.py\n    │   ├── test_flow_integration.py\n    │   ├── test_ingestion.py\n    │   ├── test_notebook_utils.py\n    │   ├── test_repository_clone.py\n    │   ├── .pylintrc\n    │   └── query_parser/\n    │       ├── test_git_host_agnostic.py\n    │       └── test_query_parser.py\n    └── .github/\n        ├── dependabot.yml\n        └── workflows/\n            ├── ci.yml\n            ├── publish.yml\n            └── scorecard.yml\n",
    "content": "================================================\nFile: README.md\n================================================\n# Gitingest\n\n[![Image](./docs/frontpage.png \"Gitingest main page\")](https://gitingest.com)\n\n[![License](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/cyclotruc/gitingest/blob/main/LICENSE)\n[![PyPI version](https://badge.fury.io/py/gitingest.svg)](https://badge.fury.io/py/gitingest)\n[![GitHub stars](https://img.shields.io/github/stars/cyclotruc/gitingest?style=social.svg)](https://github.com/cyclotruc/gitingest)\n[![Downloads](https://pepy.tech/badge/gitingest)](https://pepy.tech/project/gitingest)\n\n[![Discord](https://dcbadge.limes.pink/api/server/https://discord.com/invite/zerRaGK9EC)](https://discord.com/invite/zerRaGK9EC)\n\nTurn any Git repository into a prompt-friendly text ingest for LLMs.\n\nYou can also replace `hub` with `ingest` in any GitHub URL to access the corresponding digest.\n\n[gitingest.com](https://gitingest.com) · [Chrome Extension](https://chromewebstore.google.com/detail/adfjahbijlkjfoicpjkhjicpjpjfaood) · [Firefox Add-on](https://addons.mozilla.org/firefox/addon/gitingest)\n\n## 🚀 Features\n\n- **Easy code context**: Get a text digest from a Git repository URL or a directory\n- **Smart Formatting**: Optimized output format for LLM prompts\n- **Statistics about**:\n  - File and directory structure\n  - Size of the extract\n  - Token count\n- **CLI tool**: Run it as a shell command\n- **Python package**: Import it in your code\n\n## 📚 Requirements\n\n- Python 3.7+\n\n### 📦 Installation\n\nGitingest is available on [PyPI](https://pypi.org/project/gitingest/).\nYou can install it using `pip`:\n\n```bash\npip install gitingest\n```\n\nHowever, it might be a good idea to use `pipx` to install it.\nYou can install `pipx` using your preferred package manager.\n\n```bash\nbrew install pipx\napt install pipx\nscoop install pipx\n...\n```\n\nIf you are using pipx for the first time, run:\n\n```bash\npipx ensurepath\n```\n\n```bash\n# install gitingest\npipx install gitingest\n```\n\n## 🧩 Browser Extension Usage\n\n<!-- markdownlint-disable MD033 -->\n<a href=\"https://chromewebstore.google.com/detail/adfjahbijlkjfoicpjkhjicpjpjfaood\" target=\"_blank\" title=\"Get Gitingest Extension from Chrome Web Store\"><img height=\"48\" src=\"https://github.com/user-attachments/assets/20a6e44b-fd46-4e6c-8ea6-aad436035753\" alt=\"Available in the Chrome Web Store\" /></a>\n<a href=\"https://addons.mozilla.org/firefox/addon/gitingest\" target=\"_blank\" title=\"Get Gitingest Extension from Firefox Add-ons\"><img height=\"48\" src=\"https://github.com/user-attachments/assets/c0e99e6b-97cf-4af2-9737-099db7d3538b\" alt=\"Get The Add-on for Firefox\" /></a>\n<a href=\"https://microsoftedge.microsoft.com/addons/detail/nfobhllgcekbmpifkjlopfdfdmljmipf\" target=\"_blank\" title=\"Get Gitingest Extension from Microsoft Edge Add-ons\"><img height=\"48\" src=\"https://github.com/user-attachments/assets/204157eb-4cae-4c0e-b2cb-db514419fd9e\" alt=\"Get from the Edge Add-ons\" /></a>\n<!-- markdownlint-enable MD033 -->\n\nThe extension is open source at [lcandy2/gitingest-extension](https://github.com/lcandy2/gitingest-extension).\n\nIssues and feature requests are welcome to the repo.\n\n## 💡 Command line usage\n\nThe `gitingest` command line tool allows you to analyze codebases and create a text dump of their contents.\n\n```bash\n# Basic usage\ngitingest /path/to/directory\n\n# From URL\ngitingest https://github.com/cyclotruc/gitingest\n\n# See more options\ngitingest --help\n```\n\nThis will write the digest in a text file (default `digest.txt`) in your current working directory.\n\n## 🐍 Python package usage\n\n```python\n# Synchronous usage\nfrom gitingest import ingest\n\nsummary, tree, content = ingest(\"path/to/directory\")\n\n# or from URL\nsummary, tree, content = ingest(\"https://github.com/cyclotruc/gitingest\")\n```\n\nBy default, this won't write a file but can be enabled with the `output` argument.\n\n```python\n# Asynchronous usage\nfrom gitingest import ingest_async\nimport asyncio\n\nresult = asyncio.run(ingest_async(\"path/to/directory\"))\n```\n\n### Jupyter notebook usage\n\n```python\nfrom gitingest import ingest_async\n\n# Use await directly in Jupyter\nsummary, tree, content = await ingest_async(\"path/to/directory\")\n\n```\n\nThis is because Jupyter notebooks are asynchronous by default.\n\n## 🐳 Self-host\n\n1. Build the image:\n\n   ``` bash\n   docker build -t gitingest .\n   ```\n\n2. Run the container:\n\n   ``` bash\n   docker run -d --name gitingest -p 8000:8000 gitingest\n   ```\n\nThe application will be available at `http://localhost:8000`.\n\nIf you are hosting it on a domain, you can specify the allowed hostnames via env variable `ALLOWED_HOSTS`.\n\n   ```bash\n   # Default: \"gitingest.com, *.gitingest.com, localhost, 127.0.0.1\".\n   ALLOWED_HOSTS=\"example.com, localhost, 127.0.0.1\"\n   ```\n\n## 🤝 Contributing\n\n### Non-technical ways to contribute\n\n- **Create an Issue**: If you find a bug or have an idea for a new feature, please [create an issue](https://github.com/cyclotruc/gitingest/issues/new) on GitHub. This will help us track and prioritize your request.\n- **Spread the Word**: If you like Gitingest, please share it with your friends, colleagues, and on social media. This will help us grow the community and make Gitingest even better.\n- **Use Gitingest**: The best feedback comes from real-world usage! If you encounter any issues or have ideas for improvement, please let us know by [creating an issue](https://github.com/cyclotruc/gitingest/issues/new) on GitHub or by reaching out to us on [Discord](https://discord.com/invite/zerRaGK9EC).\n\n### Technical ways to contribute\n\nGitingest aims to be friendly for first time contributors, with a simple Python and HTML codebase. If you need any help while working with the code, reach out to us on [Discord](https://discord.com/invite/zerRaGK9EC). For detailed instructions on how to make a pull request, see [CONTRIBUTING.md](./CONTRIBUTING.md).\n\n## 🛠️ Stack\n\n- [Tailwind CSS](https://tailwindcss.com) - Frontend\n- [FastAPI](https://github.com/fastapi/fastapi) - Backend framework\n- [Jinja2](https://jinja.palletsprojects.com) - HTML templating\n- [tiktoken](https://github.com/openai/tiktoken) - Token estimation\n- [posthog](https://github.com/PostHog/posthog) - Amazing analytics\n\n### Looking for a JavaScript/FileSystemNode package?\n\nCheck out the NPM alternative 📦 Repomix: <https://github.com/yamadashy/repomix>\n\n## 🚀 Project Growth\n\n[![Star History Chart](https://api.star-history.com/svg?repos=cyclotruc/gitingest&type=Date)](https://star-history.com/#cyclotruc/gitingest&Date)\n\n\n\n================================================\nFile: CODE_OF_CONDUCT.md\n================================================\n# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nWe as members, contributors, and leaders pledge to make participation in our\ncommunity a harassment-free experience for everyone, regardless of age, body\nsize, visible or invisible disability, ethnicity, sex characteristics, gender\nidentity and expression, level of experience, education, socio-economic status,\nnationality, personal appearance, race, religion, or sexual identity\nand orientation.\n\nWe pledge to act and interact in ways that contribute to an open, welcoming,\ndiverse, inclusive, and healthy community.\n\n## Our Standards\n\nExamples of behavior that contributes to a positive environment for our\ncommunity include:\n\n* Demonstrating empathy and kindness toward other people\n* Being respectful of differing opinions, viewpoints, and experiences\n* Giving and gracefully accepting constructive feedback\n* Accepting responsibility and apologizing to those affected by our mistakes,\n  and learning from the experience\n* Focusing on what is best not just for us as individuals, but for the\n  overall community\n\nExamples of unacceptable behavior include:\n\n* The use of sexualized language or imagery, and sexual attention or\n  advances of any kind\n* Trolling, insulting or derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or email\n  address, without their explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\n## Enforcement Responsibilities\n\nCommunity leaders are responsible for clarifying and enforcing our standards of\nacceptable behavior and will take appropriate and fair corrective action in\nresponse to any behavior that they deem inappropriate, threatening, offensive,\nor harmful.\n\nCommunity leaders have the right and responsibility to remove, edit, or reject\ncomments, commits, code, wiki edits, issues, and other contributions that are\nnot aligned to this Code of Conduct, and will communicate reasons for moderation\ndecisions when appropriate.\n\n## Scope\n\nThis Code of Conduct applies within all community spaces, and also applies when\nan individual is officially representing the community in public spaces.\nExamples of representing our community include using an official e-mail address,\nposting via an official social media account, or acting as an appointed\nrepresentative at an online or offline event.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported to the community leaders responsible for enforcement at\n<romain@coderamp.io>.\nAll complaints will be reviewed and investigated promptly and fairly.\n\nAll community leaders are obligated to respect the privacy and security of the\nreporter of any incident.\n\n## Enforcement Guidelines\n\nCommunity leaders will follow these Community Impact Guidelines in determining\nthe consequences for any action they deem in violation of this Code of Conduct:\n\n### 1. Correction\n\n**Community Impact**: Use of inappropriate language or other behavior deemed\nunprofessional or unwelcome in the community.\n\n**Consequence**: A private, written warning from community leaders, providing\nclarity around the nature of the violation and an explanation of why the\nbehavior was inappropriate. A public apology may be requested.\n\n### 2. Warning\n\n**Community Impact**: A violation through a single incident or series\nof actions.\n\n**Consequence**: A warning with consequences for continued behavior. No\ninteraction with the people involved, including unsolicited interaction with\nthose enforcing the Code of Conduct, for a specified period of time. This\nincludes avoiding interactions in community spaces as well as external channels\nlike social media. Violating these terms may lead to a temporary or\npermanent ban.\n\n### 3. Temporary Ban\n\n**Community Impact**: A serious violation of community standards, including\nsustained inappropriate behavior.\n\n**Consequence**: A temporary ban from any sort of interaction or public\ncommunication with the community for a specified period of time. No public or\nprivate interaction with the people involved, including unsolicited interaction\nwith those enforcing the Code of Conduct, is allowed during this period.\nViolating these terms may lead to a permanent ban.\n\n### 4. Permanent Ban\n\n**Community Impact**: Demonstrating a pattern of violation of community\nstandards, including sustained inappropriate behavior,  harassment of an\nindividual, or aggression toward or disparagement of classes of individuals.\n\n**Consequence**: A permanent ban from any sort of public interaction within\nthe community.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant](https://www.contributor-covenant.org),\nversion 2.0, available at\n<https://www.contributor-covenant.org/version/2/0/code_of_conduct.html>.\n\nCommunity Impact Guidelines were inspired by [Mozilla's code of conduct\nenforcement ladder](https://github.com/mozilla/diversity).\n\nFor answers to common questions about this code of conduct, see the FAQ at\n<https://www.contributor-covenant.org/faq>. Translations are available at\n<https://www.contributor-covenant.org/translations>.\n\n\n\n================================================\nFile: CONTRIBUTING.md\n================================================\n# Contributing to Gitingest\n\nThanks for your interest in contributing to Gitingest! ðŸš€ Gitingest aims to be friendly for first time contributors, with a simple Python and HTML codebase. We would love your help to make it even better. If you need any help while working with the code, please reach out to us on [Discord](https://discord.com/invite/zerRaGK9EC).\n\n## How to Contribute (non-technical)\n\n- **Create an Issue**: If you find a bug or have an idea for a new feature, please [create an issue](https://github.com/cyclotruc/gitingest/issues/new) on GitHub. This will help us track and prioritize your request.\n- **Spread the Word**: If you like Gitingest, please share it with your friends, colleagues, and on social media. This will help us grow the community and make Gitingest even better.\n- **Use Gitingest**: The best feedback comes from real-world usage! If you encounter any issues or have ideas for improvement, please let us know by [creating an issue](https://github.com/cyclotruc/gitingest/issues/new) on GitHub or by reaching out to us on [Discord](https://discord.com/invite/zerRaGK9EC).\n\n## How to submit a Pull Request\n\n1. Fork the repository.\n\n2. Clone the forked repository:\n\n   ```bash\n   git clone https://github.com/cyclotruc/gitingest.git\n   cd gitingest\n   ```\n\n3. Set up the development environment and install dependencies:\n\n   ```bash\n   python -m venv .venv\n   source .venv/bin/activate\n   pip install -r requirements-dev.txt\n   pre-commit install\n   ```\n\n4. Create a new branch for your changes:\n\n    ```bash\n    git checkout -b your-branch\n    ```\n\n5. Make your changes. Make sure to add corresponding tests for your changes.\n\n6. Stage your changes:\n\n    ```bash\n    git add .\n    ```\n\n7. Run the tests:\n\n   ```bash\n   pytest\n   ```\n\n8. Run the local web server\n\n   1. Navigate to src folder\n\n        ``` bash\n        cd src\n        ```\n\n   2. Run the local web server:\n\n      ``` bash\n      uvicorn server.main:app\n      ```\n\n   3. Open your browser and navigate to `http://localhost:8000` to see the app running.\n\n9. Confirm that everything is working as expected. If you encounter any issues, fix them and repeat steps 6 to 8.\n\n10. Commit your changes:\n\n    ```bash\n    git commit -m \"Your commit message\"\n    ```\n\n    If `pre-commit` raises any issues, fix them and repeat steps 6 to 9.\n\n11. Push your changes:\n\n    ```bash\n    git push origin your-branch\n    ```\n\n12. Open a pull request on GitHub. Make sure to include a detailed description of your changes.\n\n13. Wait for the maintainers to review your pull request. If there are any issues, fix them and repeat steps 6 to 12.\n\n    *(Optional) Invite project maintainer to your branch for easier collaboration.*\n\n\n\n================================================\nFile: Dockerfile\n================================================\n# Build stage\nFROM python:3.12-slim AS builder\n\nWORKDIR /build\n\n# Copy requirements first to leverage Docker cache\nCOPY requirements.txt .\n\n# Install build dependencies and Python packages\nRUN apt-get update \\\n    && apt-get install -y --no-install-recommends gcc python3-dev \\\n    && pip install --no-cache-dir --upgrade pip \\\n    && pip install --no-cache-dir --timeout 1000 -r requirements.txt \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Runtime stage\nFROM python:3.12-slim\n\n# Set Python environment variables\nENV PYTHONUNBUFFERED=1\nENV PYTHONDONTWRITEBYTECODE=1\n\n# Install Git\nRUN apt-get update \\\n    && apt-get install -y --no-install-recommends git curl\\\n    && rm -rf /var/lib/apt/lists/*\n\nWORKDIR /app\n\n# Create a non-root user\nRUN useradd -m -u 1000 appuser\n\nCOPY --from=builder /usr/local/lib/python3.12/site-packages/ /usr/local/lib/python3.12/site-packages/\nCOPY src/ ./\n\n# Change ownership of the application files\nRUN chown -R appuser:appuser /app\n\n# Switch to non-root user\nUSER appuser\n\nEXPOSE 8000\n\nCMD [\"python\", \"-m\", \"uvicorn\", \"server.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n\n\n\n================================================\nFile: LICENSE\n================================================\nMIT License\n\nCopyright (c) 2024 Romain Courtois\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\n\n\n================================================\nFile: SECURITY.md\n================================================\n# Security Policy\n\n## Reporting a Vulnerability\n\nIf you have discovered a vulnerability inside the project, report it privately at <romain@coderamp.io>. This way the maintainer can work on a proper fix without disclosing the problem to the public before it has been solved.\n\n\n\n================================================\nFile: pyproject.toml\n================================================\n[project]\nname = \"gitingest\"\nversion = \"0.1.4\"\ndescription=\"CLI tool to analyze and create text dumps of codebases for LLMs\"\nreadme = {file = \"README.md\", content-type = \"text/markdown\" }\nrequires-python = \">= 3.8\"\ndependencies = [\n    \"click>=8.0.0\",\n    \"fastapi[standard]>=0.109.1\",  # Vulnerable to https://osv.dev/vulnerability/PYSEC-2024-38\n    \"pydantic\",\n    \"python-dotenv\",\n    \"slowapi\",\n    \"starlette>=0.40.0\",  # Vulnerable to https://osv.dev/vulnerability/GHSA-f96h-pmfr-66vw\n    \"tiktoken\",\n    \"tomli\",\n    \"typing_extensions; python_version < '3.10'\",\n    \"uvicorn>=0.11.7\",  # Vulnerable to https://osv.dev/vulnerability/PYSEC-2020-150\n]\n\nlicense = {file = \"LICENSE\"}\nauthors = [{name = \"Romain Courtois\", email = \"romain@coderamp.io\"}]\nclassifiers=[\n    \"Development Status :: 3 - Alpha\",\n    \"Intended Audience :: Developers\",\n    \"License :: OSI Approved :: MIT License\",\n    \"Programming Language :: Python :: 3.7\",\n    \"Programming Language :: Python :: 3.8\",\n    \"Programming Language :: Python :: 3.9\",\n    \"Programming Language :: Python :: 3.10\",\n    \"Programming Language :: Python :: 3.11\",\n    \"Programming Language :: Python :: 3.12\",\n    \"Programming Language :: Python :: 3.13\",\n]\n\n[project.scripts]\ngitingest = \"gitingest.cli:main\"\n\n[project.urls]\nhomepage = \"https://gitingest.com\"\ngithub = \"https://github.com/cyclotruc/gitingest\"\n\n[build-system]\nrequires = [\"setuptools>=61.0\", \"wheel\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[tool.setuptools]\npackages = {find = {where = [\"src\"]}}\ninclude-package-data = true\n\n# Linting configuration\n[tool.pylint.format]\nmax-line-length = 119\n\n[tool.pylint.'MESSAGES CONTROL']\ndisable = [\n    \"too-many-arguments\",\n    \"too-many-positional-arguments\",\n    \"too-many-locals\",\n    \"too-few-public-methods\",\n    \"broad-exception-caught\",\n    \"duplicate-code\",\n    \"fixme\",\n]\n\n[tool.pycln]\nall = true\n\n[tool.isort]\nprofile = \"black\"\nline_length = 119\nremove_redundant_aliases = true\nfloat_to_top = true\norder_by_type = true\nfilter_files = true\n\n[tool.black]\nline-length = 119\n\n# Test configuration\n[tool.pytest.ini_options]\npythonpath = [\"src\"]\ntestpaths = [\"tests/\"]\npython_files = \"test_*.py\"\nasyncio_mode = \"auto\"\nasyncio_default_fixture_loop_scope = \"function\"\npython_classes = \"Test*\"\npython_functions = \"test_*\"\n\n\n\n================================================\nFile: requirements-dev.txt\n================================================\n-r requirements.txt\nblack\ndjlint\npre-commit\npylint\npytest\npytest-asyncio\n\n\n\n================================================\nFile: requirements.txt\n================================================\nclick>=8.0.0\nfastapi[standard]>=0.109.1  # Vulnerable to https://osv.dev/vulnerability/PYSEC-2024-38\npydantic\npython-dotenv\nslowapi\nstarlette>=0.40.0  # Vulnerable to https://osv.dev/vulnerability/GHSA-f96h-pmfr-66vw\ntiktoken\ntomli\nuvicorn>=0.11.7  # Vulnerable to https://osv.dev/vulnerability/PYSEC-2020-150\n\n\n\n================================================\nFile: .dockerignore\n================================================\n# Git\n.git\n.gitignore\n\n# Python\n__pycache__\n*.pyc\n*.pyo\n*.pyd\n.Python\nenv\npip-log.txt\npip-delete-this-directory.txt\n.tox\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.log\n\n# Virtual environment\nvenv\n.env\n.venv\nENV\n\n# IDE\n.idea\n.vscode\n*.swp\n*.swo\n\n# Project specific\ndocs/\ntests/\n*.md\nLICENSE\nsetup.py\n\n\n\n================================================\nFile: .pre-commit-config.yaml\n================================================\nrepos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v5.0.0\n    hooks:\n      # Files\n      - id: check-added-large-files\n        description: \"Prevent large files from being committed.\"\n        args: [\"--maxkb=10000\"]\n      - id: check-case-conflict\n        description: \"Check for files that would conflict in case-insensitive filesystems.\"\n      - id: fix-byte-order-marker\n        description: \"Remove utf-8 byte order marker.\"\n      - id: mixed-line-ending\n        description: \"Replace mixed line ending.\"\n\n      # Links\n      - id: destroyed-symlinks\n        description: \"Detect symlinks which are changed to regular files with a content of a path which that symlink was pointing to.\"\n\n      # File files for parseable syntax: python\n      - id: check-ast\n\n      # File and line endings\n      - id: end-of-file-fixer\n        description: \"Ensure that a file is either empty, or ends with one newline.\"\n      - id: trailing-whitespace\n        description: \"Trim trailing whitespace.\"\n\n      # Python\n      - id: check-docstring-first\n        description: \"Check a common error of defining a docstring after code.\"\n      - id: requirements-txt-fixer\n        description: \"Sort entries in requirements.txt.\"\n\n  - repo: https://github.com/MarcoGorelli/absolufy-imports\n    rev: v0.3.1\n    hooks:\n      - id: absolufy-imports\n        description: \"Automatically convert relative imports to absolute. (Use `args: [--never]` to revert.)\"\n\n  - repo: https://github.com/psf/black\n    rev: 25.1.0\n    hooks:\n      - id: black\n\n  - repo: https://github.com/asottile/pyupgrade\n    rev: v3.19.1\n    hooks:\n      - id: pyupgrade\n        description: \"Automatically upgrade syntax for newer versions.\"\n        args: [--py3-plus, --py36-plus]\n\n  - repo: https://github.com/pre-commit/pygrep-hooks\n    rev: v1.10.0\n    hooks:\n      - id: python-check-blanket-noqa\n        description: \"Enforce that `noqa` annotations always occur with specific codes. Sample annotations: `# noqa: F401`, `# noqa: F401,W203`.\"\n      - id: python-check-blanket-type-ignore\n        description: \"Enforce that `# type: ignore` annotations always occur with specific codes. Sample annotations: `# type: ignore[attr-defined]`, `# type: ignore[attr-defined, name-defined]`.\"\n      - id: python-use-type-annotations\n        description: \"Enforce that python3.6+ type annotations are used instead of type comments.\"\n\n  - repo: https://github.com/PyCQA/isort\n    rev: 6.0.1\n    hooks:\n      - id: isort\n        description: \"Sort imports alphabetically, and automatically separated into sections and by type.\"\n\n\n  - repo: https://github.com/djlint/djLint\n    rev: v1.36.4\n    hooks:\n      - id: djlint-reformat-jinja\n\n  - repo: https://github.com/igorshubovych/markdownlint-cli\n    rev: v0.44.0\n    hooks:\n      - id: markdownlint\n        description: \"Lint markdown files.\"\n        args: [\"--disable=line-length\"]\n\n  - repo: https://github.com/terrencepreilly/darglint\n    rev: v1.8.1\n    hooks:\n      - id: darglint\n        name: darglint for source\n        args: [--docstring-style=numpy]\n        files: ^src/\n\n  - repo: https://github.com/pycqa/pylint\n    rev: v3.3.6\n    hooks:\n      - id: pylint\n        name: pylint for source\n        files: ^src/\n        additional_dependencies:\n          [\n            click>=8.0.0,\n            \"fastapi[standard]>=0.109.1\",\n            pydantic,\n            pytest-asyncio,\n            python-dotenv,\n            slowapi,\n            starlette>=0.40.0,\n            tiktoken,\n            tomli,\n            uvicorn>=0.11.7,\n          ]\n      - id: pylint\n        name: pylint for tests\n        files: ^tests/\n        args:\n          - --rcfile=tests/.pylintrc\n        additional_dependencies:\n          [\n            click>=8.0.0,\n            \"fastapi[standard]>=0.109.1\",\n            pydantic,\n            pytest-asyncio,\n            python-dotenv,\n            slowapi,\n            starlette>=0.40.0,\n            tiktoken,\n            tomli,\n            uvicorn>=0.11.7,\n          ]\n\n  - repo: meta\n    hooks:\n      - id: check-hooks-apply\n      - id: check-useless-excludes\n\n\n\n\n================================================\nFile: src/gitingest/__init__.py\n================================================\n\"\"\"Gitingest: A package for ingesting data from Git repositories.\"\"\"\n\nfrom gitingest.cloning import clone_repo\nfrom gitingest.entrypoint import ingest, ingest_async\nfrom gitingest.ingestion import ingest_query\nfrom gitingest.query_parsing import parse_query\n\n__all__ = [\"ingest_query\", \"clone_repo\", \"parse_query\", \"ingest\", \"ingest_async\"]\n\n\n\n================================================\nFile: src/gitingest/cli.py\n================================================\n\"\"\"Command-line interface for the Gitingest package.\"\"\"\n\n# pylint: disable=no-value-for-parameter\n\nimport asyncio\nfrom typing import Optional, Tuple\n\nimport click\n\nfrom gitingest.config import MAX_FILE_SIZE, OUTPUT_FILE_NAME\nfrom gitingest.entrypoint import ingest_async\n\n\n@click.command()\n@click.argument(\"source\", type=str, default=\".\")\n@click.option(\"--output\", \"-o\", default=None, help=\"Output file path (default: <repo_name>.txt in current directory)\")\n@click.option(\"--max-size\", \"-s\", default=MAX_FILE_SIZE, help=\"Maximum file size to process in bytes\")\n@click.option(\"--exclude-pattern\", \"-e\", multiple=True, help=\"Patterns to exclude\")\n@click.option(\"--include-pattern\", \"-i\", multiple=True, help=\"Patterns to include\")\n@click.option(\"--branch\", \"-b\", default=None, help=\"Branch to clone and ingest\")\ndef main(\n    source: str,\n    output: Optional[str],\n    max_size: int,\n    exclude_pattern: Tuple[str, ...],\n    include_pattern: Tuple[str, ...],\n    branch: Optional[str],\n):\n    \"\"\"\n     Main entry point for the CLI. This function is called when the CLI is run as a script.\n\n    It calls the async main function to run the command.\n\n    Parameters\n    ----------\n    source : str\n        The source directory or repository to analyze.\n    output : str, optional\n        The path where the output file will be written. If not specified, the output will be written\n        to a file named `<repo_name>.txt` in the current directory.\n    max_size : int\n        The maximum file size to process, in bytes. Files larger than this size will be ignored.\n    exclude_pattern : Tuple[str, ...]\n        A tuple of patterns to exclude during the analysis. Files matching these patterns will be ignored.\n    include_pattern : Tuple[str, ...]\n        A tuple of patterns to include during the analysis. Only files matching these patterns will be processed.\n    branch : str, optional\n        The branch to clone (optional).\n    \"\"\"\n    # Main entry point for the CLI. This function is called when the CLI is run as a script.\n    asyncio.run(_async_main(source, output, max_size, exclude_pattern, include_pattern, branch))\n\n\nasync def _async_main(\n    source: str,\n    output: Optional[str],\n    max_size: int,\n    exclude_pattern: Tuple[str, ...],\n    include_pattern: Tuple[str, ...],\n    branch: Optional[str],\n) -> None:\n    \"\"\"\n    Analyze a directory or repository and create a text dump of its contents.\n\n    This command analyzes the contents of a specified source directory or repository, applies custom include and\n    exclude patterns, and generates a text summary of the analysis which is then written to an output file.\n\n    Parameters\n    ----------\n    source : str\n        The source directory or repository to analyze.\n    output : str, optional\n        The path where the output file will be written. If not specified, the output will be written\n        to a file named `<repo_name>.txt` in the current directory.\n    max_size : int\n        The maximum file size to process, in bytes. Files larger than this size will be ignored.\n    exclude_pattern : Tuple[str, ...]\n        A tuple of patterns to exclude during the analysis. Files matching these patterns will be ignored.\n    include_pattern : Tuple[str, ...]\n        A tuple of patterns to include during the analysis. Only files matching these patterns will be processed.\n    branch : str, optional\n        The branch to clone (optional).\n\n    Raises\n    ------\n    Abort\n        If there is an error during the execution of the command, this exception is raised to abort the process.\n    \"\"\"\n    try:\n        # Combine default and custom ignore patterns\n        exclude_patterns = set(exclude_pattern)\n        include_patterns = set(include_pattern)\n\n        if not output:\n            output = OUTPUT_FILE_NAME\n        summary, _, _ = await ingest_async(source, max_size, include_patterns, exclude_patterns, branch, output=output)\n\n        click.echo(f\"Analysis complete! Output written to: {output}\")\n        click.echo(\"\\nSummary:\")\n        click.echo(summary)\n\n    except Exception as exc:\n        click.echo(f\"Error: {exc}\", err=True)\n        raise click.Abort()\n\n\nif __name__ == \"__main__\":\n    main()\n\n\n\n================================================\nFile: src/gitingest/cloning.py\n================================================\n\"\"\"This module contains functions for cloning a Git repository to a local path.\"\"\"\n\nimport os\nfrom pathlib import Path\nfrom typing import Optional\n\nfrom gitingest.schemas import CloneConfig\nfrom gitingest.utils.git_utils import check_repo_exists, ensure_git_installed, run_command\nfrom gitingest.utils.timeout_wrapper import async_timeout\n\nTIMEOUT: int = 60\n\n\n@async_timeout(TIMEOUT)\nasync def clone_repo(config: CloneConfig) -> None:\n    \"\"\"\n    Clone a repository to a local path based on the provided configuration.\n\n    This function handles the process of cloning a Git repository to the local file system.\n    It can clone a specific branch or commit if provided, and it raises exceptions if\n    any errors occur during the cloning process.\n\n    Parameters\n    ----------\n    config : CloneConfig\n        The configuration for cloning the repository.\n\n    Raises\n    ------\n    ValueError\n        If the repository is not found or if the provided URL is invalid.\n    OSError\n        If an error occurs while creating the parent directory for the repository.\n    \"\"\"\n    # Extract and validate query parameters\n    url: str = config.url\n    local_path: str = config.local_path\n    commit: Optional[str] = config.commit\n    branch: Optional[str] = config.branch\n    partial_clone: bool = config.subpath != \"/\"\n\n    # Create parent directory if it doesn't exist\n    parent_dir = Path(local_path).parent\n    try:\n        os.makedirs(parent_dir, exist_ok=True)\n    except OSError as exc:\n        raise OSError(f\"Failed to create parent directory {parent_dir}: {exc}\") from exc\n\n    # Check if the repository exists\n    if not await check_repo_exists(url):\n        raise ValueError(\"Repository not found, make sure it is public\")\n\n    clone_cmd = [\"git\", \"clone\", \"--single-branch\"]\n    # TODO re-enable --recurse-submodules\n\n    if partial_clone:\n        clone_cmd += [\"--filter=blob:none\", \"--sparse\"]\n\n    if not commit:\n        clone_cmd += [\"--depth=1\"]\n        if branch and branch.lower() not in (\"main\", \"master\"):\n            clone_cmd += [\"--branch\", branch]\n\n    clone_cmd += [url, local_path]\n\n    # Clone the repository\n    await ensure_git_installed()\n    await run_command(*clone_cmd)\n\n    if commit or partial_clone:\n        checkout_cmd = [\"git\", \"-C\", local_path]\n\n        if partial_clone:\n            subpath = config.subpath.lstrip(\"/\")\n            if config.blob:\n                # When ingesting from a file url (blob/branch/path/file.txt), we need to remove the file name.\n                subpath = str(Path(subpath).parent.as_posix())\n\n            checkout_cmd += [\"sparse-checkout\", \"set\", subpath]\n\n        if commit:\n            checkout_cmd += [\"checkout\", commit]\n\n        # Check out the specific commit and/or subpath\n        await run_command(*checkout_cmd)\n\n\n\n================================================\nFile: src/gitingest/config.py\n================================================\n\"\"\"Configuration file for the project.\"\"\"\n\nimport tempfile\nfrom pathlib import Path\n\nMAX_FILE_SIZE = 10 * 1024 * 1024  # 10 MB\nMAX_DIRECTORY_DEPTH = 20  # Maximum depth of directory traversal\nMAX_FILES = 10_000  # Maximum number of files to process\nMAX_TOTAL_SIZE_BYTES = 500 * 1024 * 1024  # 500 MB\n\nOUTPUT_FILE_NAME = \"digest.txt\"\n\nTMP_BASE_PATH = Path(tempfile.gettempdir()) / \"gitingest\"\n\n\n\n================================================\nFile: src/gitingest/entrypoint.py\n================================================\n\"\"\"Main entry point for ingesting a source and processing its contents.\"\"\"\n\nimport asyncio\nimport inspect\nimport shutil\nfrom typing import Optional, Set, Tuple, Union\n\nfrom gitingest.cloning import clone_repo\nfrom gitingest.config import TMP_BASE_PATH\nfrom gitingest.ingestion import ingest_query\nfrom gitingest.query_parsing import IngestionQuery, parse_query\n\n\nasync def ingest_async(\n    source: str,\n    max_file_size: int = 10 * 1024 * 1024,  # 10 MB\n    include_patterns: Optional[Union[str, Set[str]]] = None,\n    exclude_patterns: Optional[Union[str, Set[str]]] = None,\n    branch: Optional[str] = None,\n    output: Optional[str] = None,\n) -> Tuple[str, str, str]:\n    \"\"\"\n    Main entry point for ingesting a source and processing its contents.\n\n    This function analyzes a source (URL or local path), clones the corresponding repository (if applicable),\n    and processes its files according to the specified query parameters. It returns a summary, a tree-like\n    structure of the files, and the content of the files. The results can optionally be written to an output file.\n\n    Parameters\n    ----------\n    source : str\n        The source to analyze, which can be a URL (for a Git repository) or a local directory path.\n    max_file_size : int\n        Maximum allowed file size for file ingestion. Files larger than this size are ignored, by default\n        10*1024*1024 (10 MB).\n    include_patterns : Union[str, Set[str]], optional\n        Pattern or set of patterns specifying which files to include. If `None`, all files are included.\n    exclude_patterns : Union[str, Set[str]], optional\n        Pattern or set of patterns specifying which files to exclude. If `None`, no files are excluded.\n    branch : str, optional\n        The branch to clone and ingest. If `None`, the default branch is used.\n    output : str, optional\n        File path where the summary and content should be written. If `None`, the results are not written to a file.\n\n    Returns\n    -------\n    Tuple[str, str, str]\n        A tuple containing:\n        - A summary string of the analyzed repository or directory.\n        - A tree-like string representation of the file structure.\n        - The content of the files in the repository or directory.\n\n    Raises\n    ------\n    TypeError\n        If `clone_repo` does not return a coroutine, or if the `source` is of an unsupported type.\n    \"\"\"\n    repo_cloned = False\n\n    try:\n        query: IngestionQuery = await parse_query(\n            source=source,\n            max_file_size=max_file_size,\n            from_web=False,\n            include_patterns=include_patterns,\n            ignore_patterns=exclude_patterns,\n        )\n\n        if query.url:\n            selected_branch = branch if branch else query.branch  # prioritize branch argument\n            query.branch = selected_branch\n\n            clone_config = query.extract_clone_config()\n            clone_coroutine = clone_repo(clone_config)\n\n            if inspect.iscoroutine(clone_coroutine):\n                if asyncio.get_event_loop().is_running():\n                    await clone_coroutine\n                else:\n                    asyncio.run(clone_coroutine)\n            else:\n                raise TypeError(\"clone_repo did not return a coroutine as expected.\")\n\n            repo_cloned = True\n\n        summary, tree, content = ingest_query(query)\n\n        if output is not None:\n            with open(output, \"w\", encoding=\"utf-8\") as f:\n                f.write(tree + \"\\n\" + content)\n\n        return summary, tree, content\n    finally:\n        # Clean up the temporary directory if it was created\n        if repo_cloned:\n            shutil.rmtree(TMP_BASE_PATH, ignore_errors=True)\n\n\ndef ingest(\n    source: str,\n    max_file_size: int = 10 * 1024 * 1024,  # 10 MB\n    include_patterns: Optional[Union[str, Set[str]]] = None,\n    exclude_patterns: Optional[Union[str, Set[str]]] = None,\n    branch: Optional[str] = None,\n    output: Optional[str] = None,\n) -> Tuple[str, str, str]:\n    \"\"\"\n    Synchronous version of ingest_async.\n\n    This function analyzes a source (URL or local path), clones the corresponding repository (if applicable),\n    and processes its files according to the specified query parameters. It returns a summary, a tree-like\n    structure of the files, and the content of the files. The results can optionally be written to an output file.\n\n    Parameters\n    ----------\n    source : str\n        The source to analyze, which can be a URL (for a Git repository) or a local directory path.\n    max_file_size : int\n        Maximum allowed file size for file ingestion. Files larger than this size are ignored, by default\n        10*1024*1024 (10 MB).\n    include_patterns : Union[str, Set[str]], optional\n        Pattern or set of patterns specifying which files to include. If `None`, all files are included.\n    exclude_patterns : Union[str, Set[str]], optional\n        Pattern or set of patterns specifying which files to exclude. If `None`, no files are excluded.\n    branch : str, optional\n        The branch to clone and ingest. If `None`, the default branch is used.\n    output : str, optional\n        File path where the summary and content should be written. If `None`, the results are not written to a file.\n\n    Returns\n    -------\n    Tuple[str, str, str]\n        A tuple containing:\n        - A summary string of the analyzed repository or directory.\n        - A tree-like string representation of the file structure.\n        - The content of the files in the repository or directory.\n\n    See Also\n    --------\n    ingest_async : The asynchronous version of this function.\n    \"\"\"\n    return asyncio.run(\n        ingest_async(\n            source=source,\n            max_file_size=max_file_size,\n            include_patterns=include_patterns,\n            exclude_patterns=exclude_patterns,\n            branch=branch,\n            output=output,\n        )\n    )\n\n\n\n================================================\nFile: src/gitingest/ingestion.py\n================================================\n\"\"\"Functions to ingest and analyze a codebase directory or single file.\"\"\"\n\nimport warnings\nfrom pathlib import Path\nfrom typing import Tuple\n\nfrom gitingest.config import MAX_DIRECTORY_DEPTH, MAX_FILES, MAX_TOTAL_SIZE_BYTES\nfrom gitingest.output_formatters import format_node\nfrom gitingest.query_parsing import IngestionQuery\nfrom gitingest.schemas import FileSystemNode, FileSystemNodeType, FileSystemStats\nfrom gitingest.utils.ingestion_utils import _should_exclude, _should_include\n\ntry:\n    import tomllib  # type: ignore[import]\nexcept ImportError:\n    import tomli as tomllib\n\n\ndef ingest_query(query: IngestionQuery) -> Tuple[str, str, str]:\n    \"\"\"\n    Run the ingestion process for a parsed query.\n\n    This is the main entry point for analyzing a codebase directory or single file. It processes the query\n    parameters, reads the file or directory content, and generates a summary, directory structure, and file content,\n    along with token estimations.\n\n    Parameters\n    ----------\n    query : IngestionQuery\n        The parsed query object containing information about the repository and query parameters.\n\n    Returns\n    -------\n    Tuple[str, str, str]\n        A tuple containing the summary, directory structure, and file contents.\n\n    Raises\n    ------\n    ValueError\n        If the path cannot be found, is not a file, or the file has no content.\n    \"\"\"\n    subpath = Path(query.subpath.strip(\"/\")).as_posix()\n    path = query.local_path / subpath\n\n    apply_gitingest_file(path, query)\n\n    if not path.exists():\n        raise ValueError(f\"{query.slug} cannot be found\")\n\n    if (query.type and query.type == \"blob\") or query.local_path.is_file():\n        # TODO: We do this wrong! We should still check the branch and commit!\n        if not path.is_file():\n            raise ValueError(f\"Path {path} is not a file\")\n\n        relative_path = path.relative_to(query.local_path)\n\n        file_node = FileSystemNode(\n            name=path.name,\n            type=FileSystemNodeType.FILE,\n            size=path.stat().st_size,\n            file_count=1,\n            path_str=str(relative_path),\n            path=path,\n        )\n\n        if not file_node.content:\n            raise ValueError(f\"File {file_node.name} has no content\")\n\n        return format_node(file_node, query)\n\n    root_node = FileSystemNode(\n        name=path.name,\n        type=FileSystemNodeType.DIRECTORY,\n        path_str=str(path.relative_to(query.local_path)),\n        path=path,\n    )\n\n    stats = FileSystemStats()\n\n    _process_node(\n        node=root_node,\n        query=query,\n        stats=stats,\n    )\n\n    return format_node(root_node, query)\n\n\ndef apply_gitingest_file(path: Path, query: IngestionQuery) -> None:\n    \"\"\"\n    Apply the .gitingest file to the query object.\n\n    This function reads the .gitingest file in the specified path and updates the query object with the ignore\n    patterns found in the file.\n\n    Parameters\n    ----------\n    path : Path\n        The path of the directory to ingest.\n    query : IngestionQuery\n        The parsed query object containing information about the repository and query parameters.\n        It should have an attribute `ignore_patterns` which is either None or a set of strings.\n    \"\"\"\n    path_gitingest = path / \".gitingest\"\n\n    if not path_gitingest.is_file():\n        return\n\n    try:\n        with path_gitingest.open(\"rb\") as f:\n            data = tomllib.load(f)\n    except tomllib.TOMLDecodeError as exc:\n        warnings.warn(f\"Invalid TOML in {path_gitingest}: {exc}\", UserWarning)\n        return\n\n    config_section = data.get(\"config\", {})\n    ignore_patterns = config_section.get(\"ignore_patterns\")\n\n    if not ignore_patterns:\n        return\n\n    # If a single string is provided, make it a list of one element\n    if isinstance(ignore_patterns, str):\n        ignore_patterns = [ignore_patterns]\n\n    if not isinstance(ignore_patterns, (list, set)):\n        warnings.warn(\n            f\"Expected a list/set for 'ignore_patterns', got {type(ignore_patterns)} in {path_gitingest}. Skipping.\",\n            UserWarning,\n        )\n        return\n\n    # Filter out duplicated patterns\n    ignore_patterns = set(ignore_patterns)\n\n    # Filter out any non-string entries\n    valid_patterns = {pattern for pattern in ignore_patterns if isinstance(pattern, str)}\n    invalid_patterns = ignore_patterns - valid_patterns\n\n    if invalid_patterns:\n        warnings.warn(f\"Ignore patterns {invalid_patterns} are not strings. Skipping.\", UserWarning)\n\n    if not valid_patterns:\n        return\n\n    if query.ignore_patterns is None:\n        query.ignore_patterns = valid_patterns\n    else:\n        query.ignore_patterns.update(valid_patterns)\n\n    return\n\n\ndef _process_node(\n    node: FileSystemNode,\n    query: IngestionQuery,\n    stats: FileSystemStats,\n) -> None:\n    \"\"\"\n    Process a file or directory item within a directory.\n\n    This function handles each file or directory item, checking if it should be included or excluded based on the\n    provided patterns. It handles symlinks, directories, and files accordingly.\n\n    Parameters\n    ----------\n    node : FileSystemNode\n        The current directory or file node being processed.\n    query : IngestionQuery\n        The parsed query object containing information about the repository and query parameters.\n    stats : FileSystemStats\n        Statistics tracking object for the total file count and size.\n    \"\"\"\n\n    if limit_exceeded(stats, node.depth):\n        return\n\n    for sub_path in node.path.iterdir():\n\n        if query.ignore_patterns and _should_exclude(sub_path, query.local_path, query.ignore_patterns):\n            continue\n\n        if query.include_patterns and not _should_include(sub_path, query.local_path, query.include_patterns):\n            continue\n\n        if sub_path.is_symlink():\n            _process_symlink(path=sub_path, parent_node=node, stats=stats, local_path=query.local_path)\n        elif sub_path.is_file():\n            _process_file(path=sub_path, parent_node=node, stats=stats, local_path=query.local_path)\n        elif sub_path.is_dir():\n\n            child_directory_node = FileSystemNode(\n                name=sub_path.name,\n                type=FileSystemNodeType.DIRECTORY,\n                path_str=str(sub_path.relative_to(query.local_path)),\n                path=sub_path,\n                depth=node.depth + 1,\n            )\n\n            _process_node(\n                node=child_directory_node,\n                query=query,\n                stats=stats,\n            )\n            node.children.append(child_directory_node)\n            node.size += child_directory_node.size\n            node.file_count += child_directory_node.file_count\n            node.dir_count += 1 + child_directory_node.dir_count\n        else:\n            print(f\"Warning: {sub_path} is an unknown file type, skipping\")\n\n    node.sort_children()\n\n\ndef _process_symlink(path: Path, parent_node: FileSystemNode, stats: FileSystemStats, local_path: Path) -> None:\n    \"\"\"\n    Process a symlink in the file system.\n\n    This function checks the symlink's target.\n\n    Parameters\n    ----------\n    path : Path\n        The full path of the symlink.\n    parent_node : FileSystemNode\n        The parent directory node.\n    stats : FileSystemStats\n        Statistics tracking object for the total file count and size.\n    local_path : Path\n        The base path of the repository or directory being processed.\n    \"\"\"\n    child = FileSystemNode(\n        name=path.name,\n        type=FileSystemNodeType.SYMLINK,\n        path_str=str(path.relative_to(local_path)),\n        path=path,\n        depth=parent_node.depth + 1,\n    )\n    stats.total_files += 1\n    parent_node.children.append(child)\n    parent_node.file_count += 1\n\n\ndef _process_file(path: Path, parent_node: FileSystemNode, stats: FileSystemStats, local_path: Path) -> None:\n    \"\"\"\n    Process a file in the file system.\n\n    This function checks the file's size, increments the statistics, and reads its content.\n    If the file size exceeds the maximum allowed, it raises an error.\n\n    Parameters\n    ----------\n    path : Path\n        The full path of the file.\n    parent_node : FileSystemNode\n        The dictionary to accumulate the results.\n    stats : FileSystemStats\n        Statistics tracking object for the total file count and size.\n    local_path : Path\n        The base path of the repository or directory being processed.\n    \"\"\"\n    file_size = path.stat().st_size\n    if stats.total_size + file_size > MAX_TOTAL_SIZE_BYTES:\n        print(f\"Skipping file {path}: would exceed total size limit\")\n        return\n\n    stats.total_files += 1\n    stats.total_size += file_size\n\n    if stats.total_files > MAX_FILES:\n        print(f\"Maximum file limit ({MAX_FILES}) reached\")\n        return\n\n    child = FileSystemNode(\n        name=path.name,\n        type=FileSystemNodeType.FILE,\n        size=file_size,\n        file_count=1,\n        path_str=str(path.relative_to(local_path)),\n        path=path,\n        depth=parent_node.depth + 1,\n    )\n\n    parent_node.children.append(child)\n    parent_node.size += file_size\n    parent_node.file_count += 1\n\n\ndef limit_exceeded(stats: FileSystemStats, depth: int) -> bool:\n    \"\"\"\n    Check if any of the traversal limits have been exceeded.\n\n    This function checks if the current traversal has exceeded any of the configured limits:\n    maximum directory depth, maximum number of files, or maximum total size in bytes.\n\n    Parameters\n    ----------\n    stats : FileSystemStats\n        Statistics tracking object for the total file count and size.\n    depth : int\n        The current depth of directory traversal.\n\n    Returns\n    -------\n    bool\n        True if any limit has been exceeded, False otherwise.\n    \"\"\"\n    if depth > MAX_DIRECTORY_DEPTH:\n        print(f\"Maximum depth limit ({MAX_DIRECTORY_DEPTH}) reached\")\n        return True\n\n    if stats.total_files >= MAX_FILES:\n        print(f\"Maximum file limit ({MAX_FILES}) reached\")\n        return True  # TODO: end recursion\n\n    if stats.total_size >= MAX_TOTAL_SIZE_BYTES:\n        print(f\"Maxumum total size limit ({MAX_TOTAL_SIZE_BYTES/1024/1024:.1f}MB) reached\")\n        return True  # TODO: end recursion\n\n    return False\n\n\n\n================================================\nFile: src/gitingest/output_formatters.py\n================================================\n\"\"\"Functions to ingest and analyze a codebase directory or single file.\"\"\"\n\nfrom typing import Optional, Tuple\n\nimport tiktoken\n\nfrom gitingest.query_parsing import IngestionQuery\nfrom gitingest.schemas import FileSystemNode, FileSystemNodeType\n\n\ndef format_node(node: FileSystemNode, query: IngestionQuery) -> Tuple[str, str, str]:\n    \"\"\"\n    Generate a summary, directory structure, and file contents for a given file system node.\n\n    If the node represents a directory, the function will recursively process its contents.\n\n    Parameters\n    ----------\n    node : FileSystemNode\n        The file system node to be summarized.\n    query : IngestionQuery\n        The parsed query object containing information about the repository and query parameters.\n\n    Returns\n    -------\n    Tuple[str, str, str]\n        A tuple containing the summary, directory structure, and file contents.\n    \"\"\"\n    is_single_file = node.type == FileSystemNodeType.FILE\n    summary = _create_summary_prefix(query, single_file=is_single_file)\n\n    if node.type == FileSystemNodeType.DIRECTORY:\n        summary += f\"Files analyzed: {node.file_count}\\n\"\n    elif node.type == FileSystemNodeType.FILE:\n        summary += f\"File: {node.name}\\n\"\n        summary += f\"Lines: {len(node.content.splitlines()):,}\\n\"\n\n    tree = \"Directory structure:\\n\" + _create_tree_structure(query, node)\n    _create_tree_structure(query, node)\n\n    content = _gather_file_contents(node)\n\n    token_estimate = _format_token_count(tree + content)\n    if token_estimate:\n        summary += f\"\\nEstimated tokens: {token_estimate}\"\n\n    return summary, tree, content\n\n\ndef _create_summary_prefix(query: IngestionQuery, single_file: bool = False) -> str:\n    \"\"\"\n    Create a prefix string for summarizing a repository or local directory.\n\n    Includes repository name (if provided), commit/branch details, and subpath if relevant.\n\n    Parameters\n    ----------\n    query : IngestionQuery\n        The parsed query object containing information about the repository and query parameters.\n    single_file : bool\n        A flag indicating whether the summary is for a single file, by default False.\n\n    Returns\n    -------\n    str\n        A summary prefix string containing repository, commit, branch, and subpath details.\n    \"\"\"\n    parts = []\n\n    if query.user_name:\n        parts.append(f\"Repository: {query.user_name}/{query.repo_name}\")\n    else:\n        # Local scenario\n        parts.append(f\"Directory: {query.slug}\")\n\n    if query.commit:\n        parts.append(f\"Commit: {query.commit}\")\n    elif query.branch and query.branch not in (\"main\", \"master\"):\n        parts.append(f\"Branch: {query.branch}\")\n\n    if query.subpath != \"/\" and not single_file:\n        parts.append(f\"Subpath: {query.subpath}\")\n\n    return \"\\n\".join(parts) + \"\\n\"\n\n\ndef _gather_file_contents(node: FileSystemNode) -> str:\n    \"\"\"\n    Recursively gather contents of all files under the given node.\n\n    This function recursively processes a directory node and gathers the contents of all files\n    under that node. It returns the concatenated content of all files as a single string.\n\n    Parameters\n    ----------\n    node : FileSystemNode\n        The current directory or file node being processed.\n\n    Returns\n    -------\n    str\n        The concatenated content of all files under the given node.\n    \"\"\"\n    if node.type != FileSystemNodeType.DIRECTORY:\n        return node.content_string\n\n    # Recursively gather contents of all files under the current directory\n    return \"\\n\".join(_gather_file_contents(child) for child in node.children)\n\n\ndef _create_tree_structure(query: IngestionQuery, node: FileSystemNode, prefix: str = \"\", is_last: bool = True) -> str:\n    \"\"\"\n    Generate a tree-like string representation of the file structure.\n\n    This function generates a string representation of the directory structure, formatted\n    as a tree with appropriate indentation for nested directories and files.\n\n    Parameters\n    ----------\n    query : IngestionQuery\n        The parsed query object containing information about the repository and query parameters.\n    node : FileSystemNode\n        The current directory or file node being processed.\n    prefix : str\n        A string used for indentation and formatting of the tree structure, by default \"\".\n    is_last : bool\n        A flag indicating whether the current node is the last in its directory, by default True.\n\n    Returns\n    -------\n    str\n        A string representing the directory structure formatted as a tree.\n    \"\"\"\n    if not node.name:\n        # If no name is present, use the slug as the top-level directory name\n        node.name = query.slug\n\n    tree_str = \"\"\n    current_prefix = \"â””â”€â”€ \" if is_last else \"â”œâ”€â”€ \"\n\n    # Indicate directories with a trailing slash\n    display_name = node.name\n    if node.type == FileSystemNodeType.DIRECTORY:\n        display_name += \"/\"\n    elif node.type == FileSystemNodeType.SYMLINK:\n        display_name += \" -> \" + node.path.readlink().name\n\n    tree_str += f\"{prefix}{current_prefix}{display_name}\\n\"\n\n    if node.type == FileSystemNodeType.DIRECTORY and node.children:\n        prefix += \"    \" if is_last else \"â”‚   \"\n        for i, child in enumerate(node.children):\n            tree_str += _create_tree_structure(query, node=child, prefix=prefix, is_last=i == len(node.children) - 1)\n    return tree_str\n\n\ndef _format_token_count(text: str) -> Optional[str]:\n    \"\"\"\n    Return a human-readable string representing the token count of the given text.\n\n    E.g., '120' -> '120', '1200' -> '1.2k', '1200000' -> '1.2M'.\n\n    Parameters\n    ----------\n    text : str\n        The text string for which the token count is to be estimated.\n\n    Returns\n    -------\n    str, optional\n        The formatted number of tokens as a string (e.g., '1.2k', '1.2M'), or `None` if an error occurs.\n    \"\"\"\n    try:\n        encoding = tiktoken.get_encoding(\"cl100k_base\")\n        total_tokens = len(encoding.encode(text, disallowed_special=()))\n    except (ValueError, UnicodeEncodeError) as exc:\n        print(exc)\n        return None\n\n    if total_tokens >= 1_000_000:\n        return f\"{total_tokens / 1_000_000:.1f}M\"\n\n    if total_tokens >= 1_000:\n        return f\"{total_tokens / 1_000:.1f}k\"\n\n    return str(total_tokens)\n\n\n\n================================================\nFile: src/gitingest/query_parsing.py\n================================================\n\"\"\"This module contains functions to parse and validate input sources and patterns.\"\"\"\n\nimport re\nimport uuid\nimport warnings\nfrom pathlib import Path\nfrom typing import List, Optional, Set, Union\nfrom urllib.parse import unquote, urlparse\n\nfrom gitingest.config import TMP_BASE_PATH\nfrom gitingest.schemas import IngestionQuery\nfrom gitingest.utils.exceptions import InvalidPatternError\nfrom gitingest.utils.git_utils import check_repo_exists, fetch_remote_branch_list\nfrom gitingest.utils.ignore_patterns import DEFAULT_IGNORE_PATTERNS\nfrom gitingest.utils.query_parser_utils import (\n    KNOWN_GIT_HOSTS,\n    _get_user_and_repo_from_path,\n    _is_valid_git_commit_hash,\n    _is_valid_pattern,\n    _normalize_pattern,\n    _validate_host,\n    _validate_url_scheme,\n)\n\n\nasync def parse_query(\n    source: str,\n    max_file_size: int,\n    from_web: bool,\n    include_patterns: Optional[Union[str, Set[str]]] = None,\n    ignore_patterns: Optional[Union[str, Set[str]]] = None,\n) -> IngestionQuery:\n    \"\"\"\n    Parse the input source (URL or path) to extract relevant details for the query.\n\n    This function parses the input source to extract details such as the username, repository name,\n    commit hash, branch name, and other relevant information. It also processes the include and ignore\n    patterns to filter the files and directories to include or exclude from the query.\n\n    Parameters\n    ----------\n    source : str\n        The source URL or file path to parse.\n    max_file_size : int\n        The maximum file size in bytes to include.\n    from_web : bool\n        Flag indicating whether the source is a web URL.\n    include_patterns : Union[str, Set[str]], optional\n        Patterns to include, by default None. Can be a set of strings or a single string.\n    ignore_patterns : Union[str, Set[str]], optional\n        Patterns to ignore, by default None. Can be a set of strings or a single string.\n\n    Returns\n    -------\n    IngestionQuery\n        A dataclass object containing the parsed details of the repository or file path.\n    \"\"\"\n\n    # Determine the parsing method based on the source type\n    if from_web or urlparse(source).scheme in (\"https\", \"http\") or any(h in source for h in KNOWN_GIT_HOSTS):\n        # We either have a full URL or a domain-less slug\n        query = await _parse_remote_repo(source)\n    else:\n        # Local path scenario\n        query = _parse_local_dir_path(source)\n\n    # Combine default ignore patterns + custom patterns\n    ignore_patterns_set = DEFAULT_IGNORE_PATTERNS.copy()\n    if ignore_patterns:\n        ignore_patterns_set.update(_parse_patterns(ignore_patterns))\n\n    # Process include patterns and override ignore patterns accordingly\n    if include_patterns:\n        parsed_include = _parse_patterns(include_patterns)\n        # Override ignore patterns with include patterns\n        ignore_patterns_set = set(ignore_patterns_set) - set(parsed_include)\n    else:\n        parsed_include = None\n\n    return IngestionQuery(\n        user_name=query.user_name,\n        repo_name=query.repo_name,\n        url=query.url,\n        subpath=query.subpath,\n        local_path=query.local_path,\n        slug=query.slug,\n        id=query.id,\n        type=query.type,\n        branch=query.branch,\n        commit=query.commit,\n        max_file_size=max_file_size,\n        ignore_patterns=ignore_patterns_set,\n        include_patterns=parsed_include,\n    )\n\n\nasync def _parse_remote_repo(source: str) -> IngestionQuery:\n    \"\"\"\n    Parse a repository URL into a structured query dictionary.\n\n    If source is:\n      - A fully qualified URL (https://gitlab.com/...), parse & verify that domain\n      - A URL missing 'https://' (gitlab.com/...), add 'https://' and parse\n      - A 'slug' (like 'pandas-dev/pandas'), attempt known domains until we find one that exists.\n\n    Parameters\n    ----------\n    source : str\n        The URL or domain-less slug to parse.\n\n    Returns\n    -------\n    IngestionQuery\n        A dictionary containing the parsed details of the repository.\n    \"\"\"\n    source = unquote(source)\n\n    # Attempt to parse\n    parsed_url = urlparse(source)\n\n    if parsed_url.scheme:\n        _validate_url_scheme(parsed_url.scheme)\n        _validate_host(parsed_url.netloc.lower())\n\n    else:  # Will be of the form 'host/user/repo' or 'user/repo'\n        tmp_host = source.split(\"/\")[0].lower()\n        if \".\" in tmp_host:\n            _validate_host(tmp_host)\n        else:\n            # No scheme, no domain => user typed \"user/repo\", so we'll guess the domain.\n            host = await try_domains_for_user_and_repo(*_get_user_and_repo_from_path(source))\n            source = f\"{host}/{source}\"\n\n        source = \"https://\" + source\n        parsed_url = urlparse(source)\n\n    host = parsed_url.netloc.lower()\n    user_name, repo_name = _get_user_and_repo_from_path(parsed_url.path)\n\n    _id = str(uuid.uuid4())\n    slug = f\"{user_name}-{repo_name}\"\n    local_path = TMP_BASE_PATH / _id / slug\n    url = f\"https://{host}/{user_name}/{repo_name}\"\n\n    parsed = IngestionQuery(\n        user_name=user_name,\n        repo_name=repo_name,\n        url=url,\n        local_path=local_path,\n        slug=slug,\n        id=_id,\n    )\n\n    remaining_parts = parsed_url.path.strip(\"/\").split(\"/\")[2:]\n\n    if not remaining_parts:\n        return parsed\n\n    possible_type = remaining_parts.pop(0)  # e.g. 'issues', 'pull', 'tree', 'blob'\n\n    # If no extra path parts, just return\n    if not remaining_parts:\n        return parsed\n\n    # If this is an issues page or pull requests, return early without processing subpath\n    if remaining_parts and possible_type in (\"issues\", \"pull\"):\n        return parsed\n\n    parsed.type = possible_type\n\n    # Commit or branch\n    commit_or_branch = remaining_parts[0]\n    if _is_valid_git_commit_hash(commit_or_branch):\n        parsed.commit = commit_or_branch\n        remaining_parts.pop(0)\n    else:\n        parsed.branch = await _configure_branch_and_subpath(remaining_parts, url)\n\n    # Subpath if anything left\n    if remaining_parts:\n        parsed.subpath += \"/\".join(remaining_parts)\n\n    return parsed\n\n\nasync def _configure_branch_and_subpath(remaining_parts: List[str], url: str) -> Optional[str]:\n    \"\"\"\n    Configure the branch and subpath based on the remaining parts of the URL.\n    Parameters\n    ----------\n    remaining_parts : List[str]\n        The remaining parts of the URL path.\n    url : str\n        The URL of the repository.\n    Returns\n    -------\n    str, optional\n        The branch name if found, otherwise None.\n\n    \"\"\"\n    try:\n        # Fetch the list of branches from the remote repository\n        branches: List[str] = await fetch_remote_branch_list(url)\n    except RuntimeError as exc:\n        warnings.warn(f\"Warning: Failed to fetch branch list: {exc}\", RuntimeWarning)\n        return remaining_parts.pop(0)\n\n    branch = []\n    while remaining_parts:\n        branch.append(remaining_parts.pop(0))\n        branch_name = \"/\".join(branch)\n        if branch_name in branches:\n            return branch_name\n\n    return None\n\n\ndef _parse_patterns(pattern: Union[str, Set[str]]) -> Set[str]:\n    \"\"\"\n    Parse and validate file/directory patterns for inclusion or exclusion.\n\n    Takes either a single pattern string or set of pattern strings and processes them into a normalized list.\n    Patterns are split on commas and spaces, validated for allowed characters, and normalized.\n\n    Parameters\n    ----------\n    pattern : Set[str] | str\n        Pattern(s) to parse - either a single string or set of strings\n\n    Returns\n    -------\n    Set[str]\n        A set of normalized patterns.\n\n    Raises\n    ------\n    InvalidPatternError\n        If any pattern contains invalid characters. Only alphanumeric characters,\n        dash (-), underscore (_), dot (.), forward slash (/), plus (+), and\n        asterisk (*) are allowed.\n    \"\"\"\n    patterns = pattern if isinstance(pattern, set) else {pattern}\n\n    parsed_patterns: Set[str] = set()\n    for p in patterns:\n        parsed_patterns = parsed_patterns.union(set(re.split(\",| \", p)))\n\n    # Remove empty string if present\n    parsed_patterns = parsed_patterns - {\"\"}\n\n    # Normalize Windows paths to Unix-style paths\n    parsed_patterns = {p.replace(\"\\\\\", \"/\") for p in parsed_patterns}\n\n    # Validate and normalize each pattern\n    for p in parsed_patterns:\n        if not _is_valid_pattern(p):\n            raise InvalidPatternError(p)\n\n    return {_normalize_pattern(p) for p in parsed_patterns}\n\n\ndef _parse_local_dir_path(path_str: str) -> IngestionQuery:\n    \"\"\"\n    Parse the given file path into a structured query dictionary.\n\n    Parameters\n    ----------\n    path_str : str\n        The file path to parse.\n\n    Returns\n    -------\n    IngestionQuery\n        A dictionary containing the parsed details of the file path.\n    \"\"\"\n    path_obj = Path(path_str).resolve()\n    slug = path_obj.name if path_str == \".\" else path_str.strip(\"/\")\n    return IngestionQuery(\n        user_name=None,\n        repo_name=None,\n        url=None,\n        local_path=path_obj,\n        slug=slug,\n        id=str(uuid.uuid4()),\n    )\n\n\nasync def try_domains_for_user_and_repo(user_name: str, repo_name: str) -> str:\n    \"\"\"\n    Attempt to find a valid repository host for the given user_name and repo_name.\n\n    Parameters\n    ----------\n    user_name : str\n        The username or owner of the repository.\n    repo_name : str\n        The name of the repository.\n\n    Returns\n    -------\n    str\n        The domain of the valid repository host.\n\n    Raises\n    ------\n    ValueError\n        If no valid repository host is found for the given user_name and repo_name.\n    \"\"\"\n    for domain in KNOWN_GIT_HOSTS:\n        candidate = f\"https://{domain}/{user_name}/{repo_name}\"\n        if await check_repo_exists(candidate):\n            return domain\n    raise ValueError(f\"Could not find a valid repository host for '{user_name}/{repo_name}'.\")\n\n\n\n================================================\nFile: src/gitingest/schemas/__init__.py\n================================================\n\"\"\"This module contains the schemas for the Gitingest package.\"\"\"\n\nfrom gitingest.schemas.filesystem_schema import FileSystemNode, FileSystemNodeType, FileSystemStats\nfrom gitingest.schemas.ingestion_schema import CloneConfig, IngestionQuery\n\n__all__ = [\"FileSystemNode\", \"FileSystemNodeType\", \"FileSystemStats\", \"CloneConfig\", \"IngestionQuery\"]\n\n\n\n================================================\nFile: src/gitingest/schemas/filesystem_schema.py\n================================================\n\"\"\"Define the schema for the filesystem representation.\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nfrom dataclasses import dataclass, field\nfrom enum import Enum, auto\nfrom pathlib import Path\n\nfrom gitingest.utils.file_utils import get_preferred_encodings, is_text_file\nfrom gitingest.utils.notebook_utils import process_notebook\n\nSEPARATOR = \"=\" * 48  # Tiktoken, the tokenizer openai uses, counts 2 tokens if we have more than 48\n\n\nclass FileSystemNodeType(Enum):\n    \"\"\"Enum representing the type of a file system node (directory or file).\"\"\"\n\n    DIRECTORY = auto()\n    FILE = auto()\n    SYMLINK = auto()\n\n\n@dataclass\nclass FileSystemStats:\n    \"\"\"Class for tracking statistics during file system traversal.\"\"\"\n\n    visited: set[Path] = field(default_factory=set)\n    total_files: int = 0\n    total_size: int = 0\n\n\n@dataclass\nclass FileSystemNode:  # pylint: disable=too-many-instance-attributes\n    \"\"\"\n    Class representing a node in the file system (either a file or directory).\n\n    Tracks properties of files/directories for comprehensive analysis.\n    \"\"\"\n\n    name: str\n    type: FileSystemNodeType\n    path_str: str\n    path: Path\n    size: int = 0\n    file_count: int = 0\n    dir_count: int = 0\n    depth: int = 0\n    children: list[FileSystemNode] = field(default_factory=list)\n\n    def sort_children(self) -> None:\n        \"\"\"\n        Sort the children nodes of a directory according to a specific order.\n\n        Order of sorting:\n          2. Regular files (not starting with dot)\n          3. Hidden files (starting with dot)\n          4. Regular directories (not starting with dot)\n          5. Hidden directories (starting with dot)\n\n        All groups are sorted alphanumerically within themselves.\n\n        Raises\n        ------\n        ValueError\n            If the node is not a directory.\n        \"\"\"\n        if self.type != FileSystemNodeType.DIRECTORY:\n            raise ValueError(\"Cannot sort children of a non-directory node\")\n\n        def _sort_key(child: FileSystemNode) -> tuple[int, str]:\n            # returns the priority order for the sort function, 0 is first\n            # Groups: 0=README, 1=regular file, 2=hidden file, 3=regular dir, 4=hidden dir\n            name = child.name.lower()\n            if child.type == FileSystemNodeType.FILE:\n                if name == \"readme.md\":\n                    return (0, name)\n                return (1 if not name.startswith(\".\") else 2, name)\n            return (3 if not name.startswith(\".\") else 4, name)\n\n        self.children.sort(key=_sort_key)\n\n    @property\n    def content_string(self) -> str:\n        \"\"\"\n        Return the content of the node as a string, including path and content.\n\n        Returns\n        -------\n        str\n            A string representation of the node's content.\n        \"\"\"\n        parts = [\n            SEPARATOR,\n            f\"{self.type.name}: {str(self.path_str).replace(os.sep, '/')}\"\n            + (f\" -> {self.path.readlink().name}\" if self.type == FileSystemNodeType.SYMLINK else \"\"),\n            SEPARATOR,\n            f\"{self.content}\",\n        ]\n\n        return \"\\n\".join(parts) + \"\\n\\n\"\n\n    @property\n    def content(self) -> str:  # pylint: disable=too-many-return-statements\n        \"\"\"\n        Read the content of a file if it's text (or a notebook). Return an error message otherwise.\n\n        Returns\n        -------\n        str\n            The content of the file, or an error message if the file could not be read.\n\n        Raises\n        ------\n        ValueError\n            If the node is a directory.\n        \"\"\"\n        if self.type == FileSystemNodeType.DIRECTORY:\n            raise ValueError(\"Cannot read content of a directory node\")\n\n        if self.type == FileSystemNodeType.SYMLINK:\n            return \"\"\n\n        if not is_text_file(self.path):\n            return \"[Non-text file]\"\n\n        if self.path.suffix == \".ipynb\":\n            try:\n                return process_notebook(self.path)\n            except Exception as exc:\n                return f\"Error processing notebook: {exc}\"\n\n        # Try multiple encodings\n        for encoding in get_preferred_encodings():\n            try:\n                with self.path.open(encoding=encoding) as f:\n                    return f.read()\n            except UnicodeDecodeError:\n                continue\n            except UnicodeError:\n                continue\n            except OSError as exc:\n                return f\"Error reading file: {exc}\"\n\n        return \"Error: Unable to decode file with available encodings\"\n\n\n\n================================================\nFile: src/gitingest/schemas/ingestion_schema.py\n================================================\n\"\"\"This module contains the dataclasses for the ingestion process.\"\"\"\n\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import Optional, Set\n\nfrom pydantic import BaseModel, ConfigDict, Field\n\nfrom gitingest.config import MAX_FILE_SIZE\n\n\n@dataclass\nclass CloneConfig:\n    \"\"\"\n    Configuration for cloning a Git repository.\n\n    This class holds the necessary parameters for cloning a repository to a local path, including\n    the repository's URL, the target local path, and optional parameters for a specific commit or branch.\n\n    Attributes\n    ----------\n    url : str\n        The URL of the Git repository to clone.\n    local_path : str\n        The local directory where the repository will be cloned.\n    commit : str, optional\n        The specific commit hash to check out after cloning (default is None).\n    branch : str, optional\n        The branch to clone (default is None).\n    subpath : str\n        The subpath to clone from the repository (default is \"/\").\n    \"\"\"\n\n    url: str\n    local_path: str\n    commit: Optional[str] = None\n    branch: Optional[str] = None\n    subpath: str = \"/\"\n    blob: bool = False\n\n\nclass IngestionQuery(BaseModel):  # pylint: disable=too-many-instance-attributes\n    \"\"\"\n    Pydantic model to store the parsed details of the repository or file path.\n    \"\"\"\n\n    user_name: Optional[str] = None\n    repo_name: Optional[str] = None\n    local_path: Path\n    url: Optional[str] = None\n    slug: str\n    id: str\n    subpath: str = \"/\"\n    type: Optional[str] = None\n    branch: Optional[str] = None\n    commit: Optional[str] = None\n    max_file_size: int = Field(default=MAX_FILE_SIZE)\n    ignore_patterns: Optional[Set[str]] = None\n    include_patterns: Optional[Set[str]] = None\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    def extract_clone_config(self) -> CloneConfig:\n        \"\"\"\n        Extract the relevant fields for the CloneConfig object.\n\n        Returns\n        -------\n        CloneConfig\n            A CloneConfig object containing the relevant fields.\n\n        Raises\n        ------\n        ValueError\n            If the 'url' parameter is not provided.\n        \"\"\"\n        if not self.url:\n            raise ValueError(\"The 'url' parameter is required.\")\n\n        return CloneConfig(\n            url=self.url,\n            local_path=str(self.local_path),\n            commit=self.commit,\n            branch=self.branch,\n            subpath=self.subpath,\n            blob=self.type == \"blob\",\n        )\n\n\n\n================================================\nFile: src/gitingest/utils/__init__.py\n================================================\n\n\n\n================================================\nFile: src/gitingest/utils/exceptions.py\n================================================\n\"\"\"Custom exceptions for the Gitingest package.\"\"\"\n\n\nclass InvalidPatternError(ValueError):\n    \"\"\"\n    Exception raised when a pattern contains invalid characters.\n    This exception is used to signal that a pattern provided for some operation\n    contains characters that are not allowed. The valid characters for the pattern\n    include alphanumeric characters, dash (-), underscore (_), dot (.), forward slash (/),\n    plus (+), and asterisk (*).\n    Parameters\n    ----------\n    pattern : str\n        The invalid pattern that caused the error.\n    \"\"\"\n\n    def __init__(self, pattern: str) -> None:\n        super().__init__(\n            f\"Pattern '{pattern}' contains invalid characters. Only alphanumeric characters, dash (-), \"\n            \"underscore (_), dot (.), forward slash (/), plus (+), and asterisk (*) are allowed.\"\n        )\n\n\nclass AsyncTimeoutError(Exception):\n    \"\"\"\n    Exception raised when an async operation exceeds its timeout limit.\n\n    This exception is used by the `async_timeout` decorator to signal that the wrapped\n    asynchronous function has exceeded the specified time limit for execution.\n    \"\"\"\n\n\nclass InvalidNotebookError(Exception):\n    \"\"\"Exception raised when a Jupyter notebook is invalid or cannot be processed.\"\"\"\n\n    def __init__(self, message: str) -> None:\n        super().__init__(message)\n\n\n\n================================================\nFile: src/gitingest/utils/file_utils.py\n================================================\n\"\"\"Utility functions for working with files and directories.\"\"\"\n\nimport locale\nimport platform\nfrom pathlib import Path\nfrom typing import List\n\ntry:\n    locale.setlocale(locale.LC_ALL, \"\")\nexcept locale.Error:\n    locale.setlocale(locale.LC_ALL, \"C\")\n\n\ndef get_preferred_encodings() -> List[str]:\n    \"\"\"\n    Get list of encodings to try, prioritized for the current platform.\n\n    Returns\n    -------\n    List[str]\n        List of encoding names to try in priority order, starting with the\n        platform's default encoding followed by common fallback encodings.\n    \"\"\"\n    encodings = [locale.getpreferredencoding(), \"utf-8\", \"utf-16\", \"utf-16le\", \"utf-8-sig\", \"latin\"]\n    if platform.system() == \"Windows\":\n        encodings += [\"cp1252\", \"iso-8859-1\"]\n    return encodings\n\n\ndef is_text_file(path: Path) -> bool:\n    \"\"\"\n    Determine if the file is likely a text file by trying to decode a small chunk\n    with multiple encodings, and checking for common binary markers.\n\n    Parameters\n    ----------\n    path : Path\n        The path to the file to check.\n\n    Returns\n    -------\n    bool\n        True if the file is likely textual; False if it appears to be binary.\n    \"\"\"\n\n    # Attempt to read a portion of the file in binary mode\n    try:\n        with path.open(\"rb\") as f:\n            chunk = f.read(1024)\n    except OSError:\n        return False\n\n    # If file is empty, treat as text\n    if not chunk:\n        return True\n\n    # Check obvious binary bytes\n    if b\"\\x00\" in chunk or b\"\\xff\" in chunk:\n        return False\n\n    # Attempt multiple encodings\n    for enc in get_preferred_encodings():\n        try:\n            with path.open(encoding=enc) as f:\n                f.read()\n                return True\n        except UnicodeDecodeError:\n            continue\n        except UnicodeError:\n            continue\n        except OSError:\n            return False\n\n    return False\n\n\n\n================================================\nFile: src/gitingest/utils/git_utils.py\n================================================\n\"\"\"Utility functions for interacting with Git repositories.\"\"\"\n\nimport asyncio\nfrom typing import List, Tuple\n\n\nasync def run_command(*args: str) -> Tuple[bytes, bytes]:\n    \"\"\"\n    Execute a shell command asynchronously and return (stdout, stderr) bytes.\n\n    Parameters\n    ----------\n    *args : str\n        The command and its arguments to execute.\n\n    Returns\n    -------\n    Tuple[bytes, bytes]\n        A tuple containing the stdout and stderr of the command.\n\n    Raises\n    ------\n    RuntimeError\n        If command exits with a non-zero status.\n    \"\"\"\n    # Execute the requested command\n    proc = await asyncio.create_subprocess_exec(\n        *args,\n        stdout=asyncio.subprocess.PIPE,\n        stderr=asyncio.subprocess.PIPE,\n    )\n    stdout, stderr = await proc.communicate()\n    if proc.returncode != 0:\n        error_message = stderr.decode().strip()\n        raise RuntimeError(f\"Command failed: {' '.join(args)}\\nError: {error_message}\")\n\n    return stdout, stderr\n\n\nasync def ensure_git_installed() -> None:\n    \"\"\"\n    Ensure Git is installed and accessible on the system.\n\n    Raises\n    ------\n    RuntimeError\n        If Git is not installed or not accessible.\n    \"\"\"\n    try:\n        await run_command(\"git\", \"--version\")\n    except RuntimeError as exc:\n        raise RuntimeError(\"Git is not installed or not accessible. Please install Git first.\") from exc\n\n\nasync def check_repo_exists(url: str) -> bool:\n    \"\"\"\n    Check if a Git repository exists at the provided URL.\n\n    Parameters\n    ----------\n    url : str\n        The URL of the Git repository to check.\n    Returns\n    -------\n    bool\n        True if the repository exists, False otherwise.\n\n    Raises\n    ------\n    RuntimeError\n        If the curl command returns an unexpected status code.\n    \"\"\"\n    proc = await asyncio.create_subprocess_exec(\n        \"curl\",\n        \"-I\",\n        url,\n        stdout=asyncio.subprocess.PIPE,\n        stderr=asyncio.subprocess.PIPE,\n    )\n    stdout, _ = await proc.communicate()\n\n    if proc.returncode != 0:\n        return False  # likely unreachable or private\n\n    response = stdout.decode()\n    status_line = response.splitlines()[0].strip()\n    parts = status_line.split(\" \")\n    if len(parts) >= 2:\n        status_code_str = parts[1]\n        if status_code_str in (\"200\", \"301\"):\n            return True\n        if status_code_str in (\"302\", \"404\"):\n            return False\n    raise RuntimeError(f\"Unexpected status line: {status_line}\")\n\n\nasync def fetch_remote_branch_list(url: str) -> List[str]:\n    \"\"\"\n    Fetch the list of branches from a remote Git repository.\n    Parameters\n    ----------\n    url : str\n        The URL of the Git repository to fetch branches from.\n    Returns\n    -------\n    List[str]\n        A list of branch names available in the remote repository.\n    \"\"\"\n    fetch_branches_command = [\"git\", \"ls-remote\", \"--heads\", url]\n    await ensure_git_installed()\n    stdout, _ = await run_command(*fetch_branches_command)\n    stdout_decoded = stdout.decode()\n\n    return [\n        line.split(\"refs/heads/\", 1)[1]\n        for line in stdout_decoded.splitlines()\n        if line.strip() and \"refs/heads/\" in line\n    ]\n\n\n\n================================================\nFile: src/gitingest/utils/ignore_patterns.py\n================================================\n\"\"\"Default ignore patterns for Gitingest.\"\"\"\n\nfrom typing import Set\n\nDEFAULT_IGNORE_PATTERNS: Set[str] = {\n    # Python\n    \"*.pyc\",\n    \"*.pyo\",\n    \"*.pyd\",\n    \"__pycache__\",\n    \".pytest_cache\",\n    \".coverage\",\n    \".tox\",\n    \".nox\",\n    \".mypy_cache\",\n    \".ruff_cache\",\n    \".hypothesis\",\n    \"poetry.lock\",\n    \"Pipfile.lock\",\n    # JavaScript/FileSystemNode\n    \"node_modules\",\n    \"bower_components\",\n    \"package-lock.json\",\n    \"yarn.lock\",\n    \".npm\",\n    \".yarn\",\n    \".pnpm-store\",\n    \"bun.lock\",\n    \"bun.lockb\",\n    # Java\n    \"*.class\",\n    \"*.jar\",\n    \"*.war\",\n    \"*.ear\",\n    \"*.nar\",\n    \".gradle/\",\n    \"build/\",\n    \".settings/\",\n    \".classpath\",\n    \"gradle-app.setting\",\n    \"*.gradle\",\n    # IDEs and editors / Java\n    \".project\",\n    # C/C++\n    \"*.o\",\n    \"*.obj\",\n    \"*.dll\",\n    \"*.dylib\",\n    \"*.exe\",\n    \"*.lib\",\n    \"*.out\",\n    \"*.a\",\n    \"*.pdb\",\n    # Swift/Xcode\n    \".build/\",\n    \"*.xcodeproj/\",\n    \"*.xcworkspace/\",\n    \"*.pbxuser\",\n    \"*.mode1v3\",\n    \"*.mode2v3\",\n    \"*.perspectivev3\",\n    \"*.xcuserstate\",\n    \"xcuserdata/\",\n    \".swiftpm/\",\n    # Ruby\n    \"*.gem\",\n    \".bundle/\",\n    \"vendor/bundle\",\n    \"Gemfile.lock\",\n    \".ruby-version\",\n    \".ruby-gemset\",\n    \".rvmrc\",\n    # Rust\n    \"Cargo.lock\",\n    \"**/*.rs.bk\",\n    # Java / Rust\n    \"target/\",\n    # Go\n    \"pkg/\",\n    # .NET/C#\n    \"obj/\",\n    \"*.suo\",\n    \"*.user\",\n    \"*.userosscache\",\n    \"*.sln.docstates\",\n    \"packages/\",\n    \"*.nupkg\",\n    # Go / .NET / C#\n    \"bin/\",\n    # Version control\n    \".git\",\n    \".svn\",\n    \".hg\",\n    \".gitignore\",\n    \".gitattributes\",\n    \".gitmodules\",\n    # Images and media\n    \"*.svg\",\n    \"*.png\",\n    \"*.jpg\",\n    \"*.jpeg\",\n    \"*.gif\",\n    \"*.ico\",\n    \"*.pdf\",\n    \"*.mov\",\n    \"*.mp4\",\n    \"*.mp3\",\n    \"*.wav\",\n    # Virtual environments\n    \"venv\",\n    \".venv\",\n    \"env\",\n    \".env\",\n    \"virtualenv\",\n    # IDEs and editors\n    \".idea\",\n    \".vscode\",\n    \".vs\",\n    \"*.swo\",\n    \"*.swn\",\n    \".settings\",\n    \"*.sublime-*\",\n    # Temporary and cache files\n    \"*.log\",\n    \"*.bak\",\n    \"*.swp\",\n    \"*.tmp\",\n    \"*.temp\",\n    \".cache\",\n    \".sass-cache\",\n    \".eslintcache\",\n    \".DS_Store\",\n    \"Thumbs.db\",\n    \"desktop.ini\",\n    # Build directories and artifacts\n    \"build\",\n    \"dist\",\n    \"target\",\n    \"out\",\n    \"*.egg-info\",\n    \"*.egg\",\n    \"*.whl\",\n    \"*.so\",\n    # Documentation\n    \"site-packages\",\n    \".docusaurus\",\n    \".next\",\n    \".nuxt\",\n    # Other common patterns\n    ## Minified files\n    \"*.min.js\",\n    \"*.min.css\",\n    ## Source maps\n    \"*.map\",\n    ## Terraform\n    \".terraform\",\n    \"*.tfstate*\",\n    ## Dependencies in various languages\n    \"vendor/\",\n    # Gitingest\n    \"digest.txt\",\n}\n\n\n\n================================================\nFile: src/gitingest/utils/ingestion_utils.py\n================================================\n\"\"\"Utility functions for the ingestion process.\"\"\"\n\nfrom fnmatch import fnmatch\nfrom pathlib import Path\nfrom typing import Set\n\n\ndef _should_include(path: Path, base_path: Path, include_patterns: Set[str]) -> bool:\n    \"\"\"\n    Determine if the given file or directory path matches any of the include patterns.\n\n    This function checks whether the relative path of a file or directory matches any of the specified patterns. If a\n    match is found, it returns `True`, indicating that the file or directory should be included in further processing.\n\n    Parameters\n    ----------\n    path : Path\n        The absolute path of the file or directory to check.\n    base_path : Path\n        The base directory from which the relative path is calculated.\n    include_patterns : Set[str]\n        A set of patterns to check against the relative path.\n\n    Returns\n    -------\n    bool\n        `True` if the path matches any of the include patterns, `False` otherwise.\n    \"\"\"\n    try:\n        rel_path = path.relative_to(base_path)\n    except ValueError:\n        # If path is not under base_path at all\n        return False\n\n    rel_str = str(rel_path)\n    if path.is_dir():\n        rel_str += \"/\"\n\n    for pattern in include_patterns:\n        if fnmatch(rel_str, pattern):\n            return True\n    return False\n\n\ndef _should_exclude(path: Path, base_path: Path, ignore_patterns: Set[str]) -> bool:\n    \"\"\"\n    Determine if the given file or directory path matches any of the ignore patterns.\n\n    This function checks whether the relative path of a file or directory matches\n    any of the specified ignore patterns. If a match is found, it returns `True`, indicating\n    that the file or directory should be excluded from further processing.\n\n    Parameters\n    ----------\n    path : Path\n        The absolute path of the file or directory to check.\n    base_path : Path\n        The base directory from which the relative path is calculated.\n    ignore_patterns : Set[str]\n        A set of patterns to check against the relative path.\n\n    Returns\n    -------\n    bool\n        `True` if the path matches any of the ignore patterns, `False` otherwise.\n    \"\"\"\n    try:\n        rel_path = path.relative_to(base_path)\n    except ValueError:\n        # If path is not under base_path at all\n        return True\n\n    rel_str = str(rel_path)\n    for pattern in ignore_patterns:\n        if pattern and fnmatch(rel_str, pattern):\n            return True\n    return False\n\n\n\n================================================\nFile: src/gitingest/utils/notebook_utils.py\n================================================\n\"\"\"Utilities for processing Jupyter notebooks.\"\"\"\n\nimport json\nimport warnings\nfrom itertools import chain\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Optional\n\nfrom gitingest.utils.exceptions import InvalidNotebookError\n\n\ndef process_notebook(file: Path, include_output: bool = True) -> str:\n    \"\"\"\n    Process a Jupyter notebook file and return an executable Python script as a string.\n\n    Parameters\n    ----------\n    file : Path\n        The path to the Jupyter notebook file.\n    include_output : bool\n        Whether to include cell outputs in the generated script, by default True.\n\n    Returns\n    -------\n    str\n        The executable Python script as a string.\n\n    Raises\n    ------\n    InvalidNotebookError\n        If the notebook file is invalid or cannot be processed.\n    \"\"\"\n    try:\n        with file.open(encoding=\"utf-8\") as f:\n            notebook: Dict[str, Any] = json.load(f)\n    except json.JSONDecodeError as exc:\n        raise InvalidNotebookError(f\"Invalid JSON in notebook: {file}\") from exc\n\n    # Check if the notebook contains worksheets\n    worksheets = notebook.get(\"worksheets\")\n    if worksheets:\n        warnings.warn(\n            \"Worksheets are deprecated as of IPEP-17. Consider updating the notebook. \"\n            \"(See: https://github.com/jupyter/nbformat and \"\n            \"https://github.com/ipython/ipython/wiki/IPEP-17:-Notebook-Format-4#remove-multiple-worksheets \"\n            \"for more information.)\",\n            DeprecationWarning,\n        )\n\n        if len(worksheets) > 1:\n            warnings.warn(\"Multiple worksheets detected. Combining all worksheets into a single script.\", UserWarning)\n\n        cells = list(chain.from_iterable(ws[\"cells\"] for ws in worksheets))\n\n    else:\n        cells = notebook[\"cells\"]\n\n    result = [\"# Jupyter notebook converted to Python script.\"]\n\n    for cell in cells:\n        cell_str = _process_cell(cell, include_output=include_output)\n        if cell_str:\n            result.append(cell_str)\n\n    return \"\\n\\n\".join(result) + \"\\n\"\n\n\ndef _process_cell(cell: Dict[str, Any], include_output: bool) -> Optional[str]:\n    \"\"\"\n    Process a Jupyter notebook cell and return the cell content as a string.\n\n    Parameters\n    ----------\n    cell : Dict[str, Any]\n        The cell dictionary from a Jupyter notebook.\n    include_output : bool\n        Whether to include cell outputs in the generated script\n\n    Returns\n    -------\n    str, optional\n        The cell content as a string, or None if the cell is empty.\n\n    Raises\n    ------\n    ValueError\n        If an unexpected cell type is encountered.\n    \"\"\"\n    cell_type = cell[\"cell_type\"]\n\n    # Validate cell type and handle unexpected types\n    if cell_type not in (\"markdown\", \"code\", \"raw\"):\n        raise ValueError(f\"Unknown cell type: {cell_type}\")\n\n    cell_str = \"\".join(cell[\"source\"])\n\n    # Skip empty cells\n    if not cell_str:\n        return None\n\n    # Convert Markdown and raw cells to multi-line comments\n    if cell_type in (\"markdown\", \"raw\"):\n        return f'\"\"\"\\n{cell_str}\\n\"\"\"'\n\n    # Add cell output as comments\n    outputs = cell.get(\"outputs\")\n    if include_output and outputs:\n\n        # Include cell outputs as comments\n        output_lines = []\n\n        for output in outputs:\n            output_lines += _extract_output(output)\n\n        for output_line in output_lines:\n            if not output_line.endswith(\"\\n\"):\n                output_line += \"\\n\"\n\n        cell_str += \"\\n# Output:\\n#   \" + \"\\n#   \".join(output_lines)\n\n    return cell_str\n\n\ndef _extract_output(output: Dict[str, Any]) -> List[str]:\n    \"\"\"\n    Extract the output from a Jupyter notebook cell.\n\n    Parameters\n    ----------\n    output : Dict[str, Any]\n        The output dictionary from a Jupyter notebook cell.\n\n    Returns\n    -------\n    List[str]\n        The output as a list of strings.\n\n    Raises\n    ------\n    ValueError\n        If an unknown output type is encountered.\n    \"\"\"\n    output_type = output[\"output_type\"]\n\n    if output_type == \"stream\":\n        return output[\"text\"]\n\n    if output_type in (\"execute_result\", \"display_data\"):\n        return output[\"data\"][\"text/plain\"]\n\n    if output_type == \"error\":\n        return [f\"Error: {output['ename']}: {output['evalue']}\"]\n\n    raise ValueError(f\"Unknown output type: {output_type}\")\n\n\n\n================================================\nFile: src/gitingest/utils/path_utils.py\n================================================\n\"\"\"Utility functions for working with file paths.\"\"\"\n\nimport os\nimport platform\nfrom pathlib import Path\n\n\ndef _is_safe_symlink(symlink_path: Path, base_path: Path) -> bool:\n    \"\"\"\n    Check if a symlink points to a location within the base directory.\n\n    This function resolves the target of a symlink and ensures it is within the specified\n    base directory, returning `True` if it is safe, or `False` if the symlink points outside\n    the base directory.\n\n    Parameters\n    ----------\n    symlink_path : Path\n        The path of the symlink to check.\n    base_path : Path\n        The base directory to ensure the symlink points within.\n\n    Returns\n    -------\n    bool\n        `True` if the symlink points within the base directory, `False` otherwise.\n    \"\"\"\n    try:\n        if platform.system() == \"Windows\":\n            if not os.path.islink(str(symlink_path)):\n                return False\n\n        target_path = symlink_path.resolve()\n        base_resolved = base_path.resolve()\n\n        return base_resolved in target_path.parents or target_path == base_resolved\n    except (OSError, ValueError):\n        # If there's any error resolving the paths, consider it unsafe\n        return False\n\n\n\n================================================\nFile: src/gitingest/utils/query_parser_utils.py\n================================================\n\"\"\"Utility functions for parsing and validating query parameters.\"\"\"\n\nimport os\nimport string\nfrom typing import List, Set, Tuple\n\nHEX_DIGITS: Set[str] = set(string.hexdigits)\n\n\nKNOWN_GIT_HOSTS: List[str] = [\n    \"github.com\",\n    \"gitlab.com\",\n    \"bitbucket.org\",\n    \"gitea.com\",\n    \"codeberg.org\",\n    \"gist.github.com\",\n]\n\n\ndef _is_valid_git_commit_hash(commit: str) -> bool:\n    \"\"\"\n    Validate if the provided string is a valid Git commit hash.\n\n    This function checks if the commit hash is a 40-character string consisting only\n    of hexadecimal digits, which is the standard format for Git commit hashes.\n\n    Parameters\n    ----------\n    commit : str\n        The string to validate as a Git commit hash.\n\n    Returns\n    -------\n    bool\n        True if the string is a valid 40-character Git commit hash, otherwise False.\n    \"\"\"\n    return len(commit) == 40 and all(c in HEX_DIGITS for c in commit)\n\n\ndef _is_valid_pattern(pattern: str) -> bool:\n    \"\"\"\n    Validate if the given pattern contains only valid characters.\n\n    This function checks if the pattern contains only alphanumeric characters or one\n    of the following allowed characters: dash (`-`), underscore (`_`), dot (`.`),\n    forward slash (`/`), plus (`+`), asterisk (`*`), or the at sign (`@`).\n\n    Parameters\n    ----------\n    pattern : str\n        The pattern to validate.\n\n    Returns\n    -------\n    bool\n        True if the pattern is valid, otherwise False.\n    \"\"\"\n    return all(c.isalnum() or c in \"-_./+*@\" for c in pattern)\n\n\ndef _validate_host(host: str) -> None:\n    \"\"\"\n    Validate the given host against the known Git hosts.\n\n    Parameters\n    ----------\n    host : str\n        The host to validate.\n\n    Raises\n    ------\n    ValueError\n        If the host is not a known Git host.\n    \"\"\"\n    if host not in KNOWN_GIT_HOSTS:\n        raise ValueError(f\"Unknown domain '{host}' in URL\")\n\n\ndef _validate_url_scheme(scheme: str) -> None:\n    \"\"\"\n    Validate the given scheme against the known schemes.\n\n    Parameters\n    ----------\n    scheme : str\n        The scheme to validate.\n\n    Raises\n    ------\n    ValueError\n        If the scheme is not 'http' or 'https'.\n    \"\"\"\n    if scheme not in (\"https\", \"http\"):\n        raise ValueError(f\"Invalid URL scheme '{scheme}' in URL\")\n\n\ndef _get_user_and_repo_from_path(path: str) -> Tuple[str, str]:\n    \"\"\"\n    Extract the user and repository names from a given path.\n\n    Parameters\n    ----------\n    path : str\n        The path to extract the user and repository names from.\n\n    Returns\n    -------\n    Tuple[str, str]\n        A tuple containing the user and repository names.\n\n    Raises\n    ------\n    ValueError\n        If the path does not contain at least two parts.\n    \"\"\"\n    path_parts = path.lower().strip(\"/\").split(\"/\")\n    if len(path_parts) < 2:\n        raise ValueError(f\"Invalid repository URL '{path}'\")\n    return path_parts[0], path_parts[1]\n\n\ndef _normalize_pattern(pattern: str) -> str:\n    \"\"\"\n    Normalize the given pattern by removing leading separators and appending a wildcard.\n\n    This function processes the pattern string by stripping leading directory separators\n    and appending a wildcard (`*`) if the pattern ends with a separator.\n\n    Parameters\n    ----------\n    pattern : str\n        The pattern to normalize.\n\n    Returns\n    -------\n    str\n        The normalized pattern.\n    \"\"\"\n    pattern = pattern.lstrip(os.sep)\n    if pattern.endswith(os.sep):\n        pattern += \"*\"\n    return pattern\n\n\n\n================================================\nFile: src/gitingest/utils/timeout_wrapper.py\n================================================\n\"\"\"Utility functions for the Gitingest package.\"\"\"\n\nimport asyncio\nimport functools\nfrom typing import Any, Awaitable, Callable, TypeVar\n\nfrom gitingest.utils.exceptions import AsyncTimeoutError\n\nT = TypeVar(\"T\")\n\n\ndef async_timeout(seconds) -> Callable[[Callable[..., Awaitable[T]]], Callable[..., Awaitable[T]]]:\n    \"\"\"\n    Async Timeout decorator.\n\n    This decorator wraps an asynchronous function and ensures it does not run for\n    longer than the specified number of seconds. If the function execution exceeds\n    this limit, it raises an `AsyncTimeoutError`.\n\n    Parameters\n    ----------\n    seconds : int\n        The maximum allowed time (in seconds) for the asynchronous function to complete.\n\n    Returns\n    -------\n    Callable[[Callable[..., Awaitable[T]]], Callable[..., Awaitable[T]]]\n        A decorator that, when applied to an async function, ensures the function\n        completes within the specified time limit. If the function takes too long,\n        an `AsyncTimeoutError` is raised.\n    \"\"\"\n\n    def decorator(func: Callable[..., Awaitable[T]]) -> Callable[..., Awaitable[T]]:\n        @functools.wraps(func)\n        async def wrapper(*args: Any, **kwargs: Any) -> T:\n            try:\n                return await asyncio.wait_for(func(*args, **kwargs), timeout=seconds)\n            except asyncio.TimeoutError as exc:\n                raise AsyncTimeoutError(f\"Operation timed out after {seconds} seconds\") from exc\n\n        return wrapper\n\n    return decorator\n\n\n\n================================================\nFile: src/server/__init__.py\n================================================\n\n\n\n================================================\nFile: src/server/main.py\n================================================\n\"\"\"Main module for the FastAPI application.\"\"\"\n\nimport os\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom dotenv import load_dotenv\nfrom fastapi import FastAPI, Request\nfrom fastapi.responses import FileResponse, HTMLResponse\nfrom fastapi.staticfiles import StaticFiles\nfrom slowapi.errors import RateLimitExceeded\nfrom starlette.middleware.trustedhost import TrustedHostMiddleware\n\nfrom server.routers import download, dynamic, index\nfrom server.server_config import templates\nfrom server.server_utils import lifespan, limiter, rate_limit_exception_handler\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Initialize the FastAPI application with lifespan\napp = FastAPI(lifespan=lifespan)\napp.state.limiter = limiter\n\n# Register the custom exception handler for rate limits\napp.add_exception_handler(RateLimitExceeded, rate_limit_exception_handler)\n\n\n# Mount static files dynamically to serve CSS, JS, and other static assets\nstatic_dir = Path(__file__).parent.parent / \"static\"\napp.mount(\"/static\", StaticFiles(directory=static_dir), name=\"static\")\n\n\n# Fetch allowed hosts from the environment or use the default values\nallowed_hosts = os.getenv(\"ALLOWED_HOSTS\")\nif allowed_hosts:\n    allowed_hosts = allowed_hosts.split(\",\")\nelse:\n    # Define the default allowed hosts for the application\n    default_allowed_hosts = [\"gitingest.com\", \"*.gitingest.com\", \"localhost\", \"127.0.0.1\"]\n    allowed_hosts = default_allowed_hosts\n\n# Add middleware to enforce allowed hosts\napp.add_middleware(TrustedHostMiddleware, allowed_hosts=allowed_hosts)\n\n\n@app.get(\"/health\")\nasync def health_check() -> Dict[str, str]:\n    \"\"\"\n    Health check endpoint to verify that the server is running.\n\n    Returns\n    -------\n    Dict[str, str]\n        A JSON object with a \"status\" key indicating the server's health status.\n    \"\"\"\n    return {\"status\": \"healthy\"}\n\n\n@app.head(\"/\")\nasync def head_root() -> HTMLResponse:\n    \"\"\"\n    Respond to HTTP HEAD requests for the root URL.\n\n    Mirrors the headers and status code of the index page.\n\n    Returns\n    -------\n    HTMLResponse\n        An empty HTML response with appropriate headers.\n    \"\"\"\n    return HTMLResponse(content=None, headers={\"content-type\": \"text/html; charset=utf-8\"})\n\n\n@app.get(\"/api/\", response_class=HTMLResponse)\n@app.get(\"/api\", response_class=HTMLResponse)\nasync def api_docs(request: Request) -> HTMLResponse:\n    \"\"\"\n    Render the API documentation page.\n\n    Parameters\n    ----------\n    request : Request\n        The incoming HTTP request.\n\n    Returns\n    -------\n    HTMLResponse\n        A rendered HTML page displaying API documentation.\n    \"\"\"\n    return templates.TemplateResponse(\"api.jinja\", {\"request\": request})\n\n\n@app.get(\"/robots.txt\")\nasync def robots() -> FileResponse:\n    \"\"\"\n    Serve the `robots.txt` file to guide search engine crawlers.\n\n    Returns\n    -------\n    FileResponse\n        The `robots.txt` file located in the static directory.\n    \"\"\"\n    return FileResponse(\"static/robots.txt\")\n\n\n# Include routers for modular endpoints\napp.include_router(index)\napp.include_router(download)\napp.include_router(dynamic)\n\n\n\n================================================\nFile: src/server/query_processor.py\n================================================\n\"\"\"Process a query by parsing input, cloning a repository, and generating a summary.\"\"\"\n\nfrom functools import partial\n\nfrom fastapi import Request\nfrom starlette.templating import _TemplateResponse\n\nfrom gitingest.cloning import clone_repo\nfrom gitingest.ingestion import ingest_query\nfrom gitingest.query_parsing import IngestionQuery, parse_query\nfrom server.server_config import EXAMPLE_REPOS, MAX_DISPLAY_SIZE, templates\nfrom server.server_utils import Colors, log_slider_to_size\n\n\nasync def process_query(\n    request: Request,\n    input_text: str,\n    slider_position: int,\n    pattern_type: str = \"exclude\",\n    pattern: str = \"\",\n    is_index: bool = False,\n) -> _TemplateResponse:\n    \"\"\"\n    Process a query by parsing input, cloning a repository, and generating a summary.\n\n    Handle user input, process Git repository data, and prepare\n    a response for rendering a template with the processed results or an error message.\n\n    Parameters\n    ----------\n    request : Request\n        The HTTP request object.\n    input_text : str\n        Input text provided by the user, typically a Git repository URL or slug.\n    slider_position : int\n        Position of the slider, representing the maximum file size in the query.\n    pattern_type : str\n        Type of pattern to use, either \"include\" or \"exclude\" (default is \"exclude\").\n    pattern : str\n        Pattern to include or exclude in the query, depending on the pattern type.\n    is_index : bool\n        Flag indicating whether the request is for the index page (default is False).\n\n    Returns\n    -------\n    _TemplateResponse\n        Rendered template response containing the processed results or an error message.\n\n    Raises\n    ------\n    ValueError\n        If an invalid pattern type is provided.\n    \"\"\"\n    if pattern_type == \"include\":\n        include_patterns = pattern\n        exclude_patterns = None\n    elif pattern_type == \"exclude\":\n        exclude_patterns = pattern\n        include_patterns = None\n    else:\n        raise ValueError(f\"Invalid pattern type: {pattern_type}\")\n\n    template = \"index.jinja\" if is_index else \"git.jinja\"\n    template_response = partial(templates.TemplateResponse, name=template)\n    max_file_size = log_slider_to_size(slider_position)\n\n    context = {\n        \"request\": request,\n        \"repo_url\": input_text,\n        \"examples\": EXAMPLE_REPOS if is_index else [],\n        \"default_file_size\": slider_position,\n        \"pattern_type\": pattern_type,\n        \"pattern\": pattern,\n    }\n\n    try:\n        query: IngestionQuery = await parse_query(\n            source=input_text,\n            max_file_size=max_file_size,\n            from_web=True,\n            include_patterns=include_patterns,\n            ignore_patterns=exclude_patterns,\n        )\n        if not query.url:\n            raise ValueError(\"The 'url' parameter is required.\")\n\n        clone_config = query.extract_clone_config()\n        await clone_repo(clone_config)\n        summary, tree, content = ingest_query(query)\n        with open(f\"{clone_config.local_path}.txt\", \"w\", encoding=\"utf-8\") as f:\n            f.write(tree + \"\\n\" + content)\n    except Exception as exc:\n        # hack to print error message when query is not defined\n        if \"query\" in locals() and query is not None and isinstance(query, dict):\n            _print_error(query[\"url\"], exc, max_file_size, pattern_type, pattern)\n        else:\n            print(f\"{Colors.BROWN}WARN{Colors.END}: {Colors.RED}<-  {Colors.END}\", end=\"\")\n            print(f\"{Colors.RED}{exc}{Colors.END}\")\n\n        context[\"error_message\"] = f\"Error: {exc}\"\n        if \"405\" in str(exc):\n            context[\"error_message\"] = (\n                \"Repository not found. Please make sure it is public (private repositories will be supported soon)\"\n            )\n        return template_response(context=context)\n\n    if len(content) > MAX_DISPLAY_SIZE:\n        content = (\n            f\"(Files content cropped to {int(MAX_DISPLAY_SIZE / 1_000)}k characters, \"\n            \"download full ingest to see more)\\n\" + content[:MAX_DISPLAY_SIZE]\n        )\n\n    _print_success(\n        url=query.url,\n        max_file_size=max_file_size,\n        pattern_type=pattern_type,\n        pattern=pattern,\n        summary=summary,\n    )\n\n    context.update(\n        {\n            \"result\": True,\n            \"summary\": summary,\n            \"tree\": tree,\n            \"content\": content,\n            \"ingest_id\": query.id,\n        }\n    )\n\n    return template_response(context=context)\n\n\ndef _print_query(url: str, max_file_size: int, pattern_type: str, pattern: str) -> None:\n    \"\"\"\n    Print a formatted summary of the query details, including the URL, file size,\n    and pattern information, for easier debugging or logging.\n\n    Parameters\n    ----------\n    url : str\n        The URL associated with the query.\n    max_file_size : int\n        The maximum file size allowed for the query, in bytes.\n    pattern_type : str\n        Specifies the type of pattern to use, either \"include\" or \"exclude\".\n    pattern : str\n        The actual pattern string to include or exclude in the query.\n    \"\"\"\n    print(f\"{Colors.WHITE}{url:<20}{Colors.END}\", end=\"\")\n    if int(max_file_size / 1024) != 50:\n        print(f\" | {Colors.YELLOW}Size: {int(max_file_size/1024)}kb{Colors.END}\", end=\"\")\n    if pattern_type == \"include\" and pattern != \"\":\n        print(f\" | {Colors.YELLOW}Include {pattern}{Colors.END}\", end=\"\")\n    elif pattern_type == \"exclude\" and pattern != \"\":\n        print(f\" | {Colors.YELLOW}Exclude {pattern}{Colors.END}\", end=\"\")\n\n\ndef _print_error(url: str, e: Exception, max_file_size: int, pattern_type: str, pattern: str) -> None:\n    \"\"\"\n    Print a formatted error message including the URL, file size, pattern details, and the exception encountered,\n    for debugging or logging purposes.\n\n    Parameters\n    ----------\n    url : str\n        The URL associated with the query that caused the error.\n    e : Exception\n        The exception raised during the query or process.\n    max_file_size : int\n        The maximum file size allowed for the query, in bytes.\n    pattern_type : str\n        Specifies the type of pattern to use, either \"include\" or \"exclude\".\n    pattern : str\n        The actual pattern string to include or exclude in the query.\n    \"\"\"\n    print(f\"{Colors.BROWN}WARN{Colors.END}: {Colors.RED}<-  {Colors.END}\", end=\"\")\n    _print_query(url, max_file_size, pattern_type, pattern)\n    print(f\" | {Colors.RED}{e}{Colors.END}\")\n\n\ndef _print_success(url: str, max_file_size: int, pattern_type: str, pattern: str, summary: str) -> None:\n    \"\"\"\n    Print a formatted success message, including the URL, file size, pattern details, and a summary with estimated\n    tokens, for debugging or logging purposes.\n\n    Parameters\n    ----------\n    url : str\n        The URL associated with the successful query.\n    max_file_size : int\n        The maximum file size allowed for the query, in bytes.\n    pattern_type : str\n        Specifies the type of pattern to use, either \"include\" or \"exclude\".\n    pattern : str\n        The actual pattern string to include or exclude in the query.\n    summary : str\n        A summary of the query result, including details like estimated tokens.\n    \"\"\"\n    estimated_tokens = summary[summary.index(\"Estimated tokens:\") + len(\"Estimated \") :]\n    print(f\"{Colors.GREEN}INFO{Colors.END}: {Colors.GREEN}<-  {Colors.END}\", end=\"\")\n    _print_query(url, max_file_size, pattern_type, pattern)\n    print(f\" | {Colors.PURPLE}{estimated_tokens}{Colors.END}\")\n\n\n\n================================================\nFile: src/server/server_config.py\n================================================\n\"\"\"Configuration for the server.\"\"\"\n\nfrom typing import Dict, List\n\nfrom fastapi.templating import Jinja2Templates\n\nMAX_DISPLAY_SIZE: int = 300_000\nDELETE_REPO_AFTER: int = 60 * 60  # In seconds\n\n\nEXAMPLE_REPOS: List[Dict[str, str]] = [\n    {\"name\": \"Gitingest\", \"url\": \"https://github.com/cyclotruc/gitingest\"},\n    {\"name\": \"FastAPI\", \"url\": \"https://github.com/tiangolo/fastapi\"},\n    {\"name\": \"Flask\", \"url\": \"https://github.com/pallets/flask\"},\n    {\"name\": \"Excalidraw\", \"url\": \"https://github.com/excalidraw/excalidraw\"},\n    {\"name\": \"ApiAnalytics\", \"url\": \"https://github.com/tom-draper/api-analytics\"},\n]\n\ntemplates = Jinja2Templates(directory=\"server/templates\")\n\n\n\n================================================\nFile: src/server/server_utils.py\n================================================\n\"\"\"Utility functions for the server.\"\"\"\n\nimport asyncio\nimport math\nimport shutil\nimport time\nfrom contextlib import asynccontextmanager\nfrom pathlib import Path\n\nfrom fastapi import FastAPI, Request\nfrom fastapi.responses import Response\nfrom slowapi import Limiter, _rate_limit_exceeded_handler\nfrom slowapi.errors import RateLimitExceeded\nfrom slowapi.util import get_remote_address\n\nfrom gitingest.config import TMP_BASE_PATH\nfrom server.server_config import DELETE_REPO_AFTER\n\n# Initialize a rate limiter\nlimiter = Limiter(key_func=get_remote_address)\n\n\nasync def rate_limit_exception_handler(request: Request, exc: Exception) -> Response:\n    \"\"\"\n    Custom exception handler for rate-limiting errors.\n\n    Parameters\n    ----------\n    request : Request\n        The incoming HTTP request.\n    exc : Exception\n        The exception raised, expected to be RateLimitExceeded.\n\n    Returns\n    -------\n    Response\n        A response indicating that the rate limit has been exceeded.\n\n    Raises\n    ------\n    exc\n        If the exception is not a RateLimitExceeded error, it is re-raised.\n    \"\"\"\n    if isinstance(exc, RateLimitExceeded):\n        # Delegate to the default rate limit handler\n        return _rate_limit_exceeded_handler(request, exc)\n    # Re-raise other exceptions\n    raise exc\n\n\n@asynccontextmanager\nasync def lifespan(_: FastAPI):\n    \"\"\"\n    Lifecycle manager for handling startup and shutdown events for the FastAPI application.\n\n    Parameters\n    ----------\n    _ : FastAPI\n        The FastAPI application instance (unused).\n\n    Yields\n    -------\n    None\n        Yields control back to the FastAPI application while the background task runs.\n    \"\"\"\n    task = asyncio.create_task(_remove_old_repositories())\n\n    yield\n    # Cancel the background task on shutdown\n    task.cancel()\n    try:\n        await task\n    except asyncio.CancelledError:\n        pass\n\n\nasync def _remove_old_repositories():\n    \"\"\"\n    Periodically remove old repository folders.\n\n    Background task that runs periodically to clean up old repository directories.\n\n    This task:\n    - Scans the TMP_BASE_PATH directory every 60 seconds\n    - Removes directories older than DELETE_REPO_AFTER seconds\n    - Before deletion, logs repository URLs to history.txt if a matching .txt file exists\n    - Handles errors gracefully if deletion fails\n\n    The repository URL is extracted from the first .txt file in each directory,\n    assuming the filename format: \"owner-repository.txt\"\n    \"\"\"\n    while True:\n        try:\n            if not TMP_BASE_PATH.exists():\n                await asyncio.sleep(60)\n                continue\n\n            current_time = time.time()\n\n            for folder in TMP_BASE_PATH.iterdir():\n                # Skip if folder is not old enough\n                if current_time - folder.stat().st_ctime <= DELETE_REPO_AFTER:\n                    continue\n\n                await _process_folder(folder)\n\n        except Exception as exc:\n            print(f\"Error in _remove_old_repositories: {exc}\")\n\n        await asyncio.sleep(60)\n\n\nasync def _process_folder(folder: Path) -> None:\n    \"\"\"\n    Process a single folder for deletion and logging.\n\n    Parameters\n    ----------\n    folder : Path\n        The path to the folder to be processed.\n    \"\"\"\n    # Try to log repository URL before deletion\n    try:\n        txt_files = [f for f in folder.iterdir() if f.suffix == \".txt\"]\n\n        # Extract owner and repository name from the filename\n        filename = txt_files[0].stem\n        if txt_files and \"-\" in filename:\n            owner, repo = filename.split(\"-\", 1)\n            repo_url = f\"{owner}/{repo}\"\n\n            with open(\"history.txt\", mode=\"a\", encoding=\"utf-8\") as history:\n                history.write(f\"{repo_url}\\n\")\n\n    except Exception as exc:\n        print(f\"Error logging repository URL for {folder}: {exc}\")\n\n    # Delete the folder\n    try:\n        shutil.rmtree(folder)\n    except Exception as exc:\n        print(f\"Error deleting {folder}: {exc}\")\n\n\ndef log_slider_to_size(position: int) -> int:\n    \"\"\"\n    Convert a slider position to a file size in bytes using a logarithmic scale.\n\n    Parameters\n    ----------\n    position : int\n        Slider position ranging from 0 to 500.\n\n    Returns\n    -------\n    int\n        File size in bytes corresponding to the slider position.\n    \"\"\"\n    maxp = 500\n    minv = math.log(1)\n    maxv = math.log(102_400)\n    return round(math.exp(minv + (maxv - minv) * pow(position / maxp, 1.5))) * 1024\n\n\n## Color printing utility\nclass Colors:\n    \"\"\"ANSI color codes\"\"\"\n\n    BLACK = \"\\033[0;30m\"\n    RED = \"\\033[0;31m\"\n    GREEN = \"\\033[0;32m\"\n    BROWN = \"\\033[0;33m\"\n    BLUE = \"\\033[0;34m\"\n    PURPLE = \"\\033[0;35m\"\n    CYAN = \"\\033[0;36m\"\n    LIGHT_GRAY = \"\\033[0;37m\"\n    DARK_GRAY = \"\\033[1;30m\"\n    LIGHT_RED = \"\\033[1;31m\"\n    LIGHT_GREEN = \"\\033[1;32m\"\n    YELLOW = \"\\033[1;33m\"\n    LIGHT_BLUE = \"\\033[1;34m\"\n    LIGHT_PURPLE = \"\\033[1;35m\"\n    LIGHT_CYAN = \"\\033[1;36m\"\n    WHITE = \"\\033[1;37m\"\n    BOLD = \"\\033[1m\"\n    FAINT = \"\\033[2m\"\n    ITALIC = \"\\033[3m\"\n    UNDERLINE = \"\\033[4m\"\n    BLINK = \"\\033[5m\"\n    NEGATIVE = \"\\033[7m\"\n    CROSSED = \"\\033[9m\"\n    END = \"\\033[0m\"\n\n\n\n================================================\nFile: src/server/routers/__init__.py\n================================================\n\"\"\"This module contains the routers for the FastAPI application.\"\"\"\n\nfrom server.routers.download import router as download\nfrom server.routers.dynamic import router as dynamic\nfrom server.routers.index import router as index\n\n__all__ = [\"download\", \"dynamic\", \"index\"]\n\n\n\n================================================\nFile: src/server/routers/download.py\n================================================\n\"\"\"This module contains the FastAPI router for downloading a digest file.\"\"\"\n\nfrom fastapi import APIRouter, HTTPException\nfrom fastapi.responses import Response\n\nfrom gitingest.config import TMP_BASE_PATH\n\nrouter = APIRouter()\n\n\n@router.get(\"/download/{digest_id}\")\nasync def download_ingest(digest_id: str) -> Response:\n    \"\"\"\n    Download a .txt file associated with a given digest ID.\n\n    This function searches for a `.txt` file in a directory corresponding to the provided\n    digest ID. If a file is found, it is read and returned as a downloadable attachment.\n    If no `.txt` file is found, an error is raised.\n\n    Parameters\n    ----------\n    digest_id : str\n        The unique identifier for the digest. It is used to find the corresponding directory\n        and locate the .txt file within that directory.\n\n    Returns\n    -------\n    Response\n        A FastAPI Response object containing the content of the found `.txt` file. The file is\n        sent with the appropriate media type (`text/plain`) and the correct `Content-Disposition`\n        header to prompt a file download.\n\n    Raises\n    ------\n    HTTPException\n        If the digest directory is not found or if no `.txt` file exists in the directory.\n    \"\"\"\n    directory = TMP_BASE_PATH / digest_id\n\n    try:\n        if not directory.exists():\n            raise FileNotFoundError(\"Directory not found\")\n\n        txt_files = [f for f in directory.iterdir() if f.suffix == \".txt\"]\n        if not txt_files:\n            raise FileNotFoundError(\"No .txt file found\")\n\n    except FileNotFoundError as exc:\n        raise HTTPException(status_code=404, detail=\"Digest not found\") from exc\n\n    # Find the first .txt file in the directory\n    first_file = txt_files[0]\n\n    with first_file.open(encoding=\"utf-8\") as f:\n        content = f.read()\n\n    return Response(\n        content=content,\n        media_type=\"text/plain\",\n        headers={\"Content-Disposition\": f\"attachment; filename={first_file.name}\"},\n    )\n\n\n\n================================================\nFile: src/server/routers/dynamic.py\n================================================\n\"\"\"This module defines the dynamic router for handling dynamic path requests.\"\"\"\n\nfrom fastapi import APIRouter, Form, Request\nfrom fastapi.responses import HTMLResponse\n\nfrom server.query_processor import process_query\nfrom server.server_config import templates\nfrom server.server_utils import limiter\n\nrouter = APIRouter()\n\n\n@router.get(\"/{full_path:path}\")\nasync def catch_all(request: Request, full_path: str) -> HTMLResponse:\n    \"\"\"\n    Render a page with a Git URL based on the provided path.\n\n    This endpoint catches all GET requests with a dynamic path, constructs a Git URL\n    using the `full_path` parameter, and renders the `git.jinja` template with that URL.\n\n    Parameters\n    ----------\n    request : Request\n        The incoming request object, which provides context for rendering the response.\n    full_path : str\n        The full path extracted from the URL, which is used to build the Git URL.\n\n    Returns\n    -------\n    HTMLResponse\n        An HTML response containing the rendered template, with the Git URL\n        and other default parameters such as loading state and file size.\n    \"\"\"\n    return templates.TemplateResponse(\n        \"git.jinja\",\n        {\n            \"request\": request,\n            \"repo_url\": full_path,\n            \"loading\": True,\n            \"default_file_size\": 243,\n        },\n    )\n\n\n@router.post(\"/{full_path:path}\", response_class=HTMLResponse)\n@limiter.limit(\"10/minute\")\nasync def process_catch_all(\n    request: Request,\n    input_text: str = Form(...),\n    max_file_size: int = Form(...),\n    pattern_type: str = Form(...),\n    pattern: str = Form(...),\n) -> HTMLResponse:\n    \"\"\"\n    Process the form submission with user input for query parameters.\n\n    This endpoint handles POST requests, processes the input parameters (e.g., text, file size, pattern),\n    and calls the `process_query` function to handle the query logic, returning the result as an HTML response.\n\n    Parameters\n    ----------\n    request : Request\n        The incoming request object, which provides context for rendering the response.\n    input_text : str\n        The input text provided by the user for processing, by default taken from the form.\n    max_file_size : int\n        The maximum allowed file size for the input, specified by the user.\n    pattern_type : str\n        The type of pattern used for the query, specified by the user.\n    pattern : str\n        The pattern string used in the query, specified by the user.\n\n    Returns\n    -------\n    HTMLResponse\n        An HTML response generated after processing the form input and query logic,\n        which will be rendered and returned to the user.\n    \"\"\"\n    return await process_query(\n        request,\n        input_text,\n        max_file_size,\n        pattern_type,\n        pattern,\n        is_index=False,\n    )\n\n\n\n================================================\nFile: src/server/routers/index.py\n================================================\n\"\"\"This module defines the FastAPI router for the home page of the application.\"\"\"\n\nfrom fastapi import APIRouter, Form, Request\nfrom fastapi.responses import HTMLResponse\n\nfrom server.query_processor import process_query\nfrom server.server_config import EXAMPLE_REPOS, templates\nfrom server.server_utils import limiter\n\nrouter = APIRouter()\n\n\n@router.get(\"/\", response_class=HTMLResponse)\nasync def home(request: Request) -> HTMLResponse:\n    \"\"\"\n    Render the home page with example repositories and default parameters.\n\n    This endpoint serves the home page of the application, rendering the `index.jinja` template\n    and providing it with a list of example repositories and default file size values.\n\n    Parameters\n    ----------\n    request : Request\n        The incoming request object, which provides context for rendering the response.\n\n    Returns\n    -------\n    HTMLResponse\n        An HTML response containing the rendered home page template, with example repositories\n        and other default parameters such as file size.\n    \"\"\"\n    return templates.TemplateResponse(\n        \"index.jinja\",\n        {\n            \"request\": request,\n            \"examples\": EXAMPLE_REPOS,\n            \"default_file_size\": 243,\n        },\n    )\n\n\n@router.post(\"/\", response_class=HTMLResponse)\n@limiter.limit(\"10/minute\")\nasync def index_post(\n    request: Request,\n    input_text: str = Form(...),\n    max_file_size: int = Form(...),\n    pattern_type: str = Form(...),\n    pattern: str = Form(...),\n) -> HTMLResponse:\n    \"\"\"\n    Process the form submission with user input for query parameters.\n\n    This endpoint handles POST requests from the home page form. It processes the user-submitted\n    input (e.g., text, file size, pattern type) and invokes the `process_query` function to handle\n    the query logic, returning the result as an HTML response.\n\n    Parameters\n    ----------\n    request : Request\n        The incoming request object, which provides context for rendering the response.\n    input_text : str\n        The input text provided by the user for processing, by default taken from the form.\n    max_file_size : int\n        The maximum allowed file size for the input, specified by the user.\n    pattern_type : str\n        The type of pattern used for the query, specified by the user.\n    pattern : str\n        The pattern string used in the query, specified by the user.\n\n    Returns\n    -------\n    HTMLResponse\n        An HTML response containing the results of processing the form input and query logic,\n        which will be rendered and returned to the user.\n    \"\"\"\n    return await process_query(\n        request,\n        input_text,\n        max_file_size,\n        pattern_type,\n        pattern,\n        is_index=True,\n    )\n\n\n\n================================================\nFile: src/server/templates/api.jinja\n================================================\n{% extends \"base.jinja\" %}\n{% block title %}Gitingest API{% endblock %}\n{% block content %}\n    <div class=\"relative\">\n        <div class=\"w-full h-full absolute inset-0 bg-black rounded-xl translate-y-2 translate-x-2\"></div>\n        <div class=\"bg-[#fff4da] rounded-xl border-[3px] border-gray-900 p-8 relative z-20\">\n            <h1 class=\"text-3xl font-bold text-gray-900 mb-4\">API Documentation</h1>\n            <div class=\"prose prose-blue max-w-none\">\n                <div class=\"bg-yellow-50 border-[3px] border-gray-900 p-4 mb-6 rounded-lg\">\n                    <div class=\"flex\">\n                        <div class=\"flex-shrink-0\">\n                            <svg class=\"h-5 w-5 text-yellow-400\"\n                                 viewBox=\"0 0 20 20\"\n                                 fill=\"currentColor\">\n                                <path fill-rule=\"evenodd\" d=\"M8.257 3.099c.765-1.36 2.722-1.36 3.486 0l5.58 9.92c.75 1.334-.213 2.98-1.742 2.98H4.42c-1.53 0-2.493-1.646-1.743-2.98l5.58-9.92zM11 13a1 1 0 11-2 0 1 1 0 012 0zm-1-8a1 1 0 00-1 1v3a1 1 0 002 0V6a1 1 0 00-1-1z\" clip-rule=\"evenodd\" />\n                            </svg>\n                        </div>\n                        <div class=\"ml-3\">\n                            <p class=\"text-sm text-gray-900\">The API is currently under development..</p>\n                        </div>\n                    </div>\n                </div>\n                <p class=\"text-gray-900\">\n                    We're working on making our API available to the public.\n                    In the meantime, you can\n                    <a href=\"https://github.com/cyclotruc/gitingest/issues/new\"\n                       target=\"_blank\"\n                       rel=\"noopener noreferrer\"\n                       class=\"text-[#6e5000] hover:underline\">Open an issue on GitHub</a>\n                    to suggest features.\n                </p>\n            </div>\n        </div>\n    </div>\n{% endblock %}\n\n\n\n================================================\nFile: src/server/templates/base.jinja\n================================================\n<!DOCTYPE html>\n<html lang=\"en\">\n    <head>\n        <meta charset=\"UTF-8\">\n        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n        <link rel=\"icon\" type=\"image/x-icon\" href=\"/static/favicon.ico\">\n        <!-- Search Engine Meta Tags -->\n        <meta name=\"description\"\n              content=\"Replace 'hub' with 'ingest' in any GitHub URL for a prompt-friendly text.\">\n        <meta name=\"keywords\"\n              content=\"Gitingest, AI tools, LLM integration, Ingest, Digest, Context, Prompt, Git workflow, codebase extraction, Git repository, Git automation, Summarize, prompt-friendly\">\n        <meta name=\"robots\" content=\"index, follow\">\n        <!-- Favicons -->\n        <link rel=\"icon\" type=\"image/svg+xml\" href=\"/static/favicon.svg\">\n        <link rel=\"icon\"\n              type=\"image/png\"\n              sizes=\"64x64\"\n              href=\"/static/favicon-64.png\">\n        <link rel=\"apple-touch-icon\"\n              sizes=\"180x180\"\n              href=\"/static/apple-touch-icon.png\">\n        <!-- Web App Meta -->\n        <meta name=\"apple-mobile-web-app-title\" content=\"Gitingest\">\n        <meta name=\"application-name\" content=\"Gitingest\">\n        <meta name=\"theme-color\" content=\"#FCA847\">\n        <meta name=\"apple-mobile-web-app-capable\" content=\"yes\">\n        <meta name=\"apple-mobile-web-app-status-bar-style\" content=\"default\">\n        <!-- OpenGraph Meta Tags -->\n        <meta property=\"og:title\" content=\"Gitingest\">\n        <meta property=\"og:description\"\n              content=\"Replace 'hub' with 'ingest' in any GitHub URL for a prompt-friendly text.\">\n        <meta property=\"og:type\" content=\"website\">\n        <meta property=\"og:url\" content=\"{{ request.url }}\">\n        <meta property=\"og:image\" content=\"/static/og-image.png\">\n        <title>\n            {% block title %}Gitingest{% endblock %}\n        </title>\n        <script src=\"https://cdn.tailwindcss.com\"></script>\n        <script src=\"/static/js/utils.js\"></script>\n        <script>\n        !function (t, e) { var o, n, p, r; e.__SV || (window.posthog = e, e._i = [], e.init = function (i, s, a) { function g(t, e) { var o = e.split(\".\"); 2 == o.length && (t = t[o[0]], e = o[1]), t[e] = function () { t.push([e].concat(Array.prototype.slice.call(arguments, 0))) } } (p = t.createElement(\"script\")).type = \"text/javascript\", p.crossOrigin = \"anonymous\", p.async = !0, p.src = s.api_host.replace(\".i.posthog.com\", \"-assets.i.posthog.com\") + \"/static/array.js\", (r = t.getElementsByTagName(\"script\")[0]).parentNode.insertBefore(p, r); var u = e; for (void 0 !== a ? u = e[a] = [] : a = \"posthog\", u.people = u.people || [], u.toString = function (t) { var e = \"posthog\"; return \"posthog\" !== a && (e += \".\" + a), t || (e += \" (stub)\"), e }, u.people.toString = function () { return u.toString(1) + \".people (stub)\" }, o = \"init capture register register_once register_for_session unregister unregister_for_session getFeatureFlag getFeatureFlagPayload isFeatureEnabled reloadFeatureFlags updateEarlyAccessFeatureEnrollment getEarlyAccessFeatures on onFeatureFlags onSessionId getSurveys getActiveMatchingSurveys renderSurvey canRenderSurvey getNextSurveyStep identify setPersonProperties group resetGroups setPersonPropertiesForFlags resetPersonPropertiesForFlags setGroupPropertiesForFlags resetGroupPropertiesForFlags reset get_distinct_id getGroups get_session_id get_session_replay_url alias set_config startSessionRecording stopSessionRecording sessionRecordingStarted captureException loadToolbar get_property getSessionProperty createPersonProfile opt_in_capturing opt_out_capturing has_opted_in_capturing has_opted_out_capturing clear_opt_in_out_capturing debug getPageViewId\".split(\" \"), n = 0; n < o.length; n++)g(u, o[n]); e._i.push([i, s, a]) }, e.__SV = 1) }(document, window.posthog || []);\n        posthog.init('phc_9aNpiIVH2zfTWeY84vdTWxvrJRCQQhP5kcVDXUvcdou', {\n            api_host: 'https://eu.i.posthog.com',\n            person_profiles: 'always',\n        })\n        </script>\n        {% block extra_head %}{% endblock %}\n    </head>\n    <body class=\"bg-[#FFFDF8] min-h-screen flex flex-col\">\n        {% include 'components/navbar.jinja' %}\n        <!-- Main content wrapper -->\n        <main class=\"flex-1 w-full\">\n            <div class=\"max-w-4xl mx-auto px-4 py-8\">\n                {% block content %}{% endblock %}\n            </div>\n        </main>\n        {% include 'components/footer.jinja' %}\n        {% block extra_scripts %}{% endblock %}\n    </body>\n</html>\n\n\n\n================================================\nFile: src/server/templates/git.jinja\n================================================\n{% extends \"base.jinja\" %}\n{% block content %}\n    {% if error_message %}\n        <div class=\"mb-6 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700\"\n             id=\"error-message\"\n             data-message=\"{{ error_message }}\">{{ error_message }}</div>\n    {% endif %}\n    {% with is_index=true, show_examples=false %}\n        {% include 'components/git_form.jinja' %}\n    {% endwith %}\n    {% if loading %}\n        <div class=\"relative mt-10\">\n            <div class=\"w-full h-full absolute inset-0 bg-black rounded-xl translate-y-2 translate-x-2\"></div>\n            <div class=\"bg-[#fafafa] rounded-xl border-[3px] border-gray-900 p-6 relative z-20 flex flex-col items-center space-y-4\">\n                <div class=\"loader border-8 border-[#fff4da] border-t-8 border-t-[#ffc480] rounded-full w-16 h-16 animate-spin\"></div>\n                <p class=\"text-lg font-bold text-gray-900\">Loading...</p>\n            </div>\n        </div>\n    {% endif %}\n    {% include 'components/result.jinja' %}\n{% endblock content %}\n{% block extra_scripts %}\n    <script>\n    document.addEventListener('DOMContentLoaded', function() {\n        const urlInput = document.getElementById('input_text');\n        const form = document.getElementById('ingestForm');\n        if (urlInput && urlInput.value.trim() && form) {\n            // Wait for stars to be loaded before submitting\n            waitForStars().then(() => {\n                const submitEvent = new SubmitEvent('submit', {\n                    cancelable: true,\n                    bubbles: true\n                });\n                Object.defineProperty(submitEvent, 'target', {\n                    value: form,\n                    enumerable: true\n                });\n                handleSubmit(submitEvent, false);\n            });\n        }\n    });\n\n    function waitForStars() {\n        return new Promise((resolve) => {\n            const checkStars = () => {\n                const stars = document.getElementById('github-stars');\n                if (stars && stars.textContent !== '0') {\n                    resolve();\n                } else {\n                    setTimeout(checkStars, 10);\n                }\n            };\n            checkStars();\n        });\n    }\n    </script>\n{% endblock extra_scripts %}\n\n\n\n================================================\nFile: src/server/templates/index.jinja\n================================================\n{% extends \"base.jinja\" %}\n{% block extra_head %}\n    <script>\n    function submitExample(repoName) {\n        const input = document.getElementById('input_text');\n        input.value = repoName;\n        input.focus();\n    }\n    </script>\n{% endblock %}\n{% block content %}\n    <div class=\"mb-8\">\n        <div class=\"relative w-full mx-auto flex sm:flex-row flex-col justify-center items-start sm:items-center\">\n            <svg class=\"h-auto w-16 sm:w-20 md:w-24 flex-shrink-0 p-2 md:relative sm:absolute lg:absolute left-0 lg:-translate-x-full lg:ml-32 md:translate-x-10 sm:-translate-y-16 md:-translate-y-0 -translate-x-2 lg:-translate-y-10\"\n                 viewBox=\"0 0 91 98\"\n                 fill=\"none\"\n                 xmlns=\"http://www.w3.org/2000/svg\">\n                <path d=\"m35.878 14.162 1.333-5.369 1.933 5.183c4.47 11.982 14.036 21.085 25.828 24.467l5.42 1.555-5.209 2.16c-11.332 4.697-19.806 14.826-22.888 27.237l-1.333 5.369-1.933-5.183C34.56 57.599 24.993 48.496 13.201 45.114l-5.42-1.555 5.21-2.16c11.331-4.697 19.805-14.826 22.887-27.237Z\" fill=\"#FE4A60\" stroke=\"#000\" stroke-width=\"3.445\">\n                </path>\n                <path d=\"M79.653 5.729c-2.436 5.323-9.515 15.25-18.341 12.374m9.197 16.336c2.6-5.851 10.008-16.834 18.842-13.956m-9.738-15.07c-.374 3.787 1.076 12.078 9.869 14.943M70.61 34.6c.503-4.21-.69-13.346-9.49-16.214M14.922 65.967c1.338 5.677 6.372 16.756 15.808 15.659M18.21 95.832c-1.392-6.226-6.54-18.404-15.984-17.305m12.85-12.892c-.41 3.771-3.576 11.588-12.968 12.681M18.025 96c.367-4.21 3.453-12.905 12.854-14\" stroke=\"#000\" stroke-width=\"2.548\" stroke-linecap=\"round\">\n                </path>\n            </svg>\n            <h1 class=\"text-4xl sm:text-5xl sm:pt-20 lg:pt-5 md:text-6xl lg:text-7xl font-bold tracking-tighter w-full inline-block text-left md:text-center relative\">\n                Prompt-friendly\n                <br>\n                codebase&nbsp;\n            </h1>\n            <svg class=\"w-16 lg:w-20 h-auto lg:absolute flex-shrink-0 right-0 bottom-0 md:block hidden translate-y-10 md:translate-y-20 lg:translate-y-4 lg:-translate-x-12 -translate-x-10\"\n                 viewBox=\"0 0 92 80\"\n                 fill=\"none\"\n                 xmlns=\"http://www.w3.org/2000/svg\">\n                <path d=\"m35.213 16.953.595-5.261 2.644 4.587a35.056 35.056 0 0 0 26.432 17.33l5.261.594-4.587 2.644A35.056 35.056 0 0 0 48.23 63.28l-.595 5.26-2.644-4.587a35.056 35.056 0 0 0-26.432-17.328l-5.261-.595 4.587-2.644a35.056 35.056 0 0 0 17.329-26.433Z\" fill=\"#5CF1A4\" stroke=\"#000\" stroke-width=\"2.868\" class=\"\">\n                </path>\n                <path d=\"M75.062 40.108c1.07 5.255 1.072 16.52-7.472 19.54m7.422-19.682c1.836 2.965 7.643 8.14 16.187 5.121-8.544 3.02-8.207 15.23-6.971 20.957-1.97-3.343-8.044-9.274-16.588-6.254M12.054 28.012c1.34-5.22 6.126-15.4 14.554-14.369M12.035 28.162c-.274-3.487-2.93-10.719-11.358-11.75C9.104 17.443 14.013 6.262 15.414.542c.226 3.888 2.784 11.92 11.212 12.95\" stroke=\"#000\" stroke-width=\"2.319\" stroke-linecap=\"round\">\n                </path>\n            </svg>\n        </div>\n        <p class=\"text-gray-600 text-lg max-w-2xl mx-auto text-center mt-8\">\n            Turn any Git repository into a simple text digest of its codebase.\n        </p>\n        <p class=\"text-gray-600 text-lg max-w-2xl mx-auto text-center mt-0\">\n            This is useful for feeding a codebase into any LLM.\n        </p>\n    </div>\n    {% if error_message %}\n        <div class=\"mb-6 p-4 bg-red-50 border border-red-200 rounded-lg text-red-700\"\n             id=\"error-message\"\n             data-message=\"{{ error_message }}\">{{ error_message }}</div>\n    {% endif %}\n    {% with is_index=true, show_examples=true %}\n        {% include 'components/git_form.jinja' %}\n    {% endwith %}\n    <p class=\"text-gray-600 text-sm max-w-2xl mx-auto text-center mt-4\">\n        You can also replace 'hub' with 'ingest' in any GitHub URL.\n    </p>\n    {% include 'components/result.jinja' %}\n{% endblock %}\n\n\n\n================================================\nFile: src/server/templates/components/footer.jinja\n================================================\n<footer class=\"w-full border-t-[3px] border-gray-900 mt-auto\">\n    <div class=\"max-w-4xl mx-auto px-4 py-4\">\n        <div class=\"grid grid-cols-3 items-center text-gray-900 text-sm\">\n            <!-- Left column - GitHub links -->\n            <div class=\"flex items-center space-x-4\">\n                <a href=\"https://github.com/cyclotruc/gitingest\"\n                   target=\"_blank\"\n                   rel=\"noopener noreferrer\"\n                   class=\"hover:underline flex items-center\">\n                    <svg class=\"w-4 h-4 mr-1\"\n                         xmlns=\"http://www.w3.org/2000/svg\"\n                         viewBox=\"0 0 496 512\">\n                        <path fill=\"currentColor\" d=\"M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z\" />\n                    </svg>\n                    Suggest a feature\n                </a>\n            </div>\n            <!-- Middle column - Made with love -->\n            <div class=\"flex justify-center items-center\">\n                <div class=\"flex items-center\">\n                    made with ❤️ by\n                    <a href=\"https://bsky.app/profile/yasbaltrine.bsky.social\"\n                       target=\"_blank\"\n                       rel=\"noopener noreferrer\"\n                       class=\"ml-1 hover:underline\">@rom2</a>\n                </div>\n            </div>\n            <!-- Right column - Discord -->\n            <div class=\"flex justify-end\">\n                <a href=\"https://discord.gg/zerRaGK9EC\"\n                   target=\"_blank\"\n                   rel=\"noopener noreferrer\"\n                   class=\"hover:underline flex items-center\">\n                    <svg class=\"w-4 h-4 mr-1\"\n                         xmlns=\"http://www.w3.org/2000/svg\"\n                         viewBox=\"0 0 640 512\">\n                        <path fill=\"currentColor\" d=\"M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z\" />\n                    </svg>\n                    Discord\n                </a>\n            </div>\n        </div>\n    </div>\n</footer>\n\n\n\n================================================\nFile: src/server/templates/components/git_form.jinja\n================================================\n<script>\n    function changePattern(element) {\n        console.log(\"Pattern changed\", element.value);\n        let patternType = element.value;\n        const files = document.getElementsByName(\"tree-line\");\n\n        Array.from(files).forEach((element) => {\n            if (element.textContent.includes(\"Directory structure:\")) {\n                return;\n            }\n\n            element.classList.toggle('line-through');\n            element.classList.toggle('text-gray-500');\n            element.classList.toggle('hover:text-inherit');\n            element.classList.toggle('hover:no-underline');\n            element.classList.toggle('hover:line-through');\n            element.classList.toggle('hover:text-gray-500');\n        });\n    }\n</script>\n<div class=\"relative\">\n    <div class=\"w-full h-full absolute inset-0 bg-gray-900 rounded-xl translate-y-2 translate-x-2\"></div>\n    <div class=\"rounded-xl relative z-20 pl-8 sm:pl-10 pr-8 sm:pr-16 py-8 border-[3px] border-gray-900 bg-[#fff4da]\">\n        <img src=\"https://cdn.devdojo.com/images/january2023/shape-1.png\"\n             class=\"absolute md:block hidden left-0 h-[4.5rem] w-[4.5rem] bottom-0 -translate-x-full ml-3\">\n        <form class=\"flex md:flex-row flex-col w-full h-full justify-center items-stretch space-y-5 md:space-y-0 md:space-x-5\"\n              id=\"ingestForm\"\n              onsubmit=\"handleSubmit(event{% if is_index %}, true{% endif %})\">\n            <div class=\"relative w-full h-full\">\n                <div class=\"w-full h-full rounded bg-gray-900 translate-y-1 translate-x-1 absolute inset-0 z-10\"></div>\n                <input type=\"text\"\n                       name=\"input_text\"\n                       id=\"input_text\"\n                       placeholder=\"https://github.com/...\"\n                       value=\"{{ repo_url if repo_url else '' }}\"\n                       required\n                       class=\"border-[3px] w-full relative z-20 border-gray-900 placeholder-gray-600 text-lg font-medium focus:outline-none py-3.5 px-6 rounded\">\n            </div>\n            <div class=\"relative w-auto flex-shrink-0 h-full group\">\n                <div class=\"w-full h-full rounded bg-gray-800 translate-y-1 translate-x-1 absolute inset-0 z-10\"></div>\n                <button type=\"submit\"\n                        class=\"py-3.5 rounded px-6 group-hover:-translate-y-px group-hover:-translate-x-px ease-out duration-300 z-20 relative w-full border-[3px] border-gray-900 font-medium bg-[#ffc480] tracking-wide text-lg flex-shrink-0 text-gray-900\">\n                    Ingest\n                </button>\n            </div>\n            <input type=\"hidden\" name=\"pattern_type\" value=\"exclude\">\n            <input type=\"hidden\" name=\"pattern\" value=\"\">\n        </form>\n        <div class=\"mt-4 relative z-20 flex flex-wrap gap-4 items-start\">\n            <!-- Pattern selector -->\n            <div class=\"w-[200px] sm:w-[250px] mr-9 mt-4\">\n                <div class=\"relative\">\n                    <div class=\"w-full h-full rounded bg-gray-900 translate-y-1 translate-x-1 absolute inset-0 z-10\"></div>\n                    <div class=\"flex relative z-20 border-[3px] border-gray-900 rounded bg-white\">\n                        <div class=\"relative flex items-center\">\n                            <select id=\"pattern_type\"\n                                    onchange=\"changePattern(this)\"\n                                    name=\"pattern_type\"\n                                    class=\"w-21 py-2 pl-2 pr-6 appearance-none bg-[#e6e8eb] focus:outline-none border-r-[3px] border-gray-900\">\n                                <option value=\"exclude\"\n                                        {% if pattern_type == 'exclude' or not pattern_type %}selected{% endif %}>\n                                    Exclude\n                                </option>\n                                <option value=\"include\" {% if pattern_type == 'include' %}selected{% endif %}>Include</option>\n                            </select>\n                            <svg class=\"absolute right-2 w-4 h-4 pointer-events-none\"\n                                 xmlns=\"http://www.w3.org/2000/svg\"\n                                 viewBox=\"0 0 24 24\"\n                                 fill=\"none\"\n                                 stroke=\"currentColor\"\n                                 stroke-width=\"2\"\n                                 stroke-linecap=\"round\"\n                                 stroke-linejoin=\"round\">\n                                <polyline points=\"6 9 12 15 18 9\" />\n                            </svg>\n                        </div>\n                        <input type=\"text\"\n                               id=\"pattern\"\n                               name=\"pattern\"\n                               placeholder=\"*.md, src/ \"\n                               value=\"{{ pattern if pattern else '' }}\"\n                               class=\" py-2 px-2 bg-[#E8F0FE] focus:outline-none w-full\">\n                    </div>\n                </div>\n            </div>\n            <div class=\"w-[200px] sm:w-[200px] mt-3\">\n                <label for=\"file_size\" class=\"block text-gray-700 mb-1\">\n                    Include files under: <span id=\"size_value\" class=\"font-bold\">50kb</span>\n                </label>\n                <input type=\"range\"\n                       id=\"file_size\"\n                       name=\"max_file_size\"\n                       min=\"0\"\n                       max=\"500\"\n                       required\n                       value=\"{{ default_file_size }}\"\n                       class=\"w-full h-3 bg-[#FAFAFA] bg-no-repeat bg-[length:50%_100%] bg-[#ebdbb7] appearance-none border-[3px] border-gray-900 rounded-sm focus:outline-none bg-gradient-to-r from-[#FE4A60] to-[#FE4A60] [&::-webkit-slider-thumb]:w-5 [&::-webkit-slider-thumb]:h-7 [&::-webkit-slider-thumb]:appearance-none [&::-webkit-slider-thumb]:bg-white [&::-webkit-slider-thumb]:rounded-sm [&::-webkit-slider-thumb]:cursor-pointer [&::-webkit-slider-thumb]:border-solid [&::-webkit-slider-thumb]:border-[3px] [&::-webkit-slider-thumb]:border-gray-900 [&::-webkit-slider-thumb]:shadow-[3px_3px_0_#000]  \">\n            </div>\n        </div>\n        {% if show_examples %}\n            <!-- Example repositories section -->\n            <div class=\"mt-4\">\n                <p class=\"opacity-70 mb-1\">Try these example repositories:</p>\n                <div class=\"flex flex-wrap gap-2\">\n                    {% for example in examples %}\n                        <button onclick=\"submitExample('{{ example.url }}')\"\n                                class=\"px-4 py-1 bg-[#EBDBB7] hover:bg-[#FFC480] text-gray-900 rounded transition-colors duration-200 border-[3px] border-gray-900 relative hover:-translate-y-px hover:-translate-x-px\">\n                            {{ example.name }}\n                        </button>\n                    {% endfor %}\n                </div>\n            </div>\n        {% endif %}\n    </div>\n</div>\n\n\n\n================================================\nFile: src/server/templates/components/navbar.jinja\n================================================\n<script>\n    function formatStarCount(count) {\n        if (count >= 1000) {\n            return (count / 1000).toFixed(1) + 'k';\n        }\n        return count.toString();\n    }\n\n    async function fetchGitHubStars() {\n        try {\n            const response = await fetch('https://api.github.com/repos/cyclotruc/gitingest');\n            const data = await response.json();\n            const starCount = data.stargazers_count;\n\n            document.getElementById('github-stars').textContent = formatStarCount(starCount);\n        } catch (error) {\n            console.error('Error fetching GitHub stars:', error);\n            document.getElementById('github-stars').parentElement.style.display = 'none';\n        }\n    }\n\n    fetchGitHubStars();\n</script>\n<header class=\"sticky top-0 bg-[#FFFDF8] border-b-[3px] border-gray-900 z-50\">\n    <div class=\"max-w-4xl mx-auto px-4\">\n        <div class=\"flex justify-between items-center h-16\">\n            <!-- Logo -->\n            <div class=\"flex items-center gap-4\">\n                <h1 class=\"text-2xl font-bold tracking-tight\">\n                    <a href=\"/\" class=\"hover:opacity-80 transition-opacity\">\n                        <span class=\"text-gray-900\">Git</span><span class=\"text-[#FE4A60]\">ingest</span>\n                    </a>\n                </h1>\n            </div>\n            <!-- Navigation with updated styling -->\n            <nav class=\"flex items-center space-x-6\">\n                <!-- Simplified Chrome extension button -->\n                <a href=\"https://chromewebstore.google.com/detail/git-ingest-turn-any-git-r/adfjahbijlkjfoicpjkhjicpjpjfaood\"\n                   target=\"_blank\"\n                   rel=\"noopener noreferrer\"\n                   class=\"text-gray-900 hover:-translate-y-0.5 transition-transform flex items-center gap-1.5\">\n                    <div class=\"flex items-center\">\n                        <svg xmlns=\"http://www.w3.org/2000/svg\"\n                             width=\"24\"\n                             height=\"24\"\n                             viewBox=\"0 0 50 50\"\n                             fill=\"none\"\n                             stroke=\"currentColor\"\n                             stroke-width=\"3\"\n                             class=\"w-4 h-4 mx-1\">\n                            <path d=\"M 25 2 C 12.309295 2 2 12.309295 2 25 C 2 37.690705 12.309295 48 25 48 C 37.690705 48 48 37.690705 48 25 C 48 12.309295 37.690705 2 25 2 z M 25 4 C 32.987976 4 39.925645 8.44503 43.476562 15 L 25 15 A 1.0001 1.0001 0 0 0 24.886719 15.005859 C 19.738868 15.064094 15.511666 19.035373 15.046875 24.078125 L 8.0351562 12.650391 C 11.851593 7.4136918 18.014806 4 25 4 z M 6.8242188 14.501953 L 16.476562 30.230469 A 1.0001 1.0001 0 0 0 16.591797 30.388672 A 1.0001 1.0001 0 0 0 16.59375 30.392578 C 18.3752 33.158533 21.474925 35 25 35 C 26.413063 35 27.756327 34.701734 28.976562 34.169922 L 22.320312 45.824219 C 11.979967 44.509804 4 35.701108 4 25 C 4 21.169738 5.0375742 17.591533 6.8242188 14.501953 z M 25 17 C 29.430123 17 33 20.569877 33 25 C 33 26.42117 32.629678 27.751591 31.984375 28.90625 A 1.0001 1.0001 0 0 0 31.982422 28.908203 A 1.0001 1.0001 0 0 0 31.947266 28.966797 C 30.57172 31.37734 27.983486 33 25 33 C 20.569877 33 17 29.430123 17 25 C 17 20.569877 20.569877 17 25 17 z M 30.972656 17 L 44.421875 17 C 45.43679 19.465341 46 22.165771 46 25 C 46 36.609824 36.609824 46 25 46 C 24.842174 46 24.686285 45.991734 24.529297 45.988281 L 33.683594 29.958984 A 1.0001 1.0001 0 0 0 33.742188 29.841797 C 34.541266 28.405674 35 26.755664 35 25 C 35 21.728612 33.411062 18.825934 30.972656 17 z\" />\n                        </svg>\n                        Extension\n                    </div>\n                </a>\n                <div class=\"flex items-center gap-2\">\n                    <a href=\"https://github.com/cyclotruc/gitingest\"\n                       target=\"_blank\"\n                       rel=\"noopener noreferrer\"\n                       class=\"text-gray-900 hover:-translate-y-0.5 transition-transform flex items-center gap-1.5\">\n                        <svg class=\"w-4 h-4\"\n                             fill=\"currentColor\"\n                             viewBox=\"0 0 24 24\"\n                             aria-hidden=\"true\">\n                            <path fill-rule=\"evenodd\" d=\"M12 2C6.477 2 2 6.484 2 12.017c0 4.425 2.865 8.18 6.839 9.504.5.092.682-.217.682-.483 0-.237-.008-.868-.013-1.703-2.782.605-3.369-1.343-3.369-1.343-.454-1.158-1.11-1.466-1.11-1.466-.908-.62.069-.608.069-.608 1.003.07 1.531 1.032 1.531 1.032.892 1.53 2.341 1.088 2.91.832.092-.647.35-1.088.636-1.338-2.22-.253-4.555-1.113-4.555-4.951 0-1.093.39-1.988 1.029-2.688-.103-.253-.446-1.272.098-2.65 0 0 .84-.27 2.75 1.026A9.564 9.564 0 0112 6.844c.85.004 1.705.115 2.504.337 1.909-1.296 2.747-1.027 2.747-1.027.546 1.379.202 2.398.1 2.651.64.7 1.028 1.595 1.028 2.688 0 3.848-2.339 4.695-4.566 4.943.359.309.678.92.678 1.855 0 1.338-.012 2.419-.012 2.747 0 .268.18.58.688.482A10.019 10.019 0 0022 12.017C22 6.484 17.522 2 12 2z\" clip-rule=\"evenodd\">\n                            </path>\n                        </svg>\n                        GitHub\n                    </a>\n                    <div class=\"flex items-center text-sm text-gray-600\">\n                        <svg class=\"w-4 h-4 text-[#ffc480] mr-1\"\n                             fill=\"currentColor\"\n                             viewBox=\"0 0 20 20\">\n                            <path d=\"M9.049 2.927c.3-.921 1.603-.921 1.902 0l1.07 3.292a1 1 0 00.95.69h3.462c.969 0 1.371 1.24.588 1.81l-2.8 2.034a1 1 0 00-.364 1.118l1.07 3.292c.3.921-.755 1.688-1.54 1.118l-2.8-2.034a1 1 0 00-1.175 0l-2.8 2.034c-.784.57-1.838-.197-1.539-1.118l1.07-3.292a1 1 0 00-.364-1.118L2.98 8.72c-.783-.57-.38-1.81.588-1.81h3.461a1 1 0 00.951-.69l1.07-3.292z\" />\n                        </svg>\n                        <span id=\"github-stars\">0</span>\n                    </div>\n                </div>\n            </nav>\n        </div>\n    </div>\n</header>\n\n\n\n================================================\nFile: src/server/templates/components/result.jinja\n================================================\n<script>\n    function getFileName(line) {\n        // Skips \"|\", \"â””\", \"â”œ\" found in file tree\n        const index = line.search(/[a-zA-Z0-9]/);\n        return line.substring(index).trim();\n    }\n\n    function toggleFile(element) {\n        const patternInput = document.getElementById(\"pattern\");\n        const patternFiles = patternInput.value ? patternInput.value.split(\",\").map(item => item.trim()) : [];\n\n        if (element.textContent.includes(\"Directory structure:\")) {\n            return;\n        }\n\n        element.classList.toggle('line-through');\n        element.classList.toggle('text-gray-500');\n\n        const fileName = getFileName(element.textContent);\n        const fileIndex = patternFiles.indexOf(fileName);\n\n        if (fileIndex !== -1) {\n            patternFiles.splice(fileIndex, 1);\n        } else {\n            patternFiles.push(fileName);\n        }\n\n        patternInput.value = patternFiles.join(\", \");\n    }\n</script>\n{% if result %}\n    <div class=\"mt-10\" data-results>\n        <div class=\"relative\">\n            <div class=\"w-full h-full absolute inset-0 bg-gray-900 rounded-xl translate-y-2 translate-x-2\"></div>\n            <div class=\"bg-[#fafafa] rounded-xl border-[3px] border-gray-900 p-6 relative z-20 space-y-6\">\n                <!-- Summary and Directory Structure -->\n                <div class=\"grid grid-cols-1 md:grid-cols-12 gap-6\">\n                    <!-- Summary Column -->\n                    <div class=\"md:col-span-5\">\n                        <div class=\"flex justify-between items-center mb-4 py-2\">\n                            <h3 class=\"text-lg font-bold text-gray-900\">Summary</h3>\n                        </div>\n                        <div class=\"relative\">\n                            <div class=\"w-full h-full rounded bg-gray-900 translate-y-1 translate-x-1 absolute inset-0\"></div>\n                            <textarea class=\"w-full h-[160px] p-4 bg-[#fff4da] border-[3px] border-gray-900 rounded font-mono text-sm resize-none focus:outline-none relative z-10\"\n                                      readonly>{{ summary }}</textarea>\n                        </div>\n                        {% if ingest_id %}\n                            <div class=\"relative mt-4 inline-block group\">\n                                <div class=\"w-full h-full rounded bg-gray-900 translate-y-1 translate-x-1 absolute inset-0\"></div>\n                                <a href=\"/download/{{ ingest_id }}\"\n                                   class=\"inline-flex items-center px-4 py-2 bg-[#ffc480] border-[3px] border-gray-900 text-gray-900 rounded group-hover:-translate-y-px group-hover:-translate-x-px transition-transform relative z-10\">\n                                    <svg class=\"w-4 h-4 mr-2\"\n                                         fill=\"none\"\n                                         stroke=\"currentColor\"\n                                         viewBox=\"0 0 24 24\">\n                                        <path stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" d=\"M4 16v1a3 3 0 003 3h10a3 3 0 003-3v-1m-4-4l-4 4m0 0l-4-4m4 4V4\" />\n                                    </svg>\n                                    Download\n                                </a>\n                            </div>\n                            <div class=\"relative mt-4 inline-block group ml-4\">\n                                <div class=\"w-full h-full rounded bg-gray-900 translate-y-1 translate-x-1 absolute inset-0\"></div>\n                                <button onclick=\"copyFullDigest()\"\n                                        class=\"inline-flex items-center px-4 py-2 bg-[#ffc480] border-[3px] border-gray-900 text-gray-900 rounded group-hover:-translate-y-px group-hover:-translate-x-px transition-transform relative z-10\">\n                                    <svg class=\"w-4 h-4 mr-2\"\n                                         fill=\"none\"\n                                         stroke=\"currentColor\"\n                                         viewBox=\"0 0 24 24\">\n                                        <path stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" d=\"M8 5H6a2 2 0 00-2 2v12a2 2 0 002 2h10a2 2 0 002-2v-1M8 5a2 2 0 002 2h2a2 2 0 002-2M8 5a2 2 0 012-2h2a2 2 0 012 2m0 0h2a2 2 0 012 2v3m2 4H10m0 0l3-3m-3 3l3 3\" />\n                                    </svg>\n                                    Copy all\n                                </button>\n                            </div>\n                        {% endif %}\n                    </div>\n                    <!-- Directory Structure Column -->\n                    <div class=\"md:col-span-7\">\n                        <div class=\"flex justify-between items-center mb-4\">\n                            <h3 class=\"text-lg font-bold text-gray-900\">Directory Structure</h3>\n                            <div class=\"relative group\">\n                                <div class=\"w-full h-full rounded bg-gray-900 translate-y-1 translate-x-1 absolute inset-0\"></div>\n                                <button onclick=\"copyText('directory-structure')\"\n                                        class=\"px-4 py-2 bg-[#ffc480] border-[3px] border-gray-900 text-gray-900 rounded group-hover:-translate-y-px group-hover:-translate-x-px transition-transform relative z-10 flex items-center gap-2\">\n                                    <svg class=\"w-4 h-4\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                                        <path stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" d=\"M8 5H6a2 2 0 00-2 2v12a2 2 0 002 2h10a2 2 0 002-2v-1M8 5a2 2 0 002 2h2a2 2 0 002-2M8 5a2 2 0 012-2h2a2 2 0 012 2m0 0h2a2 2 0 012 2v3m2 4H10m0 0l3-3m-3 3l3 3\" />\n                                    </svg>\n                                    Copy\n                                </button>\n                            </div>\n                        </div>\n                        <div class=\"relative\">\n                            <div class=\"w-full h-full rounded bg-gray-900 translate-y-1 translate-x-1 absolute inset-0\"></div>\n                            <div class=\"directory-structure w-full p-4 bg-[#fff4da] border-[3px] border-gray-900 rounded font-mono text-sm resize-y focus:outline-none relative z-10 h-[215px] overflow-auto\"\n                                 id=\"directory-structure-container\"\n                                 readonly>\n                                <input type=\"hidden\" id=\"directory-structure-content\" value=\"{{ tree }}\" />\n                                {% for line in tree.splitlines() %}\n                                    <pre name=\"tree-line\"\n                                         class=\"cursor-pointer hover:line-through hover:text-gray-500\"\n                                         onclick=\"toggleFile(this)\">{{ line }}</pre>\n                                {% endfor %}\n                            </div>\n                        </div>\n                    </div>\n                </div>\n                <!-- Full Digest -->\n                <div>\n                    <div class=\"flex justify-between items-center mb-4\">\n                        <h3 class=\"text-lg font-bold text-gray-900\">Files Content</h3>\n                        <div class=\"relative group\">\n                            <div class=\"w-full h-full rounded bg-gray-900 translate-y-1 translate-x-1 absolute inset-0\"></div>\n                            <button onclick=\"copyText('result-text')\"\n                                    class=\"px-4 py-2 bg-[#ffc480] border-[3px] border-gray-900 text-gray-900 rounded group-hover:-translate-y-px group-hover:-translate-x-px transition-transform relative z-10 flex items-center gap-2\">\n                                <svg class=\"w-4 h-4\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                                    <path stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" d=\"M8 5H6a2 2 0 00-2 2v12a2 2 0 002 2h10a2 2 0 002-2v-1M8 5a2 2 0 002 2h2a2 2 0 002-2M8 5a2 2 0 012-2h2a2 2 0 012 2m0 0h2a2 2 0 012 2v3m2 4H10m0 0l3-3m-3 3l3 3\" />\n                                </svg>\n                                Copy\n                            </button>\n                        </div>\n                    </div>\n                    <div class=\"relative\">\n                        <div class=\"w-full h-full rounded bg-gray-900 translate-y-1 translate-x-1 absolute inset-0\"></div>\n                        <textarea class=\"result-text w-full p-4 bg-[#fff4da] border-[3px] border-gray-900 rounded font-mono text-sm resize-y focus:outline-none relative z-10\"\n                                  style=\"min-height: {{ '600px' if content else 'calc(100vh-800px)' }}\"\n                                  readonly>{{ content }}</textarea>\n                    </div>\n                </div>\n            </div>\n        </div>\n    </div>\n{% endif %}\n\n\n\n================================================\nFile: src/static/robots.txt\n================================================\nUser-agent: *\nAllow: /\nAllow: /api/\nAllow: /cyclotruc/gitingest/\n\n\n\n================================================\nFile: src/static/js/utils.js\n================================================\n// Copy functionality\nfunction copyText(className) {\n    let textToCopy;\n\n    if (className === 'directory-structure') {\n        // For directory structure, get the hidden input value\n        const hiddenInput = document.getElementById('directory-structure-content');\n        if (!hiddenInput) return;\n        textToCopy = hiddenInput.value;\n    } else {\n        // For other elements, get the textarea value\n        const textarea = document.querySelector('.' + className);\n        if (!textarea) return;\n        textToCopy = textarea.value;\n    }\n\n    const button = document.querySelector(`button[onclick=\"copyText('${className}')\"]`);\n    if (!button) return;\n\n    // Copy text\n    navigator.clipboard.writeText(textToCopy)\n        .then(() => {\n            // Store original content\n            const originalContent = button.innerHTML;\n\n            // Change button content\n            button.innerHTML = 'Copied!';\n\n            // Reset after 1 second\n            setTimeout(() => {\n                button.innerHTML = originalContent;\n            }, 1000);\n        })\n        .catch(err => {\n            // Show error in button\n            const originalContent = button.innerHTML;\n            button.innerHTML = 'Failed to copy';\n            setTimeout(() => {\n                button.innerHTML = originalContent;\n            }, 1000);\n        });\n}\n\n\nfunction handleSubmit(event, showLoading = false) {\n    event.preventDefault();\n    const form = event.target || document.getElementById('ingestForm');\n    if (!form) return;\n\n    const submitButton = form.querySelector('button[type=\"submit\"]');\n    if (!submitButton) return;\n\n    const formData = new FormData(form);\n\n    // Update file size\n    const slider = document.getElementById('file_size');\n    if (slider) {\n        formData.delete('max_file_size');\n        formData.append('max_file_size', slider.value);\n    }\n\n    // Update pattern type and pattern\n    const patternType = document.getElementById('pattern_type');\n    const pattern = document.getElementById('pattern');\n    if (patternType && pattern) {\n        formData.delete('pattern_type');\n        formData.delete('pattern');\n        formData.append('pattern_type', patternType.value);\n        formData.append('pattern', pattern.value);\n    }\n\n    const originalContent = submitButton.innerHTML;\n    const currentStars = document.getElementById('github-stars')?.textContent;\n\n    if (showLoading) {\n        submitButton.disabled = true;\n        submitButton.innerHTML = `\n            <div class=\"flex items-center justify-center\">\n                <svg class=\"animate-spin h-5 w-5 text-gray-900\" xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\">\n                    <circle class=\"opacity-25\" cx=\"12\" cy=\"12\" r=\"10\" stroke=\"currentColor\" stroke-width=\"4\"></circle>\n                    <path class=\"opacity-75\" fill=\"currentColor\" d=\"M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z\"></path>\n                </svg>\n                <span class=\"ml-2\">Processing...</span>\n            </div>\n        `;\n        submitButton.classList.add('bg-[#ffb14d]');\n    }\n\n    // Submit the form\n    fetch(form.action, {\n        method: 'POST',\n        body: formData\n    })\n        .then(response => response.text())\n        .then(html => {\n            // Store the star count before updating the DOM\n            const starCount = currentStars;\n\n            // Replace the entire body content with the new HTML\n            document.body.innerHTML = html;\n\n            // Wait for next tick to ensure DOM is updated\n            setTimeout(() => {\n                // Reinitialize slider functionality\n                initializeSlider();\n\n                const starsElement = document.getElementById('github-stars');\n                if (starsElement && starCount) {\n                    starsElement.textContent = starCount;\n                }\n\n                // Scroll to results if they exist\n                const resultsSection = document.querySelector('[data-results]');\n                if (resultsSection) {\n                    resultsSection.scrollIntoView({ behavior: 'smooth', block: 'start' });\n                }\n            }, 0);\n        })\n        .catch(error => {\n            submitButton.disabled = false;\n            submitButton.innerHTML = originalContent;\n        });\n}\n\nfunction copyFullDigest() {\n    const directoryStructure = document.getElementById('directory-structure-content').value;\n    const filesContent = document.querySelector('.result-text').value;\n    const fullDigest = `${directoryStructure}\\n\\nFiles Content:\\n\\n${filesContent}`;\n    const button = document.querySelector('[onclick=\"copyFullDigest()\"]');\n    const originalText = button.innerHTML;\n\n    navigator.clipboard.writeText(fullDigest).then(() => {\n        button.innerHTML = `\n            <svg class=\"w-4 h-4 mr-2\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n                <path stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" d=\"M5 13l4 4L19 7\"></path>\n            </svg>\n            Copied!\n        `;\n\n        setTimeout(() => {\n            button.innerHTML = originalText;\n        }, 2000);\n    }).catch(err => {\n        console.error('Failed to copy text: ', err);\n    });\n}\n\n// Add the logSliderToSize helper function\nfunction logSliderToSize(position) {\n    const minp = 0;\n    const maxp = 500;\n    const minv = Math.log(1);\n    const maxv = Math.log(102400);\n\n    const value = Math.exp(minv + (maxv - minv) * Math.pow(position / maxp, 1.5));\n    return Math.round(value);\n}\n\n// Move slider initialization to a separate function\nfunction initializeSlider() {\n    const slider = document.getElementById('file_size');\n    const sizeValue = document.getElementById('size_value');\n\n    if (!slider || !sizeValue) return;\n\n    function updateSlider() {\n        const value = logSliderToSize(slider.value);\n        sizeValue.textContent = formatSize(value);\n        slider.style.backgroundSize = `${(slider.value / slider.max) * 100}% 100%`;\n    }\n\n    // Update on slider change\n    slider.addEventListener('input', updateSlider);\n\n    // Initialize slider position\n    updateSlider();\n}\n\n// Add helper function for formatting size\nfunction formatSize(sizeInKB) {\n    if (sizeInKB >= 1024) {\n        return Math.round(sizeInKB / 1024) + 'mb';\n    }\n    return Math.round(sizeInKB) + 'kb';\n}\n\n// Initialize slider on page load\ndocument.addEventListener('DOMContentLoaded', initializeSlider);\n\n// Make sure these are available globally\nwindow.copyText = copyText;\n\nwindow.handleSubmit = handleSubmit;\nwindow.initializeSlider = initializeSlider;\nwindow.formatSize = formatSize;\n\n// Add this new function\nfunction setupGlobalEnterHandler() {\n    document.addEventListener('keydown', function (event) {\n        if (event.key === 'Enter' && !event.target.matches('textarea')) {\n            const form = document.getElementById('ingestForm');\n            if (form) {\n                handleSubmit(new Event('submit'), true);\n            }\n        }\n    });\n}\n\n// Add to the DOMContentLoaded event listener\ndocument.addEventListener('DOMContentLoaded', () => {\n    initializeSlider();\n    setupGlobalEnterHandler();\n});\n\n\n\n================================================\nFile: tests/__init__.py\n================================================\n\n\n\n================================================\nFile: tests/conftest.py\n================================================\n\"\"\"\nFixtures for tests.\n\nThis file provides shared fixtures for creating sample queries, a temporary directory structure, and a helper function\nto write `.ipynb` notebooks for testing notebook utilities.\n\"\"\"\n\nimport json\nfrom pathlib import Path\nfrom typing import Any, Callable, Dict\n\nimport pytest\n\nfrom gitingest.query_parsing import IngestionQuery\n\nWriteNotebookFunc = Callable[[str, Dict[str, Any]], Path]\n\n\n@pytest.fixture\ndef sample_query() -> IngestionQuery:\n    \"\"\"\n    Provide a default `IngestionQuery` object for use in tests.\n\n    This fixture returns a `IngestionQuery` pre-populated with typical fields and some default ignore patterns.\n\n    Returns\n    -------\n    IngestionQuery\n        The sample `IngestionQuery` object.\n    \"\"\"\n    return IngestionQuery(\n        user_name=\"test_user\",\n        repo_name=\"test_repo\",\n        url=None,\n        subpath=\"/\",\n        local_path=Path(\"/tmp/test_repo\").resolve(),\n        slug=\"test_user/test_repo\",\n        id=\"id\",\n        branch=\"main\",\n        max_file_size=1_000_000,\n        ignore_patterns={\"*.pyc\", \"__pycache__\", \".git\"},\n        include_patterns=None,\n    )\n\n\n@pytest.fixture\ndef temp_directory(tmp_path: Path) -> Path:\n    \"\"\"\n    Create a temporary directory structure for testing repository scanning.\n\n    The structure includes:\n    test_repo/\n    â”œâ”€â”€ file1.txt\n    â”œâ”€â”€ file2.py\n    â”œâ”€â”€ src/\n    â”‚   â”œâ”€â”€ subfile1.txt\n    â”‚   â”œâ”€â”€ subfile2.py\n    â”‚   â””â”€â”€ subdir/\n    â”‚       â”œâ”€â”€ file_subdir.txt\n    â”‚       â””â”€â”€ file_subdir.py\n    â”œâ”€â”€ dir1/\n    â”‚   â””â”€â”€ file_dir1.txt\n    â””â”€â”€ dir2/\n        â””â”€â”€ file_dir2.txt\n\n    Parameters\n    ----------\n    tmp_path : Path\n        The temporary directory path provided by the `tmp_path` fixture.\n\n    Returns\n    -------\n    Path\n        The path to the created `test_repo` directory.\n    \"\"\"\n    test_dir = tmp_path / \"test_repo\"\n    test_dir.mkdir()\n\n    # Root files\n    (test_dir / \"file1.txt\").write_text(\"Hello World\")\n    (test_dir / \"file2.py\").write_text(\"print('Hello')\")\n\n    # src directory and its files\n    src_dir = test_dir / \"src\"\n    src_dir.mkdir()\n    (src_dir / \"subfile1.txt\").write_text(\"Hello from src\")\n    (src_dir / \"subfile2.py\").write_text(\"print('Hello from src')\")\n\n    # src/subdir and its files\n    subdir = src_dir / \"subdir\"\n    subdir.mkdir()\n    (subdir / \"file_subdir.txt\").write_text(\"Hello from subdir\")\n    (subdir / \"file_subdir.py\").write_text(\"print('Hello from subdir')\")\n\n    # dir1 and its file\n    dir1 = test_dir / \"dir1\"\n    dir1.mkdir()\n    (dir1 / \"file_dir1.txt\").write_text(\"Hello from dir1\")\n\n    # dir2 and its file\n    dir2 = test_dir / \"dir2\"\n    dir2.mkdir()\n    (dir2 / \"file_dir2.txt\").write_text(\"Hello from dir2\")\n\n    return test_dir\n\n\n@pytest.fixture\ndef write_notebook(tmp_path: Path) -> WriteNotebookFunc:\n    \"\"\"\n    Provide a helper function to write a `.ipynb` notebook file with the given content.\n\n    Parameters\n    ----------\n    tmp_path : Path\n        The temporary directory path provided by the `tmp_path` fixture.\n\n    Returns\n    -------\n    WriteNotebookFunc\n        A callable that accepts a filename and a dictionary (representing JSON notebook data), writes it to a `.ipynb`\n        file, and returns the path to the file.\n    \"\"\"\n\n    def _write_notebook(name: str, content: Dict[str, Any]) -> Path:\n        notebook_path = tmp_path / name\n        with notebook_path.open(mode=\"w\", encoding=\"utf-8\") as f:\n            json.dump(content, f)\n        return notebook_path\n\n    return _write_notebook\n\n\n\n================================================\nFile: tests/test_cli.py\n================================================\n\"\"\"Tests for the gitingest cli.\"\"\"\n\nimport os\n\nfrom click.testing import CliRunner\n\nfrom gitingest.cli import main\nfrom gitingest.config import MAX_FILE_SIZE, OUTPUT_FILE_NAME\n\n\ndef test_cli_with_default_options():\n    runner = CliRunner()\n    result = runner.invoke(main, [\"./\"])\n    output_lines = result.output.strip().split(\"\\n\")\n    assert f\"Analysis complete! Output written to: {OUTPUT_FILE_NAME}\" in output_lines\n    assert os.path.exists(OUTPUT_FILE_NAME), f\"Output file was not created at {OUTPUT_FILE_NAME}\"\n\n    os.remove(OUTPUT_FILE_NAME)\n\n\ndef test_cli_with_options():\n    runner = CliRunner()\n    result = runner.invoke(\n        main,\n        [\n            \"./\",\n            \"--output\",\n            str(OUTPUT_FILE_NAME),\n            \"--max-size\",\n            str(MAX_FILE_SIZE),\n            \"--exclude-pattern\",\n            \"tests/\",\n            \"--include-pattern\",\n            \"src/\",\n        ],\n    )\n    output_lines = result.output.strip().split(\"\\n\")\n    assert f\"Analysis complete! Output written to: {OUTPUT_FILE_NAME}\" in output_lines\n    assert os.path.exists(OUTPUT_FILE_NAME), f\"Output file was not created at {OUTPUT_FILE_NAME}\"\n\n    os.remove(OUTPUT_FILE_NAME)\n\n\n\n================================================\nFile: tests/test_flow_integration.py\n================================================\n\"\"\"Integration tests covering core functionalities, edge cases, and concurrency handling.\"\"\"\n\nimport shutil\nfrom concurrent.futures import ThreadPoolExecutor\nfrom pathlib import Path\nfrom unittest.mock import patch\n\nimport pytest\nfrom fastapi.testclient import TestClient\n\nfrom src.server.main import app\n\nBASE_DIR = Path(__file__).resolve().parent.parent\nTEMPLATE_DIR = BASE_DIR / \"src\" / \"templates\"\n\n\n@pytest.fixture(scope=\"module\")\ndef test_client():\n    \"\"\"Create a test client fixture.\"\"\"\n    with TestClient(app) as client_instance:\n        client_instance.headers.update({\"Host\": \"localhost\"})\n        yield client_instance\n\n\n@pytest.fixture(scope=\"module\", autouse=True)\ndef mock_static_files():\n    \"\"\"Mock the static file mount to avoid directory errors.\"\"\"\n    with patch(\"src.server.main.StaticFiles\") as mock_static:\n        mock_static.return_value = None  # Mocks the StaticFiles response\n        yield mock_static\n\n\n@pytest.fixture(scope=\"module\", autouse=True)\ndef mock_templates():\n    \"\"\"Mock Jinja2 template rendering to bypass actual file loading.\"\"\"\n    with patch(\"starlette.templating.Jinja2Templates.TemplateResponse\") as mock_template:\n        mock_template.return_value = \"Mocked Template Response\"\n        yield mock_template\n\n\ndef cleanup_temp_directories():\n    temp_dir = Path(\"/tmp/gitingest\")\n    if temp_dir.exists():\n        try:\n            shutil.rmtree(temp_dir)\n        except PermissionError as exc:\n            print(f\"Error cleaning up {temp_dir}: {exc}\")\n\n\n@pytest.fixture(scope=\"module\", autouse=True)\ndef cleanup():\n    \"\"\"Cleanup temporary directories after tests.\"\"\"\n    yield\n    cleanup_temp_directories()\n\n\n@pytest.mark.asyncio\nasync def test_remote_repository_analysis(request):\n    \"\"\"Test the complete flow of analyzing a remote repository.\"\"\"\n    client = request.getfixturevalue(\"test_client\")\n    form_data = {\n        \"input_text\": \"https://github.com/octocat/Hello-World\",\n        \"max_file_size\": \"243\",\n        \"pattern_type\": \"exclude\",\n        \"pattern\": \"\",\n    }\n\n    response = client.post(\"/\", data=form_data)\n    assert response.status_code == 200, f\"Form submission failed: {response.text}\"\n    assert \"Mocked Template Response\" in response.text\n\n\n@pytest.mark.asyncio\nasync def test_invalid_repository_url(request):\n    \"\"\"Test handling of an invalid repository URL.\"\"\"\n    client = request.getfixturevalue(\"test_client\")\n    form_data = {\n        \"input_text\": \"https://github.com/nonexistent/repo\",\n        \"max_file_size\": \"243\",\n        \"pattern_type\": \"exclude\",\n        \"pattern\": \"\",\n    }\n\n    response = client.post(\"/\", data=form_data)\n    assert response.status_code == 200, f\"Request failed: {response.text}\"\n    assert \"Mocked Template Response\" in response.text\n\n\n@pytest.mark.asyncio\nasync def test_large_repository(request):\n    \"\"\"Simulate analysis of a large repository with nested folders.\"\"\"\n    client = request.getfixturevalue(\"test_client\")\n    form_data = {\n        \"input_text\": \"https://github.com/large/repo-with-many-files\",\n        \"max_file_size\": \"243\",\n        \"pattern_type\": \"exclude\",\n        \"pattern\": \"\",\n    }\n\n    response = client.post(\"/\", data=form_data)\n    assert response.status_code == 200, f\"Request failed: {response.text}\"\n    assert \"Mocked Template Response\" in response.text\n\n\n@pytest.mark.asyncio\nasync def test_concurrent_requests(request):\n    \"\"\"Test handling of multiple concurrent requests.\"\"\"\n    client = request.getfixturevalue(\"test_client\")\n\n    def make_request():\n        form_data = {\n            \"input_text\": \"https://github.com/octocat/Hello-World\",\n            \"max_file_size\": \"243\",\n            \"pattern_type\": \"exclude\",\n            \"pattern\": \"\",\n        }\n        response = client.post(\"/\", data=form_data)\n        assert response.status_code == 200, f\"Request failed: {response.text}\"\n        assert \"Mocked Template Response\" in response.text\n\n    with ThreadPoolExecutor(max_workers=5) as executor:\n        futures = [executor.submit(make_request) for _ in range(5)]\n        for future in futures:\n            future.result()\n\n\n@pytest.mark.asyncio\nasync def test_large_file_handling(request):\n    \"\"\"Test handling of repositories with large files.\"\"\"\n    client = request.getfixturevalue(\"test_client\")\n    form_data = {\n        \"input_text\": \"https://github.com/octocat/Hello-World\",\n        \"max_file_size\": \"1\",\n        \"pattern_type\": \"exclude\",\n        \"pattern\": \"\",\n    }\n\n    response = client.post(\"/\", data=form_data)\n    assert response.status_code == 200, f\"Request failed: {response.text}\"\n    assert \"Mocked Template Response\" in response.text\n\n\n@pytest.mark.asyncio\nasync def test_repository_with_patterns(request):\n    \"\"\"Test repository analysis with include/exclude patterns.\"\"\"\n    client = request.getfixturevalue(\"test_client\")\n    form_data = {\n        \"input_text\": \"https://github.com/octocat/Hello-World\",\n        \"max_file_size\": \"243\",\n        \"pattern_type\": \"include\",\n        \"pattern\": \"*.md\",\n    }\n\n    response = client.post(\"/\", data=form_data)\n    assert response.status_code == 200, f\"Request failed: {response.text}\"\n    assert \"Mocked Template Response\" in response.text\n\n\n\n================================================\nFile: tests/test_ingestion.py\n================================================\n\"\"\"\nTests for the `query_ingestion` module.\n\nThese tests validate directory scanning, file content extraction, notebook handling, and the overall ingestion logic,\nincluding filtering patterns and subpaths.\n\"\"\"\n\nfrom pathlib import Path\n\nfrom gitingest.ingestion import ingest_query\nfrom gitingest.query_parsing import IngestionQuery\n\n\ndef test_run_ingest_query(temp_directory: Path, sample_query: IngestionQuery) -> None:\n    \"\"\"\n    Test `ingest_query` to ensure it processes the directory and returns expected results.\n\n    Given a directory with .txt and .py files:\n    When `ingest_query` is invoked,\n    Then it should produce a summary string listing the files analyzed and a combined content string.\n    \"\"\"\n    sample_query.local_path = temp_directory\n    sample_query.subpath = \"/\"\n    sample_query.type = None\n\n    summary, _, content = ingest_query(sample_query)\n\n    assert \"Repository: test_user/test_repo\" in summary\n    assert \"Files analyzed: 8\" in summary\n\n    # Check presence of key files in the content\n    assert \"src/subfile1.txt\" in content\n    assert \"src/subfile2.py\" in content\n    assert \"src/subdir/file_subdir.txt\" in content\n    assert \"src/subdir/file_subdir.py\" in content\n    assert \"file1.txt\" in content\n    assert \"file2.py\" in content\n    assert \"dir1/file_dir1.txt\" in content\n    assert \"dir2/file_dir2.txt\" in content\n\n\n# TODO: Additional tests:\n# - Multiple include patterns, e.g. [\"*.txt\", \"*.py\"] or [\"/src/*\", \"*.txt\"].\n# - Edge cases with weird file names or deep subdirectory structures.\n# TODO : def test_include_txt_pattern\n# TODO : def test_include_nonexistent_extension\n\n\n\n================================================\nFile: tests/test_notebook_utils.py\n================================================\n\"\"\"\nTests for the `notebook_utils` module.\n\nThese tests validate how notebooks are processed into Python-like output, ensuring that markdown/raw cells are\nconverted to triple-quoted blocks, code cells remain executable code, and various edge cases (multiple worksheets,\nempty cells, outputs, etc.) are handled appropriately.\n\"\"\"\n\nimport pytest\n\nfrom gitingest.utils.notebook_utils import process_notebook\nfrom tests.conftest import WriteNotebookFunc\n\n\ndef test_process_notebook_all_cells(write_notebook: WriteNotebookFunc) -> None:\n    \"\"\"\n    Test processing a notebook containing markdown, code, and raw cells.\n\n    Given a notebook with:\n      - One markdown cell\n      - One code cell\n      - One raw cell\n    When `process_notebook` is invoked,\n    Then markdown and raw cells should appear in triple-quoted blocks, and code cells remain as normal code.\n    \"\"\"\n    notebook_content = {\n        \"cells\": [\n            {\"cell_type\": \"markdown\", \"source\": [\"# Markdown cell\"]},\n            {\"cell_type\": \"code\", \"source\": ['print(\"Hello Code\")']},\n            {\"cell_type\": \"raw\", \"source\": [\"<raw content>\"]},\n        ]\n    }\n    nb_path = write_notebook(\"all_cells.ipynb\", notebook_content)\n    result = process_notebook(nb_path)\n\n    assert result.count('\"\"\"') == 4, \"Two non-code cells => 2 triple-quoted blocks => 4 total triple quotes.\"\n\n    # Ensure markdown and raw cells are in triple quotes\n    assert \"# Markdown cell\" in result\n    assert \"<raw content>\" in result\n\n    # Ensure code cell is not in triple quotes\n    assert 'print(\"Hello Code\")' in result\n    assert '\"\"\"\\nprint(\"Hello Code\")\\n\"\"\"' not in result\n\n\ndef test_process_notebook_with_worksheets(write_notebook: WriteNotebookFunc) -> None:\n    \"\"\"\n    Test a notebook containing the (as of IPEP-17 deprecated) 'worksheets' key.\n\n    Given a notebook that uses the 'worksheets' key with a single worksheet,\n    When `process_notebook` is called,\n    Then a `DeprecationWarning` should be raised, and the content should match an equivalent notebook\n    that has top-level 'cells'.\n    \"\"\"\n    with_worksheets = {\n        \"worksheets\": [\n            {\n                \"cells\": [\n                    {\"cell_type\": \"markdown\", \"source\": [\"# Markdown cell\"]},\n                    {\"cell_type\": \"code\", \"source\": ['print(\"Hello Code\")']},\n                    {\"cell_type\": \"raw\", \"source\": [\"<raw content>\"]},\n                ]\n            }\n        ]\n    }\n    without_worksheets = with_worksheets[\"worksheets\"][0]  # same, but no 'worksheets' key\n\n    nb_with = write_notebook(\"with_worksheets.ipynb\", with_worksheets)\n    nb_without = write_notebook(\"without_worksheets.ipynb\", without_worksheets)\n\n    with pytest.warns(DeprecationWarning, match=\"Worksheets are deprecated as of IPEP-17.\"):\n        result_with = process_notebook(nb_with)\n\n    # Should not raise a warning\n    result_without = process_notebook(nb_without)\n\n    assert result_with == result_without, \"Content from the single worksheet should match the top-level equivalent.\"\n\n\ndef test_process_notebook_multiple_worksheets(write_notebook: WriteNotebookFunc) -> None:\n    \"\"\"\n    Test a notebook containing multiple 'worksheets'.\n\n    Given a notebook with two worksheets:\n      - First with a markdown cell\n      - Second with a code cell\n    When `process_notebook` is called,\n    Then a warning about multiple worksheets should be raised, and the second worksheet's content should appear\n    in the final output.\n    \"\"\"\n    multi_worksheets = {\n        \"worksheets\": [\n            {\"cells\": [{\"cell_type\": \"markdown\", \"source\": [\"# First Worksheet\"]}]},\n            {\"cells\": [{\"cell_type\": \"code\", \"source\": [\"# Second Worksheet\"]}]},\n        ]\n    }\n\n    single_worksheet = {\n        \"worksheets\": [\n            {\"cells\": [{\"cell_type\": \"markdown\", \"source\": [\"# First Worksheet\"]}]},\n        ]\n    }\n\n    nb_multi = write_notebook(\"multiple_worksheets.ipynb\", multi_worksheets)\n    nb_single = write_notebook(\"single_worksheet.ipynb\", single_worksheet)\n\n    # Expect DeprecationWarning + UserWarning\n    with pytest.warns(\n        DeprecationWarning, match=\"Worksheets are deprecated as of IPEP-17. Consider updating the notebook.\"\n    ):\n        with pytest.warns(\n            UserWarning, match=\"Multiple worksheets detected. Combining all worksheets into a single script.\"\n        ):\n            result_multi = process_notebook(nb_multi)\n\n    # Expect DeprecationWarning only\n    with pytest.warns(\n        DeprecationWarning, match=\"Worksheets are deprecated as of IPEP-17. Consider updating the notebook.\"\n    ):\n        result_single = process_notebook(nb_single)\n\n    assert result_multi != result_single, \"Two worksheets should produce more content than one.\"\n    assert len(result_multi) > len(result_single), \"The multi-worksheet notebook should have extra code content.\"\n    assert \"# First Worksheet\" in result_single\n    assert \"# Second Worksheet\" not in result_single\n    assert \"# First Worksheet\" in result_multi\n    assert \"# Second Worksheet\" in result_multi\n\n\ndef test_process_notebook_code_only(write_notebook: WriteNotebookFunc) -> None:\n    \"\"\"\n    Test a notebook containing only code cells.\n\n    Given a notebook with code cells only:\n    When `process_notebook` is called,\n    Then no triple quotes should appear in the output.\n    \"\"\"\n    notebook_content = {\n        \"cells\": [\n            {\"cell_type\": \"code\", \"source\": [\"print('Code Cell 1')\"]},\n            {\"cell_type\": \"code\", \"source\": [\"x = 42\"]},\n        ]\n    }\n    nb_path = write_notebook(\"code_only.ipynb\", notebook_content)\n    result = process_notebook(nb_path)\n\n    assert '\"\"\"' not in result, \"No triple quotes expected when there are only code cells.\"\n    assert \"print('Code Cell 1')\" in result\n    assert \"x = 42\" in result\n\n\ndef test_process_notebook_markdown_only(write_notebook: WriteNotebookFunc) -> None:\n    \"\"\"\n    Test a notebook with only markdown cells.\n\n    Given a notebook with two markdown cells:\n    When `process_notebook` is called,\n    Then each markdown cell should become a triple-quoted block (2 blocks => 4 triple quotes total).\n    \"\"\"\n    notebook_content = {\n        \"cells\": [\n            {\"cell_type\": \"markdown\", \"source\": [\"# Markdown Header\"]},\n            {\"cell_type\": \"markdown\", \"source\": [\"Some more markdown.\"]},\n        ]\n    }\n    nb_path = write_notebook(\"markdown_only.ipynb\", notebook_content)\n    result = process_notebook(nb_path)\n\n    assert result.count('\"\"\"') == 4, \"Two markdown cells => 2 blocks => 4 triple quotes total.\"\n    assert \"# Markdown Header\" in result\n    assert \"Some more markdown.\" in result\n\n\ndef test_process_notebook_raw_only(write_notebook: WriteNotebookFunc) -> None:\n    \"\"\"\n    Test a notebook with only raw cells.\n\n    Given two raw cells:\n    When `process_notebook` is called,\n    Then each raw cell should become a triple-quoted block (2 blocks => 4 triple quotes total).\n    \"\"\"\n    notebook_content = {\n        \"cells\": [\n            {\"cell_type\": \"raw\", \"source\": [\"Raw content line 1\"]},\n            {\"cell_type\": \"raw\", \"source\": [\"Raw content line 2\"]},\n        ]\n    }\n    nb_path = write_notebook(\"raw_only.ipynb\", notebook_content)\n    result = process_notebook(nb_path)\n\n    assert result.count('\"\"\"') == 4, \"Two raw cells => 2 blocks => 4 triple quotes.\"\n    assert \"Raw content line 1\" in result\n    assert \"Raw content line 2\" in result\n\n\ndef test_process_notebook_empty_cells(write_notebook: WriteNotebookFunc) -> None:\n    \"\"\"\n    Test that cells with an empty 'source' are skipped.\n\n    Given a notebook with 4 cells, 3 of which have empty `source`:\n    When `process_notebook` is called,\n    Then only the non-empty cell should appear in the output (1 block => 2 triple quotes).\n    \"\"\"\n    notebook_content = {\n        \"cells\": [\n            {\"cell_type\": \"markdown\", \"source\": []},\n            {\"cell_type\": \"code\", \"source\": []},\n            {\"cell_type\": \"raw\", \"source\": []},\n            {\"cell_type\": \"markdown\", \"source\": [\"# Non-empty markdown\"]},\n        ]\n    }\n    nb_path = write_notebook(\"empty_cells.ipynb\", notebook_content)\n    result = process_notebook(nb_path)\n\n    assert result.count('\"\"\"') == 2, \"Only one non-empty cell => 1 block => 2 triple quotes\"\n    assert \"# Non-empty markdown\" in result\n\n\ndef test_process_notebook_invalid_cell_type(write_notebook: WriteNotebookFunc) -> None:\n    \"\"\"\n    Test a notebook with an unknown cell type.\n\n    Given a notebook cell whose `cell_type` is unrecognized:\n    When `process_notebook` is called,\n    Then a ValueError should be raised.\n    \"\"\"\n    notebook_content = {\n        \"cells\": [\n            {\"cell_type\": \"markdown\", \"source\": [\"# Valid markdown\"]},\n            {\"cell_type\": \"unknown\", \"source\": [\"Unrecognized cell type\"]},\n        ]\n    }\n    nb_path = write_notebook(\"invalid_cell_type.ipynb\", notebook_content)\n\n    with pytest.raises(ValueError, match=\"Unknown cell type: unknown\"):\n        process_notebook(nb_path)\n\n\ndef test_process_notebook_with_output(write_notebook: WriteNotebookFunc) -> None:\n    \"\"\"\n    Test a notebook that has code cells with outputs.\n\n    Given a code cell and multiple output objects:\n    When `process_notebook` is called with `include_output=True`,\n    Then the outputs should be appended as commented lines under the code.\n    \"\"\"\n    notebook_content = {\n        \"cells\": [\n            {\n                \"cell_type\": \"code\",\n                \"source\": [\n                    \"import matplotlib.pyplot as plt\\n\",\n                    \"print('my_data')\\n\",\n                    \"my_data = [1, 2, 3, 4, 5]\\n\",\n                    \"plt.plot(my_data)\\n\",\n                    \"my_data\",\n                ],\n                \"outputs\": [\n                    {\"output_type\": \"stream\", \"text\": [\"my_data\"]},\n                    {\"output_type\": \"execute_result\", \"data\": {\"text/plain\": [\"[1, 2, 3, 4, 5]\"]}},\n                    {\"output_type\": \"display_data\", \"data\": {\"text/plain\": [\"<Figure size 640x480 with 1 Axes>\"]}},\n                ],\n            }\n        ]\n    }\n\n    nb_path = write_notebook(\"with_output.ipynb\", notebook_content)\n    with_output = process_notebook(nb_path, include_output=True)\n    without_output = process_notebook(nb_path, include_output=False)\n\n    expected_source = \"\\n\".join(\n        [\n            \"# Jupyter notebook converted to Python script.\\n\",\n            \"import matplotlib.pyplot as plt\",\n            \"print('my_data')\",\n            \"my_data = [1, 2, 3, 4, 5]\",\n            \"plt.plot(my_data)\",\n            \"my_data\\n\",\n        ]\n    )\n    expected_output = \"\\n\".join(\n        [\n            \"# Output:\",\n            \"#   my_data\",\n            \"#   [1, 2, 3, 4, 5]\",\n            \"#   <Figure size 640x480 with 1 Axes>\\n\",\n        ]\n    )\n\n    expected_combined = expected_source + expected_output\n\n    assert with_output == expected_combined, \"Should include source code and comment-ified output.\"\n    assert without_output == expected_source, \"Should include only the source code without output.\"\n\n\n\n================================================\nFile: tests/test_repository_clone.py\n================================================\n\"\"\"\nTests for the `cloning` module.\n\nThese tests cover various scenarios for cloning repositories, verifying that the appropriate Git commands are invoked\nand handling edge cases such as nonexistent URLs, timeouts, redirects, and specific commits or branches.\n\"\"\"\n\nimport asyncio\nimport os\nfrom pathlib import Path\nfrom unittest.mock import AsyncMock, patch\n\nimport pytest\n\nfrom gitingest.cloning import check_repo_exists, clone_repo\nfrom gitingest.schemas import CloneConfig\nfrom gitingest.utils.exceptions import AsyncTimeoutError\n\n\n@pytest.mark.asyncio\nasync def test_clone_with_commit() -> None:\n    \"\"\"\n    Test cloning a repository with a specific commit hash.\n\n    Given a valid URL and a commit hash:\n    When `clone_repo` is called,\n    Then the repository should be cloned and checked out at that commit.\n    \"\"\"\n    clone_config = CloneConfig(\n        url=\"https://github.com/user/repo\",\n        local_path=\"/tmp/repo\",\n        commit=\"a\" * 40,  # Simulating a valid commit hash\n        branch=\"main\",\n    )\n\n    with patch(\"gitingest.cloning.check_repo_exists\", return_value=True) as mock_check:\n        with patch(\"gitingest.cloning.run_command\", new_callable=AsyncMock) as mock_exec:\n            mock_process = AsyncMock()\n            mock_process.communicate.return_value = (b\"output\", b\"error\")\n            mock_exec.return_value = mock_process\n\n            await clone_repo(clone_config)\n\n            mock_check.assert_called_once_with(clone_config.url)\n            assert mock_exec.call_count == 2  # Clone and checkout calls\n\n\n@pytest.mark.asyncio\nasync def test_clone_without_commit() -> None:\n    \"\"\"\n    Test cloning a repository when no commit hash is provided.\n\n    Given a valid URL and no commit hash:\n    When `clone_repo` is called,\n    Then only the clone_repo operation should be performed (no checkout).\n    \"\"\"\n    query = CloneConfig(\n        url=\"https://github.com/user/repo\",\n        local_path=\"/tmp/repo\",\n        commit=None,\n        branch=\"main\",\n    )\n\n    with patch(\"gitingest.cloning.check_repo_exists\", return_value=True) as mock_check:\n        with patch(\"gitingest.cloning.run_command\", new_callable=AsyncMock) as mock_exec:\n            mock_process = AsyncMock()\n            mock_process.communicate.return_value = (b\"output\", b\"error\")\n            mock_exec.return_value = mock_process\n\n            await clone_repo(query)\n\n            mock_check.assert_called_once_with(query.url)\n            assert mock_exec.call_count == 1  # Only clone call\n\n\n@pytest.mark.asyncio\nasync def test_clone_nonexistent_repository() -> None:\n    \"\"\"\n    Test cloning a nonexistent repository URL.\n\n    Given an invalid or nonexistent URL:\n    When `clone_repo` is called,\n    Then a ValueError should be raised with an appropriate error message.\n    \"\"\"\n    clone_config = CloneConfig(\n        url=\"https://github.com/user/nonexistent-repo\",\n        local_path=\"/tmp/repo\",\n        commit=None,\n        branch=\"main\",\n    )\n    with patch(\"gitingest.cloning.check_repo_exists\", return_value=False) as mock_check:\n        with pytest.raises(ValueError, match=\"Repository not found\"):\n            await clone_repo(clone_config)\n\n            mock_check.assert_called_once_with(clone_config.url)\n\n\n@pytest.mark.asyncio\n@pytest.mark.parametrize(\n    \"mock_stdout, return_code, expected\",\n    [\n        (b\"HTTP/1.1 200 OK\\n\", 0, True),  # Existing repo\n        (b\"HTTP/1.1 404 Not Found\\n\", 0, False),  # Non-existing repo\n        (b\"HTTP/1.1 200 OK\\n\", 1, False),  # Failed request\n    ],\n)\nasync def test_check_repo_exists(mock_stdout: bytes, return_code: int, expected: bool) -> None:\n    \"\"\"\n    Test the `_check_repo_exists` function with different Git HTTP responses.\n\n    Given various stdout lines and return codes:\n    When `_check_repo_exists` is called,\n    Then it should correctly indicate whether the repository exists.\n    \"\"\"\n    url = \"https://github.com/user/repo\"\n\n    with patch(\"asyncio.create_subprocess_exec\", new_callable=AsyncMock) as mock_exec:\n        mock_process = AsyncMock()\n        # Mock the subprocess output\n        mock_process.communicate.return_value = (mock_stdout, b\"\")\n        mock_process.returncode = return_code\n        mock_exec.return_value = mock_process\n\n        repo_exists = await check_repo_exists(url)\n\n        assert repo_exists is expected\n\n\n@pytest.mark.asyncio\nasync def test_clone_with_custom_branch() -> None:\n    \"\"\"\n    Test cloning a repository with a specified custom branch.\n\n    Given a valid URL and a branch:\n    When `clone_repo` is called,\n    Then the repository should be cloned shallowly to that branch.\n    \"\"\"\n    clone_config = CloneConfig(url=\"https://github.com/user/repo\", local_path=\"/tmp/repo\", branch=\"feature-branch\")\n    with patch(\"gitingest.cloning.check_repo_exists\", return_value=True):\n        with patch(\"gitingest.cloning.run_command\", new_callable=AsyncMock) as mock_exec:\n            await clone_repo(clone_config)\n\n            mock_exec.assert_called_once_with(\n                \"git\",\n                \"clone\",\n                \"--single-branch\",\n                \"--depth=1\",\n                \"--branch\",\n                \"feature-branch\",\n                clone_config.url,\n                clone_config.local_path,\n            )\n\n\n@pytest.mark.asyncio\nasync def test_git_command_failure() -> None:\n    \"\"\"\n    Test cloning when the Git command fails during execution.\n\n    Given a valid URL, but `run_command` raises a RuntimeError:\n    When `clone_repo` is called,\n    Then a RuntimeError should be raised with the correct message.\n    \"\"\"\n    clone_config = CloneConfig(\n        url=\"https://github.com/user/repo\",\n        local_path=\"/tmp/repo\",\n    )\n    with patch(\"gitingest.cloning.check_repo_exists\", return_value=True):\n        with patch(\"gitingest.cloning.run_command\", side_effect=RuntimeError(\"Git command failed\")):\n            with pytest.raises(RuntimeError, match=\"Git command failed\"):\n                await clone_repo(clone_config)\n\n\n@pytest.mark.asyncio\nasync def test_clone_default_shallow_clone() -> None:\n    \"\"\"\n    Test cloning a repository with the default shallow clone options.\n\n    Given a valid URL and no branch or commit:\n    When `clone_repo` is called,\n    Then the repository should be cloned with `--depth=1` and `--single-branch`.\n    \"\"\"\n    clone_config = CloneConfig(\n        url=\"https://github.com/user/repo\",\n        local_path=\"/tmp/repo\",\n    )\n\n    with patch(\"gitingest.cloning.check_repo_exists\", return_value=True):\n        with patch(\"gitingest.cloning.run_command\", new_callable=AsyncMock) as mock_exec:\n            await clone_repo(clone_config)\n\n            mock_exec.assert_called_once_with(\n                \"git\",\n                \"clone\",\n                \"--single-branch\",\n                \"--depth=1\",\n                clone_config.url,\n                clone_config.local_path,\n            )\n\n\n@pytest.mark.asyncio\nasync def test_clone_commit_without_branch() -> None:\n    \"\"\"\n    Test cloning when a commit hash is provided but no branch is specified.\n\n    Given a valid URL and a commit hash (but no branch):\n    When `clone_repo` is called,\n    Then the repository should be cloned and checked out at that commit.\n    \"\"\"\n    clone_config = CloneConfig(\n        url=\"https://github.com/user/repo\",\n        local_path=\"/tmp/repo\",\n        commit=\"a\" * 40,  # Simulating a valid commit hash\n    )\n    with patch(\"gitingest.cloning.check_repo_exists\", return_value=True):\n        with patch(\"gitingest.cloning.run_command\", new_callable=AsyncMock) as mock_exec:\n            await clone_repo(clone_config)\n\n            assert mock_exec.call_count == 2  # Clone and checkout calls\n            mock_exec.assert_any_call(\"git\", \"clone\", \"--single-branch\", clone_config.url, clone_config.local_path)\n            mock_exec.assert_any_call(\"git\", \"-C\", clone_config.local_path, \"checkout\", clone_config.commit)\n\n\n@pytest.mark.asyncio\nasync def test_check_repo_exists_with_redirect() -> None:\n    \"\"\"\n    Test `check_repo_exists` when a redirect (302) is returned.\n\n    Given a URL that responds with \"302 Found\":\n    When `check_repo_exists` is called,\n    Then it should return `False`, indicating the repo is inaccessible.\n    \"\"\"\n    url = \"https://github.com/user/repo\"\n    with patch(\"asyncio.create_subprocess_exec\", new_callable=AsyncMock) as mock_exec:\n        mock_process = AsyncMock()\n        mock_process.communicate.return_value = (b\"HTTP/1.1 302 Found\\n\", b\"\")\n        mock_process.returncode = 0  # Simulate successful request\n        mock_exec.return_value = mock_process\n\n        repo_exists = await check_repo_exists(url)\n\n        assert repo_exists is False\n\n\n@pytest.mark.asyncio\nasync def test_check_repo_exists_with_permanent_redirect() -> None:\n    \"\"\"\n    Test `check_repo_exists` when a permanent redirect (301) is returned.\n\n    Given a URL that responds with \"301 Found\":\n    When `check_repo_exists` is called,\n    Then it should return `True`, indicating the repo may exist at the new location.\n    \"\"\"\n    url = \"https://github.com/user/repo\"\n    with patch(\"asyncio.create_subprocess_exec\", new_callable=AsyncMock) as mock_exec:\n        mock_process = AsyncMock()\n        mock_process.communicate.return_value = (b\"HTTP/1.1 301 Found\\n\", b\"\")\n        mock_process.returncode = 0  # Simulate successful request\n        mock_exec.return_value = mock_process\n\n        repo_exists = await check_repo_exists(url)\n\n        assert repo_exists\n\n\n@pytest.mark.asyncio\nasync def test_clone_with_timeout() -> None:\n    \"\"\"\n    Test cloning a repository when a timeout occurs.\n\n    Given a valid URL, but `run_command` times out:\n    When `clone_repo` is called,\n    Then an `AsyncTimeoutError` should be raised to indicate the operation exceeded time limits.\n    \"\"\"\n    clone_config = CloneConfig(url=\"https://github.com/user/repo\", local_path=\"/tmp/repo\")\n\n    with patch(\"gitingest.cloning.check_repo_exists\", return_value=True):\n        with patch(\"gitingest.cloning.run_command\", new_callable=AsyncMock) as mock_exec:\n            mock_exec.side_effect = asyncio.TimeoutError\n            with pytest.raises(AsyncTimeoutError, match=\"Operation timed out after\"):\n                await clone_repo(clone_config)\n\n\n@pytest.mark.asyncio\nasync def test_clone_specific_branch(tmp_path):\n    \"\"\"\n    Test cloning a specific branch of a repository.\n\n    Given a valid repository URL and a branch name:\n    When `clone_repo` is called,\n    Then the repository should be cloned and checked out at that branch.\n    \"\"\"\n    repo_url = \"https://github.com/cyclotruc/gitingest.git\"\n    branch_name = \"main\"\n    local_path = tmp_path / \"gitingest\"\n\n    config = CloneConfig(url=repo_url, local_path=str(local_path), branch=branch_name)\n    await clone_repo(config)\n\n    # Assertions\n    assert local_path.exists(), \"The repository was not cloned successfully.\"\n    assert local_path.is_dir(), \"The cloned repository path is not a directory.\"\n\n    # Check the current branch\n    current_branch = os.popen(f\"git -C {local_path} branch --show-current\").read().strip()\n    assert current_branch == branch_name, f\"Expected branch '{branch_name}', got '{current_branch}'.\"\n\n\n@pytest.mark.asyncio\nasync def test_clone_branch_with_slashes(tmp_path):\n    \"\"\"\n    Test cloning a branch with slashes in the name.\n\n    Given a valid repository URL and a branch name with slashes:\n    When `clone_repo` is called,\n    Then the repository should be cloned and checked out at that branch.\n    \"\"\"\n    repo_url = \"https://github.com/user/repo\"\n    branch_name = \"fix/in-operator\"\n    local_path = tmp_path / \"gitingest\"\n\n    clone_config = CloneConfig(url=repo_url, local_path=str(local_path), branch=branch_name)\n    with patch(\"gitingest.cloning.check_repo_exists\", return_value=True):\n        with patch(\"gitingest.cloning.run_command\", new_callable=AsyncMock) as mock_exec:\n            await clone_repo(clone_config)\n\n            mock_exec.assert_called_once_with(\n                \"git\",\n                \"clone\",\n                \"--single-branch\",\n                \"--depth=1\",\n                \"--branch\",\n                \"fix/in-operator\",\n                clone_config.url,\n                clone_config.local_path,\n            )\n\n\n@pytest.mark.asyncio\nasync def test_clone_creates_parent_directory(tmp_path: Path) -> None:\n    \"\"\"\n    Test that clone_repo creates parent directories if they don't exist.\n\n    Given a local path with non-existent parent directories:\n    When `clone_repo` is called,\n    Then it should create the parent directories before attempting to clone.\n    \"\"\"\n    nested_path = tmp_path / \"deep\" / \"nested\" / \"path\" / \"repo\"\n    clone_config = CloneConfig(\n        url=\"https://github.com/user/repo\",\n        local_path=str(nested_path),\n    )\n\n    with patch(\"gitingest.cloning.check_repo_exists\", return_value=True):\n        with patch(\"gitingest.cloning.run_command\", new_callable=AsyncMock) as mock_exec:\n            await clone_repo(clone_config)\n\n            # Verify parent directory was created\n            assert nested_path.parent.exists()\n\n            # Verify git clone was called with correct parameters\n            mock_exec.assert_called_once_with(\n                \"git\",\n                \"clone\",\n                \"--single-branch\",\n                \"--depth=1\",\n                clone_config.url,\n                str(nested_path),\n            )\n\n\n@pytest.mark.asyncio\nasync def test_clone_with_specific_subpath() -> None:\n    \"\"\"\n    Test cloning a repository with a specific subpath.\n\n    Given a valid repository URL and a specific subpath:\n    When `clone_repo` is called,\n    Then the repository should be cloned with sparse checkout enabled and the specified subpath.\n    \"\"\"\n    clone_config = CloneConfig(url=\"https://github.com/user/repo\", local_path=\"/tmp/repo\", subpath=\"src/docs\")\n\n    with patch(\"gitingest.cloning.check_repo_exists\", return_value=True):\n        with patch(\"gitingest.cloning.run_command\", new_callable=AsyncMock) as mock_exec:\n            await clone_repo(clone_config)\n\n            # Verify the clone command includes sparse checkout flags\n            mock_exec.assert_any_call(\n                \"git\",\n                \"clone\",\n                \"--single-branch\",\n                \"--filter=blob:none\",\n                \"--sparse\",\n                \"--depth=1\",\n                clone_config.url,\n                clone_config.local_path,\n            )\n\n            # Verify the sparse-checkout command sets the correct path\n            mock_exec.assert_any_call(\"git\", \"-C\", clone_config.local_path, \"sparse-checkout\", \"set\", \"src/docs\")\n\n            assert mock_exec.call_count == 2\n\n\n@pytest.mark.asyncio\nasync def test_clone_with_commit_and_subpath() -> None:\n    \"\"\"\n    Test cloning a repository with both a specific commit and subpath.\n\n    Given a valid repository URL, commit hash, and subpath:\n    When `clone_repo` is called,\n    Then the repository should be cloned with sparse checkout enabled,\n    checked out at the specific commit, and only include the specified subpath.\n    \"\"\"\n    clone_config = CloneConfig(\n        url=\"https://github.com/user/repo\",\n        local_path=\"/tmp/repo\",\n        commit=\"a\" * 40,  # Simulating a valid commit hash\n        subpath=\"src/docs\",\n    )\n\n    with patch(\"gitingest.cloning.check_repo_exists\", return_value=True):\n        with patch(\"gitingest.cloning.run_command\", new_callable=AsyncMock) as mock_exec:\n            await clone_repo(clone_config)\n\n            # Verify the clone command includes sparse checkout flags\n            mock_exec.assert_any_call(\n                \"git\",\n                \"clone\",\n                \"--single-branch\",\n                \"--filter=blob:none\",\n                \"--sparse\",\n                clone_config.url,\n                clone_config.local_path,\n            )\n\n            # Verify the sparse-checkout command sets the correct path\n            mock_exec.assert_any_call(\n                \"git\",\n                \"-C\",\n                clone_config.local_path,\n                \"sparse-checkout\",\n                \"set\",\n                \"src/docs\",\n                \"checkout\",\n                clone_config.commit,\n            )\n\n            assert mock_exec.call_count == 2\n\n\n\n================================================\nFile: tests/.pylintrc\n================================================\n[MASTER]\ninit-hook=\n    import sys\n    sys.path.append('./src')\n\n[MESSAGES CONTROL]\ndisable=missing-class-docstring,missing-function-docstring,protected-access,fixme\n\n[FORMAT]\nmax-line-length=119\n\n\n\n================================================\nFile: tests/query_parser/test_git_host_agnostic.py\n================================================\n\"\"\"\nTests to verify that the query parser is Git host agnostic.\n\nThese tests confirm that `parse_query` correctly identifies user/repo pairs and canonical URLs for GitHub, GitLab,\nBitbucket, Gitea, and Codeberg, even if the host is omitted.\n\"\"\"\n\nfrom typing import List\n\nimport pytest\n\nfrom gitingest.query_parsing import parse_query\n\n\n@pytest.mark.parametrize(\n    \"urls, expected_user, expected_repo, expected_url\",\n    [\n        (\n            [\n                \"https://github.com/tiangolo/fastapi\",\n                \"github.com/tiangolo/fastapi\",\n                \"tiangolo/fastapi\",\n            ],\n            \"tiangolo\",\n            \"fastapi\",\n            \"https://github.com/tiangolo/fastapi\",\n        ),\n        (\n            [\n                \"https://gitlab.com/gitlab-org/gitlab-runner\",\n                \"gitlab.com/gitlab-org/gitlab-runner\",\n                \"gitlab-org/gitlab-runner\",\n            ],\n            \"gitlab-org\",\n            \"gitlab-runner\",\n            \"https://gitlab.com/gitlab-org/gitlab-runner\",\n        ),\n        (\n            [\n                \"https://bitbucket.org/na-dna/llm-knowledge-share\",\n                \"bitbucket.org/na-dna/llm-knowledge-share\",\n                \"na-dna/llm-knowledge-share\",\n            ],\n            \"na-dna\",\n            \"llm-knowledge-share\",\n            \"https://bitbucket.org/na-dna/llm-knowledge-share\",\n        ),\n        (\n            [\n                \"https://gitea.com/xorm/xorm\",\n                \"gitea.com/xorm/xorm\",\n                \"xorm/xorm\",\n            ],\n            \"xorm\",\n            \"xorm\",\n            \"https://gitea.com/xorm/xorm\",\n        ),\n        (\n            [\n                \"https://codeberg.org/forgejo/forgejo\",\n                \"codeberg.org/forgejo/forgejo\",\n                \"forgejo/forgejo\",\n            ],\n            \"forgejo\",\n            \"forgejo\",\n            \"https://codeberg.org/forgejo/forgejo\",\n        ),\n    ],\n)\n@pytest.mark.asyncio\nasync def test_parse_query_without_host(\n    urls: List[str],\n    expected_user: str,\n    expected_repo: str,\n    expected_url: str,\n) -> None:\n    \"\"\"\n    Test `parse_query` for Git host agnosticism.\n\n    Given multiple URL variations for the same user/repo on different Git hosts (with or without host names):\n    When `parse_query` is called with each variation,\n    Then the parser should correctly identify the user, repo, canonical URL, and other default fields.\n    \"\"\"\n    for url in urls:\n        query = await parse_query(url, max_file_size=50, from_web=True)\n\n        assert query.user_name == expected_user\n        assert query.repo_name == expected_repo\n        assert query.url == expected_url\n        assert query.slug == f\"{expected_user}-{expected_repo}\"\n        assert query.id is not None\n        assert query.subpath == \"/\"\n        assert query.branch is None\n        assert query.commit is None\n        assert query.type is None\n\n\n\n================================================\nFile: tests/query_parser/test_query_parser.py\n================================================\n\"\"\"\nTests for the `query_parsing` module.\n\nThese tests cover URL parsing, pattern parsing, and handling of branches/subpaths for HTTP(S) repositories and local\npaths.\n\"\"\"\n\nfrom pathlib import Path\nfrom unittest.mock import AsyncMock, patch\n\nimport pytest\n\nfrom gitingest.query_parsing import _parse_patterns, _parse_remote_repo, parse_query\nfrom gitingest.utils.ignore_patterns import DEFAULT_IGNORE_PATTERNS\n\n\n@pytest.mark.asyncio\nasync def test_parse_url_valid_https() -> None:\n    \"\"\"\n    Test `_parse_remote_repo` with valid HTTPS URLs.\n\n    Given various HTTPS URLs on supported platforms:\n    When `_parse_remote_repo` is called,\n    Then user name, repo name, and the URL should be extracted correctly.\n    \"\"\"\n    test_cases = [\n        \"https://github.com/user/repo\",\n        \"https://gitlab.com/user/repo\",\n        \"https://bitbucket.org/user/repo\",\n        \"https://gitea.com/user/repo\",\n        \"https://codeberg.org/user/repo\",\n        \"https://gist.github.com/user/repo\",\n    ]\n    for url in test_cases:\n        query = await _parse_remote_repo(url)\n\n        assert query.user_name == \"user\"\n        assert query.repo_name == \"repo\"\n        assert query.url == url\n\n\n@pytest.mark.asyncio\nasync def test_parse_url_valid_http() -> None:\n    \"\"\"\n    Test `_parse_remote_repo` with valid HTTP URLs.\n\n    Given various HTTP URLs on supported platforms:\n    When `_parse_remote_repo` is called,\n    Then user name, repo name, and the slug should be extracted correctly.\n    \"\"\"\n    test_cases = [\n        \"http://github.com/user/repo\",\n        \"http://gitlab.com/user/repo\",\n        \"http://bitbucket.org/user/repo\",\n        \"http://gitea.com/user/repo\",\n        \"http://codeberg.org/user/repo\",\n        \"http://gist.github.com/user/repo\",\n    ]\n    for url in test_cases:\n        query = await _parse_remote_repo(url)\n\n        assert query.user_name == \"user\"\n        assert query.repo_name == \"repo\"\n        assert query.slug == \"user-repo\"\n\n\n@pytest.mark.asyncio\nasync def test_parse_url_invalid() -> None:\n    \"\"\"\n    Test `_parse_remote_repo` with an invalid URL.\n\n    Given an HTTPS URL lacking a repository structure (e.g., \"https://github.com\"),\n    When `_parse_remote_repo` is called,\n    Then a ValueError should be raised indicating an invalid repository URL.\n    \"\"\"\n    url = \"https://github.com\"\n    with pytest.raises(ValueError, match=\"Invalid repository URL\"):\n        await _parse_remote_repo(url)\n\n\n@pytest.mark.asyncio\n@pytest.mark.parametrize(\"url\", [\"https://github.com/user/repo\", \"https://gitlab.com/user/repo\"])\nasync def test_parse_query_basic(url):\n    \"\"\"\n    Test `parse_query` with a basic valid repository URL.\n\n    Given an HTTPS URL and ignore_patterns=\"*.txt\":\n    When `parse_query` is called,\n    Then user/repo, URL, and ignore patterns should be parsed correctly.\n    \"\"\"\n    query = await parse_query(source=url, max_file_size=50, from_web=True, ignore_patterns=\"*.txt\")\n\n    assert query.user_name == \"user\"\n    assert query.repo_name == \"repo\"\n    assert query.url == url\n    assert query.ignore_patterns\n    assert \"*.txt\" in query.ignore_patterns\n\n\n@pytest.mark.asyncio\nasync def test_parse_query_mixed_case() -> None:\n    \"\"\"\n    Test `parse_query` with mixed-case URLs.\n\n    Given a URL with mixed-case parts (e.g. \"Https://GitHub.COM/UsEr/rEpO\"):\n    When `parse_query` is called,\n    Then the user and repo names should be normalized to lowercase.\n    \"\"\"\n    url = \"Https://GitHub.COM/UsEr/rEpO\"\n    query = await parse_query(url, max_file_size=50, from_web=True)\n\n    assert query.user_name == \"user\"\n    assert query.repo_name == \"repo\"\n\n\n@pytest.mark.asyncio\nasync def test_parse_query_include_pattern() -> None:\n    \"\"\"\n    Test `parse_query` with a specified include pattern.\n\n    Given a URL and include_patterns=\"*.py\":\n    When `parse_query` is called,\n    Then the include pattern should be set, and default ignore patterns remain applied.\n    \"\"\"\n    url = \"https://github.com/user/repo\"\n    query = await parse_query(url, max_file_size=50, from_web=True, include_patterns=\"*.py\")\n\n    assert query.include_patterns == {\"*.py\"}\n    assert query.ignore_patterns == DEFAULT_IGNORE_PATTERNS\n\n\n@pytest.mark.asyncio\nasync def test_parse_query_invalid_pattern() -> None:\n    \"\"\"\n    Test `parse_query` with an invalid pattern.\n\n    Given an include pattern containing special characters (e.g., \"*.py;rm -rf\"):\n    When `parse_query` is called,\n    Then a ValueError should be raised indicating invalid characters.\n    \"\"\"\n    url = \"https://github.com/user/repo\"\n    with pytest.raises(ValueError, match=\"Pattern.*contains invalid characters\"):\n        await parse_query(url, max_file_size=50, from_web=True, include_patterns=\"*.py;rm -rf\")\n\n\n@pytest.mark.asyncio\nasync def test_parse_url_with_subpaths() -> None:\n    \"\"\"\n    Test `_parse_remote_repo` with a URL containing branch and subpath.\n\n    Given a URL referencing a branch (\"main\") and a subdir (\"subdir/file\"):\n    When `_parse_remote_repo` is called with remote branch fetching,\n    Then user, repo, branch, and subpath should be identified correctly.\n    \"\"\"\n    url = \"https://github.com/user/repo/tree/main/subdir/file\"\n    with patch(\"gitingest.utils.git_utils.run_command\", new_callable=AsyncMock) as mock_run_command:\n        mock_run_command.return_value = (b\"refs/heads/main\\nrefs/heads/dev\\nrefs/heads/feature-branch\\n\", b\"\")\n        with patch(\n            \"gitingest.utils.git_utils.fetch_remote_branch_list\", new_callable=AsyncMock\n        ) as mock_fetch_branches:\n            mock_fetch_branches.return_value = [\"main\", \"dev\", \"feature-branch\"]\n            query = await _parse_remote_repo(url)\n\n            assert query.user_name == \"user\"\n            assert query.repo_name == \"repo\"\n            assert query.branch == \"main\"\n            assert query.subpath == \"/subdir/file\"\n\n\n@pytest.mark.asyncio\nasync def test_parse_url_invalid_repo_structure() -> None:\n    \"\"\"\n    Test `_parse_remote_repo` with a URL missing a repository name.\n\n    Given a URL like \"https://github.com/user\":\n    When `_parse_remote_repo` is called,\n    Then a ValueError should be raised indicating an invalid repository URL.\n    \"\"\"\n    url = \"https://github.com/user\"\n    with pytest.raises(ValueError, match=\"Invalid repository URL\"):\n        await _parse_remote_repo(url)\n\n\ndef test_parse_patterns_valid() -> None:\n    \"\"\"\n    Test `_parse_patterns` with valid comma-separated patterns.\n\n    Given patterns like \"*.py, *.md, docs/*\":\n    When `_parse_patterns` is called,\n    Then it should return a set of parsed strings.\n    \"\"\"\n    patterns = \"*.py, *.md, docs/*\"\n    parsed_patterns = _parse_patterns(patterns)\n\n    assert parsed_patterns == {\"*.py\", \"*.md\", \"docs/*\"}\n\n\ndef test_parse_patterns_invalid_characters() -> None:\n    \"\"\"\n    Test `_parse_patterns` with invalid characters.\n\n    Given a pattern string containing special characters (e.g. \"*.py;rm -rf\"):\n    When `_parse_patterns` is called,\n    Then a ValueError should be raised indicating invalid pattern syntax.\n    \"\"\"\n    patterns = \"*.py;rm -rf\"\n    with pytest.raises(ValueError, match=\"Pattern.*contains invalid characters\"):\n        _parse_patterns(patterns)\n\n\n@pytest.mark.asyncio\nasync def test_parse_query_with_large_file_size() -> None:\n    \"\"\"\n    Test `parse_query` with a very large file size limit.\n\n    Given a URL and max_file_size=10**9:\n    When `parse_query` is called,\n    Then `max_file_size` should be set correctly and default ignore patterns remain unchanged.\n    \"\"\"\n    url = \"https://github.com/user/repo\"\n    query = await parse_query(url, max_file_size=10**9, from_web=True)\n\n    assert query.max_file_size == 10**9\n    assert query.ignore_patterns == DEFAULT_IGNORE_PATTERNS\n\n\n@pytest.mark.asyncio\nasync def test_parse_query_empty_patterns() -> None:\n    \"\"\"\n    Test `parse_query` with empty patterns.\n\n    Given empty include_patterns and ignore_patterns:\n    When `parse_query` is called,\n    Then include_patterns becomes None and default ignore patterns apply.\n    \"\"\"\n    url = \"https://github.com/user/repo\"\n    query = await parse_query(url, max_file_size=50, from_web=True, include_patterns=\"\", ignore_patterns=\"\")\n\n    assert query.include_patterns is None\n    assert query.ignore_patterns == DEFAULT_IGNORE_PATTERNS\n\n\n@pytest.mark.asyncio\nasync def test_parse_query_include_and_ignore_overlap() -> None:\n    \"\"\"\n    Test `parse_query` with overlapping patterns.\n\n    Given include=\"*.py\" and ignore={\"*.py\", \"*.txt\"}:\n    When `parse_query` is called,\n    Then \"*.py\" should be removed from ignore patterns.\n    \"\"\"\n    url = \"https://github.com/user/repo\"\n    query = await parse_query(\n        url,\n        max_file_size=50,\n        from_web=True,\n        include_patterns=\"*.py\",\n        ignore_patterns={\"*.py\", \"*.txt\"},\n    )\n\n    assert query.include_patterns == {\"*.py\"}\n    assert query.ignore_patterns is not None\n    assert \"*.py\" not in query.ignore_patterns\n    assert \"*.txt\" in query.ignore_patterns\n\n\n@pytest.mark.asyncio\nasync def test_parse_query_local_path() -> None:\n    \"\"\"\n    Test `parse_query` with a local file path.\n\n    Given \"/home/user/project\" and from_web=False:\n    When `parse_query` is called,\n    Then the local path should be set, id generated, and slug formed accordingly.\n    \"\"\"\n    path = \"/home/user/project\"\n    query = await parse_query(path, max_file_size=100, from_web=False)\n    tail = Path(\"home/user/project\")\n\n    assert query.local_path.parts[-len(tail.parts) :] == tail.parts\n    assert query.id is not None\n    assert query.slug == \"home/user/project\"\n\n\n@pytest.mark.asyncio\nasync def test_parse_query_relative_path() -> None:\n    \"\"\"\n    Test `parse_query` with a relative path.\n\n    Given \"./project\" and from_web=False:\n    When `parse_query` is called,\n    Then local_path resolves relatively, and slug ends with \"project\".\n    \"\"\"\n    path = \"./project\"\n    query = await parse_query(path, max_file_size=100, from_web=False)\n    tail = Path(\"project\")\n\n    assert query.local_path.parts[-len(tail.parts) :] == tail.parts\n    assert query.slug.endswith(\"project\")\n\n\n@pytest.mark.asyncio\nasync def test_parse_query_empty_source() -> None:\n    \"\"\"\n    Test `parse_query` with an empty string.\n\n    Given an empty source string:\n    When `parse_query` is called,\n    Then a ValueError should be raised indicating an invalid repository URL.\n    \"\"\"\n    with pytest.raises(ValueError, match=\"Invalid repository URL\"):\n        await parse_query(\"\", max_file_size=100, from_web=True)\n\n\n@pytest.mark.asyncio\n@pytest.mark.parametrize(\n    \"url, expected_branch, expected_commit\",\n    [\n        (\"https://github.com/user/repo/tree/main\", \"main\", None),\n        (\n            \"https://github.com/user/repo/tree/abcd1234abcd1234abcd1234abcd1234abcd1234\",\n            None,\n            \"abcd1234abcd1234abcd1234abcd1234abcd1234\",\n        ),\n    ],\n)\nasync def test_parse_url_branch_and_commit_distinction(url: str, expected_branch: str, expected_commit: str) -> None:\n    \"\"\"\n    Test `_parse_remote_repo` distinguishing branch vs. commit hash.\n\n    Given either a branch URL (e.g., \".../tree/main\") or a 40-character commit URL:\n    When `_parse_remote_repo` is called with branch fetching,\n    Then the function should correctly set `branch` or `commit` based on the URL content.\n    \"\"\"\n    with patch(\"gitingest.utils.git_utils.run_command\", new_callable=AsyncMock) as mock_run_command:\n        # Mocking the return value to include 'main' and some additional branches\n        mock_run_command.return_value = (b\"refs/heads/main\\nrefs/heads/dev\\nrefs/heads/feature-branch\\n\", b\"\")\n        with patch(\n            \"gitingest.utils.git_utils.fetch_remote_branch_list\", new_callable=AsyncMock\n        ) as mock_fetch_branches:\n            mock_fetch_branches.return_value = [\"main\", \"dev\", \"feature-branch\"]\n\n            query = await _parse_remote_repo(url)\n\n            # Verify that `branch` and `commit` match our expectations\n            assert query.branch == expected_branch\n            assert query.commit == expected_commit\n\n\n@pytest.mark.asyncio\nasync def test_parse_query_uuid_uniqueness() -> None:\n    \"\"\"\n    Test `parse_query` for unique UUID generation.\n\n    Given the same path twice:\n    When `parse_query` is called repeatedly,\n    Then each call should produce a different query id.\n    \"\"\"\n    path = \"/home/user/project\"\n    query_1 = await parse_query(path, max_file_size=100, from_web=False)\n    query_2 = await parse_query(path, max_file_size=100, from_web=False)\n\n    assert query_1.id != query_2.id\n\n\n@pytest.mark.asyncio\nasync def test_parse_url_with_query_and_fragment() -> None:\n    \"\"\"\n    Test `_parse_remote_repo` with query parameters and a fragment.\n\n    Given a URL like \"https://github.com/user/repo?arg=value#fragment\":\n    When `_parse_remote_repo` is called,\n    Then those parts should be stripped, leaving a clean user/repo URL.\n    \"\"\"\n    url = \"https://github.com/user/repo?arg=value#fragment\"\n    query = await _parse_remote_repo(url)\n\n    assert query.user_name == \"user\"\n    assert query.repo_name == \"repo\"\n    assert query.url == \"https://github.com/user/repo\"  # URL should be cleaned\n\n\n@pytest.mark.asyncio\nasync def test_parse_url_unsupported_host() -> None:\n    \"\"\"\n    Test `_parse_remote_repo` with an unsupported host.\n\n    Given \"https://only-domain.com\":\n    When `_parse_remote_repo` is called,\n    Then a ValueError should be raised for the unknown domain.\n    \"\"\"\n    url = \"https://only-domain.com\"\n    with pytest.raises(ValueError, match=\"Unknown domain 'only-domain.com' in URL\"):\n        await _parse_remote_repo(url)\n\n\n@pytest.mark.asyncio\nasync def test_parse_query_with_branch() -> None:\n    \"\"\"\n    Test `parse_query` when a branch is specified in a blob path.\n\n    Given \"https://github.com/pandas-dev/pandas/blob/2.2.x/...\":\n    When `parse_query` is called,\n    Then the branch should be identified, subpath set, and commit remain None.\n    \"\"\"\n    url = \"https://github.com/pandas-dev/pandas/blob/2.2.x/.github/ISSUE_TEMPLATE/documentation_improvement.yaml\"\n    query = await parse_query(url, max_file_size=10**9, from_web=True)\n\n    assert query.user_name == \"pandas-dev\"\n    assert query.repo_name == \"pandas\"\n    assert query.url == \"https://github.com/pandas-dev/pandas\"\n    assert query.slug == \"pandas-dev-pandas\"\n    assert query.id is not None\n    assert query.subpath == \"/.github/ISSUE_TEMPLATE/documentation_improvement.yaml\"\n    assert query.branch == \"2.2.x\"\n    assert query.commit is None\n    assert query.type == \"blob\"\n\n\n@pytest.mark.asyncio\n@pytest.mark.parametrize(\n    \"url, expected_branch, expected_subpath\",\n    [\n        (\"https://github.com/user/repo/tree/main/src\", \"main\", \"/src\"),\n        (\"https://github.com/user/repo/tree/fix1\", \"fix1\", \"/\"),\n        (\"https://github.com/user/repo/tree/nonexistent-branch/src\", \"nonexistent-branch\", \"/src\"),\n    ],\n)\nasync def test_parse_repo_source_with_failed_git_command(url, expected_branch, expected_subpath):\n    \"\"\"\n    Test `_parse_remote_repo` when git fetch fails.\n\n    Given a URL referencing a branch, but Git fetching fails:\n    When `_parse_remote_repo` is called,\n    Then it should fall back to path components for branch identification.\n    \"\"\"\n    with patch(\"gitingest.utils.git_utils.fetch_remote_branch_list\", new_callable=AsyncMock) as mock_fetch_branches:\n        mock_fetch_branches.side_effect = Exception(\"Failed to fetch branch list\")\n\n        with pytest.warns(\n            RuntimeWarning,\n            match=\"Warning: Failed to fetch branch list: Command failed: \"\n            \"git ls-remote --heads https://github.com/user/repo\",\n        ):\n\n            query = await _parse_remote_repo(url)\n\n            assert query.branch == expected_branch\n            assert query.subpath == expected_subpath\n\n\n@pytest.mark.asyncio\n@pytest.mark.parametrize(\n    \"url, expected_branch, expected_subpath\",\n    [\n        (\"https://github.com/user/repo/tree/feature/fix1/src\", \"feature/fix1\", \"/src\"),\n        (\"https://github.com/user/repo/tree/main/src\", \"main\", \"/src\"),\n        (\"https://github.com/user/repo\", None, \"/\"),  # No\n        (\"https://github.com/user/repo/tree/nonexistent-branch/src\", None, \"/\"),  # Non-existent branch\n        (\"https://github.com/user/repo/tree/fix\", \"fix\", \"/\"),\n        (\"https://github.com/user/repo/blob/fix/page.html\", \"fix\", \"/page.html\"),\n    ],\n)\nasync def test_parse_repo_source_with_various_url_patterns(url, expected_branch, expected_subpath):\n    \"\"\"\n    Test `_parse_remote_repo` with various URL patterns.\n\n    Given multiple branch/blob patterns (including nonexistent branches):\n    When `_parse_remote_repo` is called with remote branch fetching,\n    Then the correct branch/subpath should be set or None if unmatched.\n    \"\"\"\n    with patch(\"gitingest.utils.git_utils.run_command\", new_callable=AsyncMock) as mock_run_command:\n        with patch(\n            \"gitingest.utils.git_utils.fetch_remote_branch_list\", new_callable=AsyncMock\n        ) as mock_fetch_branches:\n            mock_run_command.return_value = (\n                b\"refs/heads/feature/fix1\\nrefs/heads/main\\nrefs/heads/feature-branch\\nrefs/heads/fix\\n\",\n                b\"\",\n            )\n            mock_fetch_branches.return_value = [\"feature/fix1\", \"main\", \"feature-branch\"]\n\n            query = await _parse_remote_repo(url)\n\n            assert query.branch == expected_branch\n            assert query.subpath == expected_subpath\n\n\n\n================================================\nFile: .github/dependabot.yml\n================================================\nversion: 2\nupdates:\n  - package-ecosystem: \"pip\"\n    directory: \"/\"\n    schedule:\n      interval: \"daily\"\n      time: \"06:00\"\n      timezone: \"UTC\"\n    open-pull-requests-limit: 5\n    labels:\n      - \"dependencies\"\n      - \"pip\"\n\n\n\n================================================\nFile: .github/workflows/ci.yml\n================================================\nname: CI\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\npermissions:\n  contents: read\n\njobs:\n  test:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: true\n      matrix:\n        os: [ubuntu-latest, macos-latest, windows-latest]\n        python-version: [\"3.8\", \"3.9\", \"3.10\", \"3.11\", \"3.12\", \"3.13\"]\n\n    steps:\n    - uses: actions/checkout@v4\n\n    - name: Set up Python\n      uses: actions/setup-python@v5\n      with:\n        python-version: ${{ matrix.python-version }}\n\n    - name: Cache pip\n      uses: actions/cache@v4\n      with:\n        path: ~/.cache/pip\n        key: ${{ runner.os }}-pip-${{ hashFiles('**/*requirements*.txt') }}\n        restore-keys: |\n          ${{ runner.os }}-pip-\n\n    - name: Install dependencies\n      run: |\n        pip install --upgrade pip\n        pip install -r requirements-dev.txt\n\n    - name: Run tests\n      run: |\n        pytest\n\n    #  Run pre-commit only on Python 3.13 + ubuntu.\n    - name: Run pre-commit hooks\n      if: ${{ matrix.python-version == '3.13' && matrix.os == 'ubuntu-latest' }}\n      run: |\n        pre-commit run --all-files\n\n\n\n================================================\nFile: .github/workflows/publish.yml\n================================================\nname: \"Publish to PyPI\"\n\non:\n  release:\n    types: [created]\n  workflow_dispatch:\n\npermissions:\n  contents: read\n\njobs:\n  release-build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: \"3.13\"\n      - name: Build package\n        run: |\n          pip install build\n          python -m build\n      - uses: actions/upload-artifact@v4\n        with:\n          name: dist\n          path: dist/\n\n  pypi-publish:\n    needs: [release-build]\n    runs-on: ubuntu-latest\n    environment: pypi\n    permissions:\n      id-token: write\n    steps:\n      - uses: actions/download-artifact@v4\n        with:\n          name: dist\n          path: dist/\n      - uses: pypa/gh-action-pypi-publish@release/v1\n\n\n\n================================================\nFile: .github/workflows/scorecard.yml\n================================================\nname: OSSF Scorecard\non:\n  # For Branch-Protection check. Only the default branch is supported. See\n  # https://github.com/ossf/scorecard/blob/main/docs/checks.md#branch-protection\n  branch_protection_rule:\n  # To guarantee Maintained check is occasionally updated. See\n  # https://github.com/ossf/scorecard/blob/main/docs/checks.md#maintained\n  schedule:\n    - cron: '33 11 * * 2'\n  push:\n    branches: [ \"main\" ]\n\n# Declare default permissions as read only.\npermissions: read-all\n\njobs:\n  analysis:\n    name: Scorecard analysis\n    runs-on: ubuntu-latest\n    permissions:\n      # Needed to upload the results to code-scanning dashboard.\n      security-events: write\n      # Needed to publish results and get a badge (see publish_results below).\n      id-token: write\n\n    steps:\n      - name: \"Checkout code\"\n        uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11 # v4.1.1\n        with:\n          persist-credentials: false\n\n      - name: \"Run analysis\"\n        uses: ossf/scorecard-action@0864cf19026789058feabb7e87baa5f140aac736 # v2.3.1\n        with:\n          results_file: results.sarif\n          results_format: sarif\n\n          # Public repositories:\n          #   - Publish results to OpenSSF REST API for easy access by consumers\n          #   - Allows the repository to include the Scorecard badge.\n          #   - See https://github.com/ossf/scorecard-action#publishing-results.\n          publish_results: true\n\n      # Upload the results as artifacts (optional). Commenting out will disable uploads of run results in SARIF\n      # format to the repository Actions tab.\n\n      # Upload the results to GitHub's code scanning dashboard (optional).\n      # Commenting out will disable upload of results to your repo's Code Scanning dashboard\n      - name: \"Upload to code-scanning\"\n        uses: github/codeql-action/upload-sarif@v3\n        with:\n          sarif_file: results.sarif\n\n\n"
  },
  "analysis": {
    "gemini": "RELEVANT FILES:\n- `src/gitingest/cli.py`\n- `src/gitingest/entrypoint.py`\n- `src/gitingest/ingestion.py`\n- `src/gitingest/query_parsing.py`\n- `src/gitingest/cloning.py`\n- `src/server/routers/index.py`\n- `src/server/query_processor.py`\n- `src/static/js/utils.js`\n- `tests/test_cli.py`\n- `tests/test_ingestion.py`\n- `tests/test_flow_integration.py`\n- `tests/test_query_parser.py`\n- `.github/workflows/ci.yml`\n- `.github/workflows/publish.yml`\n\nKEY CODE ELEMENTS:\n```filename: src/gitingest/cli.py\n@click.command()\n@click.argument(\"source\")\n@click.option(\n    \"--output\",\n    \"-o\",\n    type=click.Path(exists=False, writable=True, path_type=Path),\n    default=None,\n    help=\"Output file path. If not specified, prints to stdout.\",\n)\n@click.option(\n    \"--max-size\",\n    \"-m\",\n    type=int,\n    default=None,\n    help=\"Maximum file size to ingest (in KB). Defaults to no limit.\",\n)\n@click.option(\n    \"--exclude-pattern\",\n    \"-e\",\n    multiple=True,\n    help=\"Exclude files matching this pattern. Can be specified multiple times.\",\n)\n@click.option(\n    \"--include-pattern\",\n    \"-i\",\n    multiple=True,\n    help=\"Include files matching this pattern. Can be specified multiple times.\",\n)\n@click.option(\n    \"--branch\",\n    \"-b\",\n    type=str,\n    default=None,\n    help=\"The specific branch to use. Defaults to the repository's main branch.\",\n)\n@asyncio_run\nasync def gitingest(\n    source: str,\n    output: Path | None,\n    max_size: int | None,\n    exclude_pattern: tuple[str, ...],\n    include_pattern: tuple[str, ...],\n    branch: str | None,\n) -> None:\n    \"\"\"\n    Ingests a repository or directory, clones it if needed, then returns the\n    directory structure and all file contents (up to the max size limit).\n    \"\"\"\n    results = await ingest_async(source, max_size, list(exclude_pattern), list(include_pattern), branch)\n\n    if output:\n        output.write_text(results.formatted_content)\n    else:\n        print(results.formatted_content)\n```\n\n```filename: src/gitingest/entrypoint.py\nasync def ingest_async(\n    source: str,\n    max_size: int | None = None,\n    exclude_patterns: list[str] | None = None,\n    include_patterns: list[str] | None = None,\n    branch: str | None = None,\n) -> IngestedData:\n    \"\"\"Ingests a URL or local path. If a URL, it clones it, and then processes it.\"\"\"\n    query = parse_query(source, max_file_size_kb=max_size, include_patterns=include_patterns, ignore_patterns=exclude_patterns, branch=branch)\n    return await ingest_query(query)\n\ndef ingest(\n    source: str,\n    max_size: int | None = None,\n    exclude_patterns: list[str] | None = None,\n    include_patterns: list[str] | None = None,\n    branch: str | None = None,\n) -> IngestedData:\n    \"\"\"Synchronous wrapper for ingest_async.\"\"\"\n    return asyncio.run(ingest_async(source, max_size, exclude_patterns, include_patterns, branch))\n```\n\n```filename: src/server/routers/index.py\n@router.post(\"/\")\nasync def process_git(\n    request: Request,\n    input_text: str = Form(...),\n    slider_position: int = Form(500),\n    pattern_type: str = Form(\"\"),\n    pattern: str = Form(\"\"),\n    is_index: bool = True,\n):\n    \"\"\"Processes a git repository URL and renders the result.\"\"\"\n    return await process_query(request, input_text, slider_position, pattern_type, pattern, is_index)\n```\n\n```filename: src/server/query_processor.py\nasync def process_query(request: Request, input_text: str, slider_position: int, pattern_type: str, pattern: str, is_index: bool):\n    try:\n        max_file_size_kb = log_slider_to_size(slider_position)\n\n        query = parse_query(\n            input_text,\n            max_file_size_kb=max_file_size_kb,\n            include_patterns=[pattern] if pattern_type == \"include\" and pattern else None,\n            ignore_patterns=[pattern] if pattern_type == \"exclude\" and pattern else None,\n        )\n\n        clone_config = query.extract_clone_config()\n        await clone_repo(clone_config)\n\n        results = await ingest_query(query)\n\n        content_display = results.formatted_content[:server_config.MAX_DISPLAY_SIZE]\n\n        # Render the template with the results\n        return templates.TemplateResponse(\n            \"index.jinja\" if is_index else \"git.jinja\",\n            {\n                \"request\": request,\n                \"summary\": results.summary,\n                \"directory_structure\": results.directory_structure,\n                \"content\": content_display,\n                \"input_text\": input_text,\n                \"is_index\": is_index,\n            },\n        )\n    except Exception as e:\n        tb_str = traceback.format_exception(type(e), e, e.__traceback__)\n        error_message = f\"Error processing the repository: {e}\\n{''.join(tb_str)}\"\n        return templates.TemplateResponse(\n            \"index.jinja\" if is_index else \"git.jinja\",\n            {\n                \"request\": request,\n                \"error\": error_message,\n                \"input_text\": input_text,\n                \"is_index\": is_index,\n            },\n        )\n```\n\n```filename: src/static/js/utils.js\nfunction handleSubmit(event, showLoading = false) {\n    event.preventDefault();\n\n    const form = event.target;\n    const formData = new FormData(form);\n\n    // Get the file size limit from the slider\n    const sliderPosition = document.getElementById('fileSizeSlider').value;\n    const fileSizeInKB = logSliderToSize(sliderPosition);\n    formData.set('slider_position', sliderPosition);\n\n    // Get pattern type\n    var patternType = document.querySelector('input[name=\"patternType\"]:checked');\n    if (patternType) {\n        patternType = patternType.value\n    } else {\n        patternType = \"\";\n    }\n    formData.set('pattern_type', patternType);\n\n    // Get pattern\n    const pattern = document.getElementById('pattern').value;\n    formData.set('pattern', pattern);\n\n    // Show loading animation on submit button\n    const submitButton = form.querySelector('button[type=\"submit\"]');\n    if (showLoading) {\n        submitButton.innerHTML = '<span class=\"spinner-border spinner-border-sm\" role=\"status\" aria-hidden=\"true\"></span> Loading...';\n        submitButton.disabled = true;\n    }\n\n    fetch(form.action, {\n        method: form.method,\n        body: formData\n    })\n    .then(response => response.text())\n    .then(html => {\n        // Replace the entire page content with the response from the server\n        document.documentElement.innerHTML = html;\n\n        // Re-init the slider\n        initializeSlider();\n        // Handle scrolling to results after the content is replaced\n        const resultsDiv = document.getElementById('results');\n        if (resultsDiv) {\n            resultsDiv.scrollIntoView({ behavior: 'smooth' });\n        }\n    })\n    .catch(error => {\n        console.error('Error:', error);\n        // Re-enable the submit button and remove the loading animation\n        submitButton.innerHTML = 'Submit';\n        submitButton.disabled = false;\n    });\n}\n```\n\n**Consolidated Analysis:**\n\nThe `gitingest` repository offers both a command-line interface and a web application to ingest and analyze code from Git repositories (or local directories). The core functionality involves parsing the input source, cloning the repository (if necessary), traversing the file system, filtering files based on include/exclude patterns and size limits, extracting content, and formatting the output.\n\n**Key Components:**\n\n*   **CLI (`src/gitingest/cli.py`):**  Uses `click` to provide a command-line interface for ingesting code. The `gitingest` command accepts arguments for the source (URL or local path), output file, max file size, exclude patterns, include patterns, and branch.\n\n*   **Ingestion Engine (`src/gitingest/entrypoint.py`, `src/gitingest/ingestion.py`, `src/gitingest/query_parsing.py`, `src/gitingest/cloning.py`):** This is the core logic for parsing the input, cloning the repo, traversing the file system, extracting content, and formatting the output.  `ingest_async` is the main entry point for ingestion. `parse_query` parses the URL/path and creates an `IngestionQuery` object.  `clone_repo` clones the repo using the `CloneConfig`. `ingest_query` handles the actual processing.\n\n*   **Web Server (`src/server/routers/index.py`, `src/server/query_processor.py`):** A FastAPI-based web server that provides a web interface for submitting Git repository URLs and analyzing their contents. `index.py` handles routing and calls the `process_query` to perform the actual ingestion and rendering. `process_query` orchestrates the parsing, cloning, ingestion, and rendering processes.\n\n*   **Frontend (`src/static/js/utils.js`):** JavaScript code that handles form submissions, UI updates, and copying text to the clipboard. The `handleSubmit` function manages form submission and page updates based on the server's response. The javascript implements the slider functionality.\n\n*   **Testing (`tests/test_cli.py`, `tests/test_ingestion.py`, `tests/test_query_parser.py`, `tests/test_flow_integration.py`):** A comprehensive suite of tests that cover the CLI, core ingestion logic, query parsing, and end-to-end flow. The integration tests verify that the frontend and backend interact correctly.\n\n*   **CI/CD (`.github/workflows/ci.yml`, `.github/workflows/publish.yml`):**  GitHub Actions workflows for Continuous Integration (running tests and linting on pull requests) and Continuous Deployment (publishing the package to PyPI on new releases).\n**Key Files, Functions, Classes, Components, Frontend, Backend, and Database files:**\n\n*   **RELEVANT FILES:** See beginning of response\n*   **KEY CODE ELEMENTS:** See beginning of response\n*   **Key Files**\n    *   **`cli.py`:** Command-line interface.\n    *   **`entrypoint.py`, `ingestion.py`, `query_parsing.py`, `cloning.py`:** Core ingestion engine files.\n    *   **`index.py`, `query_processor.py`:** Web server route and core processor.\n    *   **`utils.js`:** Client-side javascript utilities.\n*   **Functions:**\n    *   **`ingest_async(source)` (entrypoint.py):** Main entry point for ingestion.\n    *   **`parse_query(source)` (query_parsing.py):** Parses the input source.\n    *   **`clone_repo(config)` (cloning.py):** Clones a Git repository.\n    *   **`handleSubmit(event)` (utils.js):** Handles form submission on the frontend.\n    *   **`process_query(request, input_text, slider_position, pattern_type, pattern, is_index)` (query_processor.py)**: Core server backend function.\n*   **Classes/Data Structures:**\n    *   `IngestionQuery`: Dataclass/Pydantic model holding parsed query parameters.\n    *   `CloneConfig`: Dataclass holding cloning configuration.\n*   **Components:**\n    *   **CLI:** Command-line interface.\n    *   **Web Server:** FastAPI-based web server.\n    *   **Ingestion Engine:** Core logic for processing codebases.\n    *   **Frontend:** JavaScript-based user interface.\n*   **Frontend:** `src/static/js/utils.js`, Jinja2 templates (`src/server/templates/`)\n*   **Backend:** `src/gitingest/*`, `src/server/*`\n*   **Database files:** Not explicitly used. Temporary directories are utilized for cloning the code, but those are removed. The processed \"digest\" is returned to the user or written to an output file; persistence is not explicitly incorporated.\n",
    "groq": "### Detailed Summary of Extracted Files\n\nThe provided repository contains various files that contribute to the functionality of a Git repository ingestion and analysis tool. Below is a detailed summary of each file:\n\n#### 1. `src/gitingest/cli.py`\n\n*   This file defines the command-line interface (CLI) for the ingestion tool using the Click library.\n*   The `gitingest` command accepts arguments for the source (URL or local path), output file, max file size, exclude patterns, include patterns, and branch.\n*   The `gitingest` function is the main entry point for the CLI, which calls the `ingest_async` function to perform the ingestion.\n\n#### 2. `src/gitingest/entrypoint.py`\n\n*   This file contains the core logic for ingesting a Git repository or directory.\n*   The `ingest_async` function is the main entry point for ingestion, which parses the input source, clones the repository (if necessary), and processes the files.\n*   The `ingest` function is a synchronous wrapper for `ingest_async`.\n\n#### 3. `src/gitingest/ingestion.py`\n\n*   Although not provided, this file is likely responsible for the actual ingestion of files, including traversing the file system, filtering files based on include/exclude patterns and size limits, and extracting content.\n\n#### 4. `src/gitingest/query_parsing.py`\n\n*   Although not provided, this file is likely responsible for parsing the input source and creating an `IngestionQuery` object.\n*   The `parse_query` function is used to parse the input source and create an `IngestionQuery` object.\n\n#### 5. `src/gitingest/cloning.py`\n\n*   Although not provided, this file is likely responsible for cloning a Git repository.\n*   The `clone_repo` function is used to clone a Git repository using the `CloneConfig`.\n\n#### 6. `src/server/routers/index.py`\n\n*   This file defines the routing for the web server using FastAPI.\n*   The `process_git` function handles the processing of a Git repository URL and renders the result.\n\n#### 7. `src/server/query_processor.py`\n\n*   This file contains the core logic for processing a Git repository query.\n*   The `process_query` function orchestrates the parsing, cloning, ingestion, and rendering processes.\n*   It also handles errors and exceptions during the processing.\n\n#### 8. `src/static/js/utils.js`\n\n*   This file contains JavaScript code that handles form submissions, UI updates, and copying text to the clipboard.\n*   The `handleSubmit` function manages form submission and page updates based on the server's response.\n\n#### 9. `tests/test_cli.py`\n\n*   This file contains tests for the command-line interface (CLI).\n*   The tests verify that the CLI functions correctly and handles different scenarios.\n\n#### 10. `tests/test_ingestion.py`\n\n*   This file contains tests for the ingestion logic.\n*   The tests verify that the ingestion functions correctly and handles different scenarios.\n\n#### 11. `tests/test_flow_integration.py`\n\n*   This file contains tests for the end-to-end flow of the application.\n*   The tests verify that the application functions correctly from the user's perspective.\n\n#### 12. `tests/test_query_parser.py`\n\n*   This file contains tests for the query parsing logic.\n*   The tests verify that the query parser functions correctly and handles different scenarios.\n\n#### 13. `.github/workflows/ci.yml`\n\n*   This file defines a GitHub Actions workflow for continuous integration (CI).\n*   The workflow runs tests and linting on pull requests.\n\n#### 14. `.github/workflows/publish.yml`\n\n*   This file defines a GitHub Actions workflow for continuous deployment (CD).\n*   The workflow publishes the package to PyPI on new releases.\n\n### Key Components and Technologies\n\n*   **Command-Line Interface (CLI):** The application provides a CLI for ingesting Git repositories or directories.\n*   **Web Server:** The application uses FastAPI to provide a web interface for ingesting Git repositories.\n*   **Ingestion Engine:** The application uses a core ingestion engine to process Git repositories or directories.\n*   **Frontend:** The application uses JavaScript and HTML/CSS to provide a user interface.\n*   **Backend:** The application uses Python and FastAPI to provide a web server and ingestion engine.\n*   **Database:** The application does not use a database explicitly, but it uses temporary directories for cloning and processing Git repositories.\n\n### Example Use Cases\n\n*   **Command-Line Interface (CLI):** A user can use the CLI to ingest a Git repository or directory by running the command `gitingest <source> --output <output_file>`.\n*   **Web Interface:** A user can use the web interface to ingest a Git repository by entering the repository URL and clicking the \"Ingest\" button.\n*   **Integration with CI/CD Pipelines:** The application can be integrated with CI/CD pipelines to automate the ingestion and analysis of Git repositories.\n\n### Advice and Next Steps\n\n*   **Security:** Ensure that the application handles sensitive information, such as Git repository credentials, securely.\n*   **Error Handling:** Improve error handling and logging to provide better feedback to users.\n*   **Performance:** Optimize the ingestion engine to improve performance and handle large Git repositories.\n*   **Testing:** Add more tests to cover different scenarios and edge cases.\n*   **Documentation:** Improve documentation to provide better guidance to users and developers."
  }
}